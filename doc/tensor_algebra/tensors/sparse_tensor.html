<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>tensap.tensor_algebra.tensors.sparse_tensor API documentation</title>
<meta name="description" content="Module sparse_tensor â€¦" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tensap.tensor_algebra.tensors.sparse_tensor</code></h1>
</header>
<section id="section-intro">
<p>Module sparse_tensor.</p>
<p>Copyright (c) 2020, Anthony Nouy, Erwan Grelier
This file is part of tensap (tensor approximation package).</p>
<p>tensap is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.</p>
<p>tensap is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
See the
GNU Lesser General Public License for more details.</p>
<p>You should have received a copy of the GNU Lesser General Public License
along with tensap.
If not, see <a href="https://www.gnu.org/licenses/">https://www.gnu.org/licenses/</a>.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;
Module sparse_tensor.

Copyright (c) 2020, Anthony Nouy, Erwan Grelier
This file is part of tensap (tensor approximation package).

tensap is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

tensap is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public License
along with tensap.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

&#39;&#39;&#39;

from copy import deepcopy
import numpy as np
from scipy.sparse import lil_matrix, coo_matrix
import tensap


class SparseTensor:
    &#39;&#39;&#39;
    Class SparseTensor.

    Attributes
    ----------
    data : numpy.ndarray
        The values of the tensor at the entries in indices.
    indices : tensap.MultiIndices
        The set of multi-indices corresponding to the non-zero coefficients of
        the tensor.
    order : int
        The order of the tensor.
    shape : numpy.ndarray
        The shape of the tensor.

    &#39;&#39;&#39;

    def __init__(self, data=None, indices=None, shape=None):
        &#39;&#39;&#39;
        Constructor for the class SparseTensor.

        Parameters
        ----------
        data : list or numpy.ndarray, optional
            The values of the tensor at the entries in indices, or the tensor
            itself. The default is None.
        indices : tensap.MultiIndices, optional
            The set of multi-indices corresponding to the non-zero coefficients
            of the tensor. The default is None, indicating to infer it from
            the tensor provided in data.
        shape : list or numpy.ndarray, optional
            The shape of the tensor. The default is None, indicating to infer
            it from the tensor provided in data.

        Raises
        ------
        ValueError
            If the provided arguments are wrong.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        if data is None and indices is None and shape is None:
            self.data = []
            self.order = 0
            self.indices = []
            self.shape = []
        elif data is not None and indices is None and shape is None:
            if isinstance(data, (list, np.ndarray)):
                self.order = np.ndim(data)
                self.shape = np.shape(data)

                rep = np.nonzero(data)
                self.data = data[rep]
                self.indices = tensap.MultiIndices(
                    np.hstack([np.reshape(x, [-1, 1]) for x in rep]))
            elif np.all([hasattr(data, x) for x in [&#39;data&#39;, &#39;order&#39;,
                                                    &#39;shape&#39;, &#39;indices&#39;]]):
                self.data = data.data
                self.order = data.order
                self.shape = data.shape
                self.indices = data.indices
            else:
                raise ValueError(&#39;Wrong input arguments.&#39;)
        elif data is not None and indices is not None and shape is not None:
            assert isinstance(indices, tensap.MultiIndices), \
                &#39;Argument indices must be a MultiIndices.&#39;

            self.indices = indices
            self.order = indices.ndim()
            self.shape = shape
            self.data = data
            assert np.size(data) == indices.cardinal(), \
                &#39;data and indices must have the same number of elements.&#39;
        else:
            raise ValueError(&#39;Wrong input arguments.&#39;)
        self.data = np.squeeze(self.data)
        self.shape = np.squeeze(self.shape)

    @property
    def size(self):
        &#39;&#39;&#39;
        Compute the size of the tensor. Equivalent to self.storage().

        Returns
        -------
        numpy.ndarray
            The size of the tensor.

        &#39;&#39;&#39;
        return np.prod(self.shape)

    def storage(self):
        &#39;&#39;&#39;
        Return the storage complexity of the SparseTensor.

        Returns
        -------
        int
            The storage complexity of the SparseTensor.

        &#39;&#39;&#39;
        return self.size

    def sparse_storage(self):
        &#39;&#39;&#39;
        Return the sparse storage complexity of the SparseTensor.

        Returns
        -------
        int
            The sparse storage complexity of the SparseTensor.

        &#39;&#39;&#39;
        return self.count_non_zero()

    def count_non_zero(self):
        &#39;&#39;&#39;
        Return the number of non-zero coefficients of the SparseTensor.
        Equivalent to self.sparse_storage().

        Returns
        -------
        int
            The number of non-zero coefficients of the SparseTensor.

        &#39;&#39;&#39;
        return self.indices.cardinal()

    @property
    def ndim(self):
        &#39;&#39;&#39;
        Compute the order of the tensor. Equivalent to self.order.

        Returns
        -------
        int
            The order of the tensor.

        &#39;&#39;&#39;
        return np.size(self.shape)

    def full(self):
        &#39;&#39;&#39;
        Convert the SparseTensor to a tensap.FullTensor.

        Returns
        -------
        y : tensap.FullTensor
            The SparseTensor as a tensap.FullTensor.

        &#39;&#39;&#39;
        y = tensap.FullTensor(np.zeros(self.shape))
        ind = tuple(self.indices.to_list())
        y.data[ind] = self.data
        return y

    def numpy(self):
        &#39;&#39;&#39;
        Convert the SparseTensor to a scipy.sparse.lil.lil_matrix, which can
        be converted to a numpy.matrix using the command todense().

        Returns
        -------
        y : scipy.sparse.lil.lil_matrix
            The SparseTensor as a scipy.sparse.lil.lil_matrix.

        &#39;&#39;&#39;
        assert self.ndim &lt;= 2, \
            &#39;nd sparse arrays are not allowed for d &gt; 2.&#39;

        y = lil_matrix(tuple(self.shape), dtype=float)
        ind = tuple(self.indices.to_list())
        y[ind] = self.data
        return y

    def eval_at_indices(self, ind, dims=None):
        &#39;&#39;&#39;
        Evaluate the tensor at indices.

        If dims is None, return
        s(k) = x(indices(k, 1), indices(k, 2), ..., indices(k, d)),
        1 &lt;= k &lt;= self.shape[0].

        If dims is not None, return a partial evaluation: up to a permutation
        (placing the dimensions dims on the left), return
        s(k, i_1, ..., i_d&#39;) = x(indices(k, 1), indices(k, 2), ...,
        indices(k, M), i_1, ..., i_d&#39;),
        1 &lt;= k &lt;= self.shape[0], with M = dims.size and d&#39; = self.order - M.

        Parameters
        ----------
        ind : list of numpy.ndarray
            The indices of the tensor.
        dims : list of numpy.ndarray, optional
            The dimensions associated with the indices. The default is None,
            indicating that indices refers to all the dimensions.

        Returns
        -------
        evaluations : scipy.sparse.lil.lil_matrix
            The evaluations of the tensor.

        &#39;&#39;&#39;
        assert dims is None or np.all(dims == np.arange(self.order)), \
            &#39;Method not implemented.&#39;

        if isinstance(ind, tensap.MultiIndices):
            ind = ind.array

        J = self.indices.array
        loc_J, loc_I = np.nonzero(np.all(ind == J[:, np.newaxis], axis=2))
        evaluations = lil_matrix((ind.shape[0], 1), dtype=float)
        evaluations[loc_I, 0] = self.data[loc_J]
        return evaluations

    def squeeze(self, dims):
        &#39;&#39;&#39;
        Remove the singleton dimensions of the tensor.

        Parameters
        ----------
        dims : list or numpy.ndarray, optional
            Dimensions to squeeze. The default is None, indicating all the
            singleton dimensions.

        Returns
        -------
        SparseTensor
            The squeezed tensor.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def __add__(self, y):
        ind = self.indices.add_indices(y.indices)
        _, rep_x, _ = ind.intersect_indices(self.indices)
        _, rep_y, _ = ind.intersect_indices(y.indices)
        data = np.zeros(ind.cardinal())
        data[rep_x] += self.data
        data[rep_y] += y.data
        return SparseTensor(data, ind, self.shape)

    def __neg__(self):
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def __sub__(self, y):
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def tensor_vector_product(self, vectors, dims=None):
        &#39;&#39;&#39;
        Compute the contraction of the tensor with vectors.

        Compute the contraction of self with each vector contained in the list
        vectors along dimensions specified by dims. The operation is such that
        V[k] is contracted with the dims[k]-th dimension of self.

        Parameters
        ----------
        vectors : numpy.ndarray or list of numpy.ndarray
            The vectors to use in the product.
        dims : list or numpy.ndarray, optional
            Indices of the contractions. The default is None, indicating all
            the dimensions.

        Returns
        -------
        out : SparseTensor
            The tensor after the contractions with the vectors.

        &#39;&#39;&#39;
        if dims is None:
            assert isinstance(vectors, list), &#39;vectors should be a list.&#39;
            assert len(vectors) == self.order, \
                &#39;len(vectors) must be self.order.&#39;
            dims = np.arange(self.order)
        else:
            dims = np.array(dims)
            if not isinstance(vectors, list):
                vectors = [vectors]
            assert len(vectors) == dims.size, \
                &#39;len(vectors) must be equal to dims.size.&#39;

        vectors = [np.ravel(x) for x in vectors]

        out = deepcopy(self)
        not_dims = np.setdiff1d(range(out.order), dims)
        if not_dims.size == 0:
            out.shape = []
        else:
            out.shape = out.shape[not_dims]

        for i in range(dims.size):
            a = out.data * vectors[i][out.indices.array[:, dims[i]]]

            out.indices.array = out.indices.array[:, np.setdiff1d(
                range(out.indices.array.shape[1]), dims[i])]
            out.indices.array = out.indices.array[a != 0, :]

            if out.indices.array.size != 0:
                out.indices.array, ind = np.unique(out.indices.array, axis=0,
                                                   return_inverse=True)

                a = a[a != 0]
                out.data = np.bincount(ind, weights=a)

            dims -= dims &gt; dims[i]

        out.order -= len(vectors)

        if np.size(out.shape) == 0:
            out = out.data

        return out

    def tensor_matrix_product(self, matrices, dims=None):
        &#39;&#39;&#39;
        Contract a tensor with matrices.

        The second dimension of the matrix matrices[k] is contracted with the
        k-th dimension of self, with the indices k given in dims (if provided).

        Parameters
        ----------
        matrices : numpy.ndarray or list of numpy.ndarray
            The matrices to use in the product.
        dims : list or numpy.ndarray, optional
            Indices of the contractions. The default is None, indicating all
            the dimensions.

        Returns
        -------
        out : SparseTensor
            The tensor after the contractions with the matrices.

        &#39;&#39;&#39;
        if dims is None:
            assert isinstance(matrices, (list, np.ndarray)), \
                &#39;matrices should be a list or a numpy.ndarray.&#39;
            assert len(matrices) == self.order, \
                &#39;len(matrices) must be self.order.&#39;
            dims = range(self.order)
        else:
            dims = np.atleast_1d(dims)
            if not isinstance(matrices, list):
                matrices = [matrices]
            assert len(matrices) == dims.size, \
                &#39;len(matrices) must be equal to dims.size.&#39;

        k = 0
        out = deepcopy(self)
        for mu in dims:
            perm_dims = np.concatenate(
                ([mu], np.setdiff1d(np.arange(out.order), mu)))
            out = out.transpose(perm_dims)
            if out.order == 1:
                out.shape[1] = 1
            ind = tensap.MultiIndices(
                out.indices.array[out.data != 0, :]).sub2ind(out.shape)
            x1, x2 = np.unravel_index(ind,
                                      [out.shape[0], np.prod(out.shape[1:])],
                                      order=&#39;F&#39;)
            x2u, x2uind = np.unique(x2, return_inverse=True)
            s = coo_matrix((out.data[out.data != 0],
                            (x1, x2uind)),
                           shape=(out.shape[0], np.max(x2uind)+1))
            a = np.transpose(s.transpose().dot(np.transpose(matrices[k])))
            y1, y2 = np.nonzero(a)
            out.shape[0] = matrices[k].shape[0]
            ind = np.ravel_multi_index((y1, np.reshape(x2u[y2], y1.shape)),
                                       (out.shape[0], np.prod(out.shape[1:])),
                                       order=&#39;F&#39;)
            out.indices = tensap.MultiIndices.ind2sub(out.shape, ind)
            out.data = np.ravel(a[a != 0])
            out = out.itranspose(perm_dims)
            k += 1
        return out

    def tensor_matrix_product_eval_diag(self, matrices):
        &#39;&#39;&#39;
        Evaluate the diagonal of a tensor obtained by contraction with
        matrices.

        Parameters
        ----------
        matrices : list
            The matrices to use in the product.

        Returns
        -------
        SparseTensor
            The diagonal of the contractions of the tensor with the matrices.

        &#39;&#39;&#39;
        y = matrices[0][:, self.indices.array[:, 0]]
        for k in np.arange(1, self.order):
            y *= matrices[k][:, self.indices.array[:, k]]
        return np.matmul(y, self.data)

    def transpose(self, dims):
        &#39;&#39;&#39;
        Transpose (permute) the dimensions of the tensor.

        Parameters
        ----------
        dims : list or numpy.ndarray
            The new ordering of the dimensions.

        Returns
        -------
        out : SparseTensor
            The transposed (permuted) tensor.

        &#39;&#39;&#39;
        out = deepcopy(self)
        out.indices.array = out.indices.array[:, dims]
        out.shape = out.shape[dims]
        return out

    def itranspose(self, dims):
        &#39;&#39;&#39;
        Return the inverse transpose (permutation) of the dimensions of the
        tensor.

        Parameters
        ----------
        dims : list or numpy.ndarray
            The original transpose (permutation) indices.

        Returns
        -------
        SparseTensor
            The transposed (permuted) tensor.

        &#39;&#39;&#39;
        out = deepcopy(self)
        return out.transpose(np.argsort(dims))

    def reshape(self, shape):
        &#39;&#39;&#39;
        Reshape the tensor.

        Parameters
        ----------
        shape : list or numpy.ndarray
            The new shape of the tensor.

        Returns
        -------
        tensor : SparseTensor
            The reshaped tensor.

        &#39;&#39;&#39;
        shape = np.array(shape)
        ind = self.indices.sub2ind(self.shape)
        out = deepcopy(self)
        out.indices = tensap.MultiIndices.ind2sub(shape, ind)
        out.shape = shape
        out.order = shape.size
        return out

    def tensor_diagonal_matrix_product(self, matrices, dims=None):
        &#39;&#39;&#39;
        Contract a SparseTensor with matrices built from their diagonals.

        The second dimension of the matrix matrices[k] is contracted with the
        k-th dimension of self, with the indices k given in dims (if provided).

        FIXME: not optimal, does not exploit sparsity.

        Parameters
        ----------
        matrices : numpy.ndarray or list of numpy.ndarray
            The diagonals of the matrices to use in the product.
        dims : list or numpy.ndarray, optional
            Indices of the contractions. The default is None, indicating all
            the dimensions.

        Returns
        -------
        SparseTensor
            The tensor after the contractions with the matrices.

        &#39;&#39;&#39;
        if not isinstance(matrices, list):
            matrices = [matrices[:, i] for i in range(np.shape(matrices)[1])]

        if dims is None:
            assert len(matrices) == self.order, \
                &#39;len(matrices) must be self.order.&#39;
            dims = range(self.order)
        else:
            dims = np.array(dims)
            assert len(matrices) == dims.size, \
                &#39;len(matrices) must be equal to dims.size.&#39;

        matrices = [tensap.FullTensor(np.diag(np.reshape(x, [-1])))
                    for x in matrices]
        return self.tensor_matrix_product(matrices, dims)

    def dot(self, y):
        &#39;&#39;&#39;
        Return the inner product of two tensors.

        Parameters
        ----------
        y : tensap.Tensor
            The second tensor of the inner products. Must be convertible to
            a SparseTensor.

        Returns
        -------
        numpy.float
            The inner product of the two tensors.

        &#39;&#39;&#39;
        if not isinstance(y, SparseTensor):
            try:
                y = y.sparse()
            except Exception:
                raise ValueError(&#39;Cannot convert input to SparseTensor.&#39;)

        _, ind_x, ind_y = self.indices.intersect_indices(y.indices)
        return np.sum(self.data[ind_x] * y.data[ind_y])

    def __mul__(self, y):
        if not isinstance(y, SparseTensor):
            try:
                y = y.sparse()
            except Exception:
                raise ValueError(&#39;Cannot convert input to SparseTensor.&#39;)

        _, ind_x, ind_y = self.indices.intersect_indices(y.indices)
        out = deepcopy(self)
        out.data = self.data[ind_x] * y.data[ind_y]
        out.indices.array = self.indices.array[ind_x, :]
        return out

    def norm(self):
        &#39;&#39;&#39;
        Compute the canonical norm of the SparseTensor.

        Returns
        -------
        numpy.float
            The norm of the tensor.

        &#39;&#39;&#39;
        return np.sqrt(self.dot(self))

    def orth(self, dim):
        &#39;&#39;&#39;
        Orthogonalize the tensor.

        Parameters
        ----------
        dim : int
            The dimension of the orthogonal dim-matricization of self.

        Returns
        -------
        SparseTensor
            A tensor whose dim-matricization is an orthogonal matrix
            corresponding to the Q factor of a QR factorization of the
            dim-matricization of self.
        r_matrix : numpy.ndarray
            The R factor.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def cat(self, y, dims):
        &#39;&#39;&#39;
        Concatenate the tensors.

        Concatenates self and y in a tensor z such that:
        z(i_1 ,..., i_d) = x(i_1, ..., i_d) if i_k &lt;= sz[k]-1 for k in dims,
        z(i_1, ..., i_d) = y(i_1-sz[0], ..., i_d-sz[d-1]) if i_k &gt;= sz[k]
        for k in dims,
        z(i_1, ..., i_d) = 0 otherwise, with sz = self.shape and
        dims = range(self.order) if not provided.

        Parameters
        ----------
        y : Tensor
            The second tensor to be concatenaed.
        dims : list or numpy.ndarray, optional
            The dimensions of the concatenation. The default is None,
            indicating all the dimensions.
        Returns
        -------
        SparseTensor
            The concatenated tensors.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def kron(self, y):
        &#39;&#39;&#39;
        Kronecker product of tensors.

        Similar to numpy.kron but for sparse tensors.

        Parameters
        ----------
        y : Tensor
            The second tensor of the Kronecker product.

        Returns
        -------
        SparseTensor
            The tensor resulting from the Kronecker product.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def dot_with_rank_one_metric(self, y, M):
        &#39;&#39;&#39;
        Compute the weighted inner product of two tensors.

        Compute the weighted canonical inner product of self and y,
        where the inner product related to dimension k is weighted by
        M[k]. It is equivalent to
        self.dot(y.tensor_matrix_product(M)),
        but can be much faster.

        Parameters
        ----------
        y : Tensor
            The second tensor of the inner product.
        M : list or numpy.ndarray or FullTensor
            The weight matrix.

        Returns
        -------
        numpy.float
            The weighted inner product.

        &#39;&#39;&#39;
        s = y.tensor_matrix_product(M)
        return self.dot(s)

    def tensordot_matrix_product_except_dim(self, y, M, dim):
        &#39;&#39;&#39;
        Particular type of contraction.

        Compute a special contraction of two tensors self, y, a list of
        matrices M and a particular dimension dim. Note that dim must
        be a scalar, while M must be a list array with x.self.order
        elements.

        Parameters
        ----------
        y : Tensor
            The second tensor of the contraction.
        M : list
            The list of matrices of the contraction.
        dim : int
            The excluded dimension.

        Returns
        -------
        numpy.ndarray
            The result of the contraction.

        &#39;&#39;&#39;
        # dims = np.setdiff1d(np.arange(self.order), dim)
        # s = y.tensor_matrix_product(M[dims], dims)
        # return self.tensordot(s, dims, dims)
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def eval_diag(self, dims=None):
        &#39;&#39;&#39;
        Extract the diagonal of the tensor.

        The tensor must be such that self.shape[mu] = n for all mu (in dims if
        provided).

        Parameters
        ----------
        dims : list of numpy.ndarray, optional
            The dimensions associated with the indices of the diagonal. The
            default is None,indicating that indices refers to all the
            dimensions.

        Returns
        -------
        data : numpy.ndarray
            The evaluations of the diagonal of the tensor.

        &#39;&#39;&#39;
        if dims is None:
            dims = np.arange(self.order)
        else:
            dims = np.atleast_1d(dims)

        if dims.size == 1:
            data = self
        else:
            assert np.all([self.shape[x] == self.shape[dims[0]] for
                           x in dims]),\
             &#39;The shapes of the tensor in dimensions dims should be equal.&#39;
            ind = np.repeat(np.reshape(np.arange(self.shape[0]), [-1, 1]),
                            dims.size, 1)
            data = self.eval_at_indices(ind, dims)
        return data

    def sub_tensor(self, *indices):
        &#39;&#39;&#39;
        Extract a subtensor of the tensor.

        The result is a tensor s of shape
        len(indices[0]), ..., len(indices[self.order-1]),
        such that
        s(k1,...,kd) = x(indices[0][k1], ..., indices[self.order-1][kd]).

        Example: x.subTensor([1, 2], &#39;:&#39;, [2, 5, 6]) returns a tensor with
        shape [2, self.shape[1], 3].

        Parameters
        ----------
        *indices : list
            The indices to extract in each dimension. &#39;:&#39; indicates all the
            indices.

        Returns
        -------
        SparseTensor
            The subtensor.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;Method not implemented.&#39;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor"><code class="flex name class">
<span>class <span class="ident">SparseTensor</span></span>
<span>(</span><span>data=None, indices=None, shape=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Class SparseTensor.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The values of the tensor at the entries in indices.</dd>
<dt><strong><code>indices</code></strong> :&ensp;<code>tensap.MultiIndices</code></dt>
<dd>The set of multi-indices corresponding to the non-zero coefficients of
the tensor.</dd>
<dt><strong><code>order</code></strong> :&ensp;<code>int</code></dt>
<dd>The order of the tensor.</dd>
<dt><strong><code>shape</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The shape of the tensor.</dd>
</dl>
<p>Constructor for the class SparseTensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>The values of the tensor at the entries in indices, or the tensor
itself. The default is None.</dd>
<dt><strong><code>indices</code></strong> :&ensp;<code>tensap.MultiIndices</code>, optional</dt>
<dd>The set of multi-indices corresponding to the non-zero coefficients
of the tensor. The default is None, indicating to infer it from
the tensor provided in data.</dd>
<dt><strong><code>shape</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>The shape of the tensor. The default is None, indicating to infer
it from the tensor provided in data.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the provided arguments are wrong.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SparseTensor:
    &#39;&#39;&#39;
    Class SparseTensor.

    Attributes
    ----------
    data : numpy.ndarray
        The values of the tensor at the entries in indices.
    indices : tensap.MultiIndices
        The set of multi-indices corresponding to the non-zero coefficients of
        the tensor.
    order : int
        The order of the tensor.
    shape : numpy.ndarray
        The shape of the tensor.

    &#39;&#39;&#39;

    def __init__(self, data=None, indices=None, shape=None):
        &#39;&#39;&#39;
        Constructor for the class SparseTensor.

        Parameters
        ----------
        data : list or numpy.ndarray, optional
            The values of the tensor at the entries in indices, or the tensor
            itself. The default is None.
        indices : tensap.MultiIndices, optional
            The set of multi-indices corresponding to the non-zero coefficients
            of the tensor. The default is None, indicating to infer it from
            the tensor provided in data.
        shape : list or numpy.ndarray, optional
            The shape of the tensor. The default is None, indicating to infer
            it from the tensor provided in data.

        Raises
        ------
        ValueError
            If the provided arguments are wrong.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        if data is None and indices is None and shape is None:
            self.data = []
            self.order = 0
            self.indices = []
            self.shape = []
        elif data is not None and indices is None and shape is None:
            if isinstance(data, (list, np.ndarray)):
                self.order = np.ndim(data)
                self.shape = np.shape(data)

                rep = np.nonzero(data)
                self.data = data[rep]
                self.indices = tensap.MultiIndices(
                    np.hstack([np.reshape(x, [-1, 1]) for x in rep]))
            elif np.all([hasattr(data, x) for x in [&#39;data&#39;, &#39;order&#39;,
                                                    &#39;shape&#39;, &#39;indices&#39;]]):
                self.data = data.data
                self.order = data.order
                self.shape = data.shape
                self.indices = data.indices
            else:
                raise ValueError(&#39;Wrong input arguments.&#39;)
        elif data is not None and indices is not None and shape is not None:
            assert isinstance(indices, tensap.MultiIndices), \
                &#39;Argument indices must be a MultiIndices.&#39;

            self.indices = indices
            self.order = indices.ndim()
            self.shape = shape
            self.data = data
            assert np.size(data) == indices.cardinal(), \
                &#39;data and indices must have the same number of elements.&#39;
        else:
            raise ValueError(&#39;Wrong input arguments.&#39;)
        self.data = np.squeeze(self.data)
        self.shape = np.squeeze(self.shape)

    @property
    def size(self):
        &#39;&#39;&#39;
        Compute the size of the tensor. Equivalent to self.storage().

        Returns
        -------
        numpy.ndarray
            The size of the tensor.

        &#39;&#39;&#39;
        return np.prod(self.shape)

    def storage(self):
        &#39;&#39;&#39;
        Return the storage complexity of the SparseTensor.

        Returns
        -------
        int
            The storage complexity of the SparseTensor.

        &#39;&#39;&#39;
        return self.size

    def sparse_storage(self):
        &#39;&#39;&#39;
        Return the sparse storage complexity of the SparseTensor.

        Returns
        -------
        int
            The sparse storage complexity of the SparseTensor.

        &#39;&#39;&#39;
        return self.count_non_zero()

    def count_non_zero(self):
        &#39;&#39;&#39;
        Return the number of non-zero coefficients of the SparseTensor.
        Equivalent to self.sparse_storage().

        Returns
        -------
        int
            The number of non-zero coefficients of the SparseTensor.

        &#39;&#39;&#39;
        return self.indices.cardinal()

    @property
    def ndim(self):
        &#39;&#39;&#39;
        Compute the order of the tensor. Equivalent to self.order.

        Returns
        -------
        int
            The order of the tensor.

        &#39;&#39;&#39;
        return np.size(self.shape)

    def full(self):
        &#39;&#39;&#39;
        Convert the SparseTensor to a tensap.FullTensor.

        Returns
        -------
        y : tensap.FullTensor
            The SparseTensor as a tensap.FullTensor.

        &#39;&#39;&#39;
        y = tensap.FullTensor(np.zeros(self.shape))
        ind = tuple(self.indices.to_list())
        y.data[ind] = self.data
        return y

    def numpy(self):
        &#39;&#39;&#39;
        Convert the SparseTensor to a scipy.sparse.lil.lil_matrix, which can
        be converted to a numpy.matrix using the command todense().

        Returns
        -------
        y : scipy.sparse.lil.lil_matrix
            The SparseTensor as a scipy.sparse.lil.lil_matrix.

        &#39;&#39;&#39;
        assert self.ndim &lt;= 2, \
            &#39;nd sparse arrays are not allowed for d &gt; 2.&#39;

        y = lil_matrix(tuple(self.shape), dtype=float)
        ind = tuple(self.indices.to_list())
        y[ind] = self.data
        return y

    def eval_at_indices(self, ind, dims=None):
        &#39;&#39;&#39;
        Evaluate the tensor at indices.

        If dims is None, return
        s(k) = x(indices(k, 1), indices(k, 2), ..., indices(k, d)),
        1 &lt;= k &lt;= self.shape[0].

        If dims is not None, return a partial evaluation: up to a permutation
        (placing the dimensions dims on the left), return
        s(k, i_1, ..., i_d&#39;) = x(indices(k, 1), indices(k, 2), ...,
        indices(k, M), i_1, ..., i_d&#39;),
        1 &lt;= k &lt;= self.shape[0], with M = dims.size and d&#39; = self.order - M.

        Parameters
        ----------
        ind : list of numpy.ndarray
            The indices of the tensor.
        dims : list of numpy.ndarray, optional
            The dimensions associated with the indices. The default is None,
            indicating that indices refers to all the dimensions.

        Returns
        -------
        evaluations : scipy.sparse.lil.lil_matrix
            The evaluations of the tensor.

        &#39;&#39;&#39;
        assert dims is None or np.all(dims == np.arange(self.order)), \
            &#39;Method not implemented.&#39;

        if isinstance(ind, tensap.MultiIndices):
            ind = ind.array

        J = self.indices.array
        loc_J, loc_I = np.nonzero(np.all(ind == J[:, np.newaxis], axis=2))
        evaluations = lil_matrix((ind.shape[0], 1), dtype=float)
        evaluations[loc_I, 0] = self.data[loc_J]
        return evaluations

    def squeeze(self, dims):
        &#39;&#39;&#39;
        Remove the singleton dimensions of the tensor.

        Parameters
        ----------
        dims : list or numpy.ndarray, optional
            Dimensions to squeeze. The default is None, indicating all the
            singleton dimensions.

        Returns
        -------
        SparseTensor
            The squeezed tensor.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def __add__(self, y):
        ind = self.indices.add_indices(y.indices)
        _, rep_x, _ = ind.intersect_indices(self.indices)
        _, rep_y, _ = ind.intersect_indices(y.indices)
        data = np.zeros(ind.cardinal())
        data[rep_x] += self.data
        data[rep_y] += y.data
        return SparseTensor(data, ind, self.shape)

    def __neg__(self):
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def __sub__(self, y):
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def tensor_vector_product(self, vectors, dims=None):
        &#39;&#39;&#39;
        Compute the contraction of the tensor with vectors.

        Compute the contraction of self with each vector contained in the list
        vectors along dimensions specified by dims. The operation is such that
        V[k] is contracted with the dims[k]-th dimension of self.

        Parameters
        ----------
        vectors : numpy.ndarray or list of numpy.ndarray
            The vectors to use in the product.
        dims : list or numpy.ndarray, optional
            Indices of the contractions. The default is None, indicating all
            the dimensions.

        Returns
        -------
        out : SparseTensor
            The tensor after the contractions with the vectors.

        &#39;&#39;&#39;
        if dims is None:
            assert isinstance(vectors, list), &#39;vectors should be a list.&#39;
            assert len(vectors) == self.order, \
                &#39;len(vectors) must be self.order.&#39;
            dims = np.arange(self.order)
        else:
            dims = np.array(dims)
            if not isinstance(vectors, list):
                vectors = [vectors]
            assert len(vectors) == dims.size, \
                &#39;len(vectors) must be equal to dims.size.&#39;

        vectors = [np.ravel(x) for x in vectors]

        out = deepcopy(self)
        not_dims = np.setdiff1d(range(out.order), dims)
        if not_dims.size == 0:
            out.shape = []
        else:
            out.shape = out.shape[not_dims]

        for i in range(dims.size):
            a = out.data * vectors[i][out.indices.array[:, dims[i]]]

            out.indices.array = out.indices.array[:, np.setdiff1d(
                range(out.indices.array.shape[1]), dims[i])]
            out.indices.array = out.indices.array[a != 0, :]

            if out.indices.array.size != 0:
                out.indices.array, ind = np.unique(out.indices.array, axis=0,
                                                   return_inverse=True)

                a = a[a != 0]
                out.data = np.bincount(ind, weights=a)

            dims -= dims &gt; dims[i]

        out.order -= len(vectors)

        if np.size(out.shape) == 0:
            out = out.data

        return out

    def tensor_matrix_product(self, matrices, dims=None):
        &#39;&#39;&#39;
        Contract a tensor with matrices.

        The second dimension of the matrix matrices[k] is contracted with the
        k-th dimension of self, with the indices k given in dims (if provided).

        Parameters
        ----------
        matrices : numpy.ndarray or list of numpy.ndarray
            The matrices to use in the product.
        dims : list or numpy.ndarray, optional
            Indices of the contractions. The default is None, indicating all
            the dimensions.

        Returns
        -------
        out : SparseTensor
            The tensor after the contractions with the matrices.

        &#39;&#39;&#39;
        if dims is None:
            assert isinstance(matrices, (list, np.ndarray)), \
                &#39;matrices should be a list or a numpy.ndarray.&#39;
            assert len(matrices) == self.order, \
                &#39;len(matrices) must be self.order.&#39;
            dims = range(self.order)
        else:
            dims = np.atleast_1d(dims)
            if not isinstance(matrices, list):
                matrices = [matrices]
            assert len(matrices) == dims.size, \
                &#39;len(matrices) must be equal to dims.size.&#39;

        k = 0
        out = deepcopy(self)
        for mu in dims:
            perm_dims = np.concatenate(
                ([mu], np.setdiff1d(np.arange(out.order), mu)))
            out = out.transpose(perm_dims)
            if out.order == 1:
                out.shape[1] = 1
            ind = tensap.MultiIndices(
                out.indices.array[out.data != 0, :]).sub2ind(out.shape)
            x1, x2 = np.unravel_index(ind,
                                      [out.shape[0], np.prod(out.shape[1:])],
                                      order=&#39;F&#39;)
            x2u, x2uind = np.unique(x2, return_inverse=True)
            s = coo_matrix((out.data[out.data != 0],
                            (x1, x2uind)),
                           shape=(out.shape[0], np.max(x2uind)+1))
            a = np.transpose(s.transpose().dot(np.transpose(matrices[k])))
            y1, y2 = np.nonzero(a)
            out.shape[0] = matrices[k].shape[0]
            ind = np.ravel_multi_index((y1, np.reshape(x2u[y2], y1.shape)),
                                       (out.shape[0], np.prod(out.shape[1:])),
                                       order=&#39;F&#39;)
            out.indices = tensap.MultiIndices.ind2sub(out.shape, ind)
            out.data = np.ravel(a[a != 0])
            out = out.itranspose(perm_dims)
            k += 1
        return out

    def tensor_matrix_product_eval_diag(self, matrices):
        &#39;&#39;&#39;
        Evaluate the diagonal of a tensor obtained by contraction with
        matrices.

        Parameters
        ----------
        matrices : list
            The matrices to use in the product.

        Returns
        -------
        SparseTensor
            The diagonal of the contractions of the tensor with the matrices.

        &#39;&#39;&#39;
        y = matrices[0][:, self.indices.array[:, 0]]
        for k in np.arange(1, self.order):
            y *= matrices[k][:, self.indices.array[:, k]]
        return np.matmul(y, self.data)

    def transpose(self, dims):
        &#39;&#39;&#39;
        Transpose (permute) the dimensions of the tensor.

        Parameters
        ----------
        dims : list or numpy.ndarray
            The new ordering of the dimensions.

        Returns
        -------
        out : SparseTensor
            The transposed (permuted) tensor.

        &#39;&#39;&#39;
        out = deepcopy(self)
        out.indices.array = out.indices.array[:, dims]
        out.shape = out.shape[dims]
        return out

    def itranspose(self, dims):
        &#39;&#39;&#39;
        Return the inverse transpose (permutation) of the dimensions of the
        tensor.

        Parameters
        ----------
        dims : list or numpy.ndarray
            The original transpose (permutation) indices.

        Returns
        -------
        SparseTensor
            The transposed (permuted) tensor.

        &#39;&#39;&#39;
        out = deepcopy(self)
        return out.transpose(np.argsort(dims))

    def reshape(self, shape):
        &#39;&#39;&#39;
        Reshape the tensor.

        Parameters
        ----------
        shape : list or numpy.ndarray
            The new shape of the tensor.

        Returns
        -------
        tensor : SparseTensor
            The reshaped tensor.

        &#39;&#39;&#39;
        shape = np.array(shape)
        ind = self.indices.sub2ind(self.shape)
        out = deepcopy(self)
        out.indices = tensap.MultiIndices.ind2sub(shape, ind)
        out.shape = shape
        out.order = shape.size
        return out

    def tensor_diagonal_matrix_product(self, matrices, dims=None):
        &#39;&#39;&#39;
        Contract a SparseTensor with matrices built from their diagonals.

        The second dimension of the matrix matrices[k] is contracted with the
        k-th dimension of self, with the indices k given in dims (if provided).

        FIXME: not optimal, does not exploit sparsity.

        Parameters
        ----------
        matrices : numpy.ndarray or list of numpy.ndarray
            The diagonals of the matrices to use in the product.
        dims : list or numpy.ndarray, optional
            Indices of the contractions. The default is None, indicating all
            the dimensions.

        Returns
        -------
        SparseTensor
            The tensor after the contractions with the matrices.

        &#39;&#39;&#39;
        if not isinstance(matrices, list):
            matrices = [matrices[:, i] for i in range(np.shape(matrices)[1])]

        if dims is None:
            assert len(matrices) == self.order, \
                &#39;len(matrices) must be self.order.&#39;
            dims = range(self.order)
        else:
            dims = np.array(dims)
            assert len(matrices) == dims.size, \
                &#39;len(matrices) must be equal to dims.size.&#39;

        matrices = [tensap.FullTensor(np.diag(np.reshape(x, [-1])))
                    for x in matrices]
        return self.tensor_matrix_product(matrices, dims)

    def dot(self, y):
        &#39;&#39;&#39;
        Return the inner product of two tensors.

        Parameters
        ----------
        y : tensap.Tensor
            The second tensor of the inner products. Must be convertible to
            a SparseTensor.

        Returns
        -------
        numpy.float
            The inner product of the two tensors.

        &#39;&#39;&#39;
        if not isinstance(y, SparseTensor):
            try:
                y = y.sparse()
            except Exception:
                raise ValueError(&#39;Cannot convert input to SparseTensor.&#39;)

        _, ind_x, ind_y = self.indices.intersect_indices(y.indices)
        return np.sum(self.data[ind_x] * y.data[ind_y])

    def __mul__(self, y):
        if not isinstance(y, SparseTensor):
            try:
                y = y.sparse()
            except Exception:
                raise ValueError(&#39;Cannot convert input to SparseTensor.&#39;)

        _, ind_x, ind_y = self.indices.intersect_indices(y.indices)
        out = deepcopy(self)
        out.data = self.data[ind_x] * y.data[ind_y]
        out.indices.array = self.indices.array[ind_x, :]
        return out

    def norm(self):
        &#39;&#39;&#39;
        Compute the canonical norm of the SparseTensor.

        Returns
        -------
        numpy.float
            The norm of the tensor.

        &#39;&#39;&#39;
        return np.sqrt(self.dot(self))

    def orth(self, dim):
        &#39;&#39;&#39;
        Orthogonalize the tensor.

        Parameters
        ----------
        dim : int
            The dimension of the orthogonal dim-matricization of self.

        Returns
        -------
        SparseTensor
            A tensor whose dim-matricization is an orthogonal matrix
            corresponding to the Q factor of a QR factorization of the
            dim-matricization of self.
        r_matrix : numpy.ndarray
            The R factor.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def cat(self, y, dims):
        &#39;&#39;&#39;
        Concatenate the tensors.

        Concatenates self and y in a tensor z such that:
        z(i_1 ,..., i_d) = x(i_1, ..., i_d) if i_k &lt;= sz[k]-1 for k in dims,
        z(i_1, ..., i_d) = y(i_1-sz[0], ..., i_d-sz[d-1]) if i_k &gt;= sz[k]
        for k in dims,
        z(i_1, ..., i_d) = 0 otherwise, with sz = self.shape and
        dims = range(self.order) if not provided.

        Parameters
        ----------
        y : Tensor
            The second tensor to be concatenaed.
        dims : list or numpy.ndarray, optional
            The dimensions of the concatenation. The default is None,
            indicating all the dimensions.
        Returns
        -------
        SparseTensor
            The concatenated tensors.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def kron(self, y):
        &#39;&#39;&#39;
        Kronecker product of tensors.

        Similar to numpy.kron but for sparse tensors.

        Parameters
        ----------
        y : Tensor
            The second tensor of the Kronecker product.

        Returns
        -------
        SparseTensor
            The tensor resulting from the Kronecker product.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def dot_with_rank_one_metric(self, y, M):
        &#39;&#39;&#39;
        Compute the weighted inner product of two tensors.

        Compute the weighted canonical inner product of self and y,
        where the inner product related to dimension k is weighted by
        M[k]. It is equivalent to
        self.dot(y.tensor_matrix_product(M)),
        but can be much faster.

        Parameters
        ----------
        y : Tensor
            The second tensor of the inner product.
        M : list or numpy.ndarray or FullTensor
            The weight matrix.

        Returns
        -------
        numpy.float
            The weighted inner product.

        &#39;&#39;&#39;
        s = y.tensor_matrix_product(M)
        return self.dot(s)

    def tensordot_matrix_product_except_dim(self, y, M, dim):
        &#39;&#39;&#39;
        Particular type of contraction.

        Compute a special contraction of two tensors self, y, a list of
        matrices M and a particular dimension dim. Note that dim must
        be a scalar, while M must be a list array with x.self.order
        elements.

        Parameters
        ----------
        y : Tensor
            The second tensor of the contraction.
        M : list
            The list of matrices of the contraction.
        dim : int
            The excluded dimension.

        Returns
        -------
        numpy.ndarray
            The result of the contraction.

        &#39;&#39;&#39;
        # dims = np.setdiff1d(np.arange(self.order), dim)
        # s = y.tensor_matrix_product(M[dims], dims)
        # return self.tensordot(s, dims, dims)
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def eval_diag(self, dims=None):
        &#39;&#39;&#39;
        Extract the diagonal of the tensor.

        The tensor must be such that self.shape[mu] = n for all mu (in dims if
        provided).

        Parameters
        ----------
        dims : list of numpy.ndarray, optional
            The dimensions associated with the indices of the diagonal. The
            default is None,indicating that indices refers to all the
            dimensions.

        Returns
        -------
        data : numpy.ndarray
            The evaluations of the diagonal of the tensor.

        &#39;&#39;&#39;
        if dims is None:
            dims = np.arange(self.order)
        else:
            dims = np.atleast_1d(dims)

        if dims.size == 1:
            data = self
        else:
            assert np.all([self.shape[x] == self.shape[dims[0]] for
                           x in dims]),\
             &#39;The shapes of the tensor in dimensions dims should be equal.&#39;
            ind = np.repeat(np.reshape(np.arange(self.shape[0]), [-1, 1]),
                            dims.size, 1)
            data = self.eval_at_indices(ind, dims)
        return data

    def sub_tensor(self, *indices):
        &#39;&#39;&#39;
        Extract a subtensor of the tensor.

        The result is a tensor s of shape
        len(indices[0]), ..., len(indices[self.order-1]),
        such that
        s(k1,...,kd) = x(indices[0][k1], ..., indices[self.order-1][kd]).

        Example: x.subTensor([1, 2], &#39;:&#39;, [2, 5, 6]) returns a tensor with
        shape [2, self.shape[1], 3].

        Parameters
        ----------
        *indices : list
            The indices to extract in each dimension. &#39;:&#39; indicates all the
            indices.

        Returns
        -------
        SparseTensor
            The subtensor.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;Method not implemented.&#39;)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.ndim"><code class="name">var <span class="ident">ndim</span></code></dt>
<dd>
<div class="desc"><p>Compute the order of the tensor. Equivalent to self.order.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The order of the tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def ndim(self):
    &#39;&#39;&#39;
    Compute the order of the tensor. Equivalent to self.order.

    Returns
    -------
    int
        The order of the tensor.

    &#39;&#39;&#39;
    return np.size(self.shape)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.size"><code class="name">var <span class="ident">size</span></code></dt>
<dd>
<div class="desc"><p>Compute the size of the tensor. Equivalent to self.storage().</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The size of the tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def size(self):
    &#39;&#39;&#39;
    Compute the size of the tensor. Equivalent to self.storage().

    Returns
    -------
    numpy.ndarray
        The size of the tensor.

    &#39;&#39;&#39;
    return np.prod(self.shape)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.cat"><code class="name flex">
<span>def <span class="ident">cat</span></span>(<span>self, y, dims)</span>
</code></dt>
<dd>
<div class="desc"><p>Concatenate the tensors.</p>
<p>Concatenates self and y in a tensor z such that:
z(i_1 ,&hellip;, i_d) = x(i_1, &hellip;, i_d) if i_k &lt;= sz[k]-1 for k in dims,
z(i_1, &hellip;, i_d) = y(i_1-sz[0], &hellip;, i_d-sz[d-1]) if i_k &gt;= sz[k]
for k in dims,
z(i_1, &hellip;, i_d) = 0 otherwise, with sz = self.shape and
dims = range(self.order) if not provided.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>The second tensor to be concatenaed.</dd>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>The dimensions of the concatenation. The default is None,
indicating all the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor">SparseTensor</a></code></dt>
<dd>The concatenated tensors.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cat(self, y, dims):
    &#39;&#39;&#39;
    Concatenate the tensors.

    Concatenates self and y in a tensor z such that:
    z(i_1 ,..., i_d) = x(i_1, ..., i_d) if i_k &lt;= sz[k]-1 for k in dims,
    z(i_1, ..., i_d) = y(i_1-sz[0], ..., i_d-sz[d-1]) if i_k &gt;= sz[k]
    for k in dims,
    z(i_1, ..., i_d) = 0 otherwise, with sz = self.shape and
    dims = range(self.order) if not provided.

    Parameters
    ----------
    y : Tensor
        The second tensor to be concatenaed.
    dims : list or numpy.ndarray, optional
        The dimensions of the concatenation. The default is None,
        indicating all the dimensions.
    Returns
    -------
    SparseTensor
        The concatenated tensors.

    &#39;&#39;&#39;
    raise NotImplementedError(&#39;Method not implemented.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.count_non_zero"><code class="name flex">
<span>def <span class="ident">count_non_zero</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the number of non-zero coefficients of the SparseTensor.
Equivalent to self.sparse_storage().</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The number of non-zero coefficients of the SparseTensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count_non_zero(self):
    &#39;&#39;&#39;
    Return the number of non-zero coefficients of the SparseTensor.
    Equivalent to self.sparse_storage().

    Returns
    -------
    int
        The number of non-zero coefficients of the SparseTensor.

    &#39;&#39;&#39;
    return self.indices.cardinal()</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.dot"><code class="name flex">
<span>def <span class="ident">dot</span></span>(<span>self, y)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the inner product of two tensors.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>tensap.Tensor</code></dt>
<dd>The second tensor of the inner products. Must be convertible to
a SparseTensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.float</code></dt>
<dd>The inner product of the two tensors.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dot(self, y):
    &#39;&#39;&#39;
    Return the inner product of two tensors.

    Parameters
    ----------
    y : tensap.Tensor
        The second tensor of the inner products. Must be convertible to
        a SparseTensor.

    Returns
    -------
    numpy.float
        The inner product of the two tensors.

    &#39;&#39;&#39;
    if not isinstance(y, SparseTensor):
        try:
            y = y.sparse()
        except Exception:
            raise ValueError(&#39;Cannot convert input to SparseTensor.&#39;)

    _, ind_x, ind_y = self.indices.intersect_indices(y.indices)
    return np.sum(self.data[ind_x] * y.data[ind_y])</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.dot_with_rank_one_metric"><code class="name flex">
<span>def <span class="ident">dot_with_rank_one_metric</span></span>(<span>self, y, M)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the weighted inner product of two tensors.</p>
<p>Compute the weighted canonical inner product of self and y,
where the inner product related to dimension k is weighted by
M[k]. It is equivalent to
self.dot(y.tensor_matrix_product(M)),
but can be much faster.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>The second tensor of the inner product.</dd>
<dt><strong><code>M</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code> or <code>FullTensor</code></dt>
<dd>The weight matrix.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.float</code></dt>
<dd>The weighted inner product.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dot_with_rank_one_metric(self, y, M):
    &#39;&#39;&#39;
    Compute the weighted inner product of two tensors.

    Compute the weighted canonical inner product of self and y,
    where the inner product related to dimension k is weighted by
    M[k]. It is equivalent to
    self.dot(y.tensor_matrix_product(M)),
    but can be much faster.

    Parameters
    ----------
    y : Tensor
        The second tensor of the inner product.
    M : list or numpy.ndarray or FullTensor
        The weight matrix.

    Returns
    -------
    numpy.float
        The weighted inner product.

    &#39;&#39;&#39;
    s = y.tensor_matrix_product(M)
    return self.dot(s)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.eval_at_indices"><code class="name flex">
<span>def <span class="ident">eval_at_indices</span></span>(<span>self, ind, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate the tensor at indices.</p>
<p>If dims is None, return
s(k) = x(indices(k, 1), indices(k, 2), &hellip;, indices(k, d)),
1 &lt;= k &lt;= self.shape[0].</p>
<p>If dims is not None, return a partial evaluation: up to a permutation
(placing the dimensions dims on the left), return
s(k, i_1, &hellip;, i_d') = x(indices(k, 1), indices(k, 2), &hellip;,
indices(k, M), i_1, &hellip;, i_d'),
1 &lt;= k &lt;= self.shape[0], with M = dims.size and d' = self.order - M.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ind</code></strong> :&ensp;<code>list</code> of <code>numpy.ndarray</code></dt>
<dd>The indices of the tensor.</dd>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> of <code>numpy.ndarray</code>, optional</dt>
<dd>The dimensions associated with the indices. The default is None,
indicating that indices refers to all the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>evaluations</code></strong> :&ensp;<code>scipy.sparse.lil.lil_matrix</code></dt>
<dd>The evaluations of the tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval_at_indices(self, ind, dims=None):
    &#39;&#39;&#39;
    Evaluate the tensor at indices.

    If dims is None, return
    s(k) = x(indices(k, 1), indices(k, 2), ..., indices(k, d)),
    1 &lt;= k &lt;= self.shape[0].

    If dims is not None, return a partial evaluation: up to a permutation
    (placing the dimensions dims on the left), return
    s(k, i_1, ..., i_d&#39;) = x(indices(k, 1), indices(k, 2), ...,
    indices(k, M), i_1, ..., i_d&#39;),
    1 &lt;= k &lt;= self.shape[0], with M = dims.size and d&#39; = self.order - M.

    Parameters
    ----------
    ind : list of numpy.ndarray
        The indices of the tensor.
    dims : list of numpy.ndarray, optional
        The dimensions associated with the indices. The default is None,
        indicating that indices refers to all the dimensions.

    Returns
    -------
    evaluations : scipy.sparse.lil.lil_matrix
        The evaluations of the tensor.

    &#39;&#39;&#39;
    assert dims is None or np.all(dims == np.arange(self.order)), \
        &#39;Method not implemented.&#39;

    if isinstance(ind, tensap.MultiIndices):
        ind = ind.array

    J = self.indices.array
    loc_J, loc_I = np.nonzero(np.all(ind == J[:, np.newaxis], axis=2))
    evaluations = lil_matrix((ind.shape[0], 1), dtype=float)
    evaluations[loc_I, 0] = self.data[loc_J]
    return evaluations</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.eval_diag"><code class="name flex">
<span>def <span class="ident">eval_diag</span></span>(<span>self, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Extract the diagonal of the tensor.</p>
<p>The tensor must be such that self.shape[mu] = n for all mu (in dims if
provided).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> of <code>numpy.ndarray</code>, optional</dt>
<dd>The dimensions associated with the indices of the diagonal. The
default is None,indicating that indices refers to all the
dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The evaluations of the diagonal of the tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval_diag(self, dims=None):
    &#39;&#39;&#39;
    Extract the diagonal of the tensor.

    The tensor must be such that self.shape[mu] = n for all mu (in dims if
    provided).

    Parameters
    ----------
    dims : list of numpy.ndarray, optional
        The dimensions associated with the indices of the diagonal. The
        default is None,indicating that indices refers to all the
        dimensions.

    Returns
    -------
    data : numpy.ndarray
        The evaluations of the diagonal of the tensor.

    &#39;&#39;&#39;
    if dims is None:
        dims = np.arange(self.order)
    else:
        dims = np.atleast_1d(dims)

    if dims.size == 1:
        data = self
    else:
        assert np.all([self.shape[x] == self.shape[dims[0]] for
                       x in dims]),\
         &#39;The shapes of the tensor in dimensions dims should be equal.&#39;
        ind = np.repeat(np.reshape(np.arange(self.shape[0]), [-1, 1]),
                        dims.size, 1)
        data = self.eval_at_indices(ind, dims)
    return data</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.full"><code class="name flex">
<span>def <span class="ident">full</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert the SparseTensor to a tensap.FullTensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>tensap.FullTensor</code></dt>
<dd>The SparseTensor as a tensap.FullTensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def full(self):
    &#39;&#39;&#39;
    Convert the SparseTensor to a tensap.FullTensor.

    Returns
    -------
    y : tensap.FullTensor
        The SparseTensor as a tensap.FullTensor.

    &#39;&#39;&#39;
    y = tensap.FullTensor(np.zeros(self.shape))
    ind = tuple(self.indices.to_list())
    y.data[ind] = self.data
    return y</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.itranspose"><code class="name flex">
<span>def <span class="ident">itranspose</span></span>(<span>self, dims)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the inverse transpose (permutation) of the dimensions of the
tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The original transpose (permutation) indices.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor">SparseTensor</a></code></dt>
<dd>The transposed (permuted) tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def itranspose(self, dims):
    &#39;&#39;&#39;
    Return the inverse transpose (permutation) of the dimensions of the
    tensor.

    Parameters
    ----------
    dims : list or numpy.ndarray
        The original transpose (permutation) indices.

    Returns
    -------
    SparseTensor
        The transposed (permuted) tensor.

    &#39;&#39;&#39;
    out = deepcopy(self)
    return out.transpose(np.argsort(dims))</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.kron"><code class="name flex">
<span>def <span class="ident">kron</span></span>(<span>self, y)</span>
</code></dt>
<dd>
<div class="desc"><p>Kronecker product of tensors.</p>
<p>Similar to numpy.kron but for sparse tensors.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>The second tensor of the Kronecker product.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor">SparseTensor</a></code></dt>
<dd>The tensor resulting from the Kronecker product.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def kron(self, y):
    &#39;&#39;&#39;
    Kronecker product of tensors.

    Similar to numpy.kron but for sparse tensors.

    Parameters
    ----------
    y : Tensor
        The second tensor of the Kronecker product.

    Returns
    -------
    SparseTensor
        The tensor resulting from the Kronecker product.

    &#39;&#39;&#39;
    raise NotImplementedError(&#39;Method not implemented.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.norm"><code class="name flex">
<span>def <span class="ident">norm</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the canonical norm of the SparseTensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.float</code></dt>
<dd>The norm of the tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def norm(self):
    &#39;&#39;&#39;
    Compute the canonical norm of the SparseTensor.

    Returns
    -------
    numpy.float
        The norm of the tensor.

    &#39;&#39;&#39;
    return np.sqrt(self.dot(self))</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.numpy"><code class="name flex">
<span>def <span class="ident">numpy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert the SparseTensor to a scipy.sparse.lil.lil_matrix, which can
be converted to a numpy.matrix using the command todense().</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>scipy.sparse.lil.lil_matrix</code></dt>
<dd>The SparseTensor as a scipy.sparse.lil.lil_matrix.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def numpy(self):
    &#39;&#39;&#39;
    Convert the SparseTensor to a scipy.sparse.lil.lil_matrix, which can
    be converted to a numpy.matrix using the command todense().

    Returns
    -------
    y : scipy.sparse.lil.lil_matrix
        The SparseTensor as a scipy.sparse.lil.lil_matrix.

    &#39;&#39;&#39;
    assert self.ndim &lt;= 2, \
        &#39;nd sparse arrays are not allowed for d &gt; 2.&#39;

    y = lil_matrix(tuple(self.shape), dtype=float)
    ind = tuple(self.indices.to_list())
    y[ind] = self.data
    return y</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.orth"><code class="name flex">
<span>def <span class="ident">orth</span></span>(<span>self, dim)</span>
</code></dt>
<dd>
<div class="desc"><p>Orthogonalize the tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dim</code></strong> :&ensp;<code>int</code></dt>
<dd>The dimension of the orthogonal dim-matricization of self.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor">SparseTensor</a></code></dt>
<dd>A tensor whose dim-matricization is an orthogonal matrix
corresponding to the Q factor of a QR factorization of the
dim-matricization of self.</dd>
<dt><strong><code>r_matrix</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The R factor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def orth(self, dim):
    &#39;&#39;&#39;
    Orthogonalize the tensor.

    Parameters
    ----------
    dim : int
        The dimension of the orthogonal dim-matricization of self.

    Returns
    -------
    SparseTensor
        A tensor whose dim-matricization is an orthogonal matrix
        corresponding to the Q factor of a QR factorization of the
        dim-matricization of self.
    r_matrix : numpy.ndarray
        The R factor.

    &#39;&#39;&#39;
    raise NotImplementedError(&#39;Method not implemented.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.reshape"><code class="name flex">
<span>def <span class="ident">reshape</span></span>(<span>self, shape)</span>
</code></dt>
<dd>
<div class="desc"><p>Reshape the tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>shape</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The new shape of the tensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tensor</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor">SparseTensor</a></code></dt>
<dd>The reshaped tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reshape(self, shape):
    &#39;&#39;&#39;
    Reshape the tensor.

    Parameters
    ----------
    shape : list or numpy.ndarray
        The new shape of the tensor.

    Returns
    -------
    tensor : SparseTensor
        The reshaped tensor.

    &#39;&#39;&#39;
    shape = np.array(shape)
    ind = self.indices.sub2ind(self.shape)
    out = deepcopy(self)
    out.indices = tensap.MultiIndices.ind2sub(shape, ind)
    out.shape = shape
    out.order = shape.size
    return out</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.sparse_storage"><code class="name flex">
<span>def <span class="ident">sparse_storage</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the sparse storage complexity of the SparseTensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The sparse storage complexity of the SparseTensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sparse_storage(self):
    &#39;&#39;&#39;
    Return the sparse storage complexity of the SparseTensor.

    Returns
    -------
    int
        The sparse storage complexity of the SparseTensor.

    &#39;&#39;&#39;
    return self.count_non_zero()</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.squeeze"><code class="name flex">
<span>def <span class="ident">squeeze</span></span>(<span>self, dims)</span>
</code></dt>
<dd>
<div class="desc"><p>Remove the singleton dimensions of the tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>Dimensions to squeeze. The default is None, indicating all the
singleton dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor">SparseTensor</a></code></dt>
<dd>The squeezed tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def squeeze(self, dims):
    &#39;&#39;&#39;
    Remove the singleton dimensions of the tensor.

    Parameters
    ----------
    dims : list or numpy.ndarray, optional
        Dimensions to squeeze. The default is None, indicating all the
        singleton dimensions.

    Returns
    -------
    SparseTensor
        The squeezed tensor.

    &#39;&#39;&#39;
    raise NotImplementedError(&#39;Method not implemented.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.storage"><code class="name flex">
<span>def <span class="ident">storage</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the storage complexity of the SparseTensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The storage complexity of the SparseTensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def storage(self):
    &#39;&#39;&#39;
    Return the storage complexity of the SparseTensor.

    Returns
    -------
    int
        The storage complexity of the SparseTensor.

    &#39;&#39;&#39;
    return self.size</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.sub_tensor"><code class="name flex">
<span>def <span class="ident">sub_tensor</span></span>(<span>self, *indices)</span>
</code></dt>
<dd>
<div class="desc"><p>Extract a subtensor of the tensor.</p>
<p>The result is a tensor s of shape
len(indices[0]), &hellip;, len(indices[self.order-1]),
such that
s(k1,&hellip;,kd) = x(indices[0][k1], &hellip;, indices[self.order-1][kd]).</p>
<p>Example: x.subTensor([1, 2], ':', [2, 5, 6]) returns a tensor with
shape [2, self.shape[1], 3].</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>*indices</code></strong> :&ensp;<code>list</code></dt>
<dd>The indices to extract in each dimension. ':' indicates all the
indices.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor">SparseTensor</a></code></dt>
<dd>The subtensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sub_tensor(self, *indices):
    &#39;&#39;&#39;
    Extract a subtensor of the tensor.

    The result is a tensor s of shape
    len(indices[0]), ..., len(indices[self.order-1]),
    such that
    s(k1,...,kd) = x(indices[0][k1], ..., indices[self.order-1][kd]).

    Example: x.subTensor([1, 2], &#39;:&#39;, [2, 5, 6]) returns a tensor with
    shape [2, self.shape[1], 3].

    Parameters
    ----------
    *indices : list
        The indices to extract in each dimension. &#39;:&#39; indicates all the
        indices.

    Returns
    -------
    SparseTensor
        The subtensor.

    &#39;&#39;&#39;
    raise NotImplementedError(&#39;Method not implemented.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensor_diagonal_matrix_product"><code class="name flex">
<span>def <span class="ident">tensor_diagonal_matrix_product</span></span>(<span>self, matrices, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Contract a SparseTensor with matrices built from their diagonals.</p>
<p>The second dimension of the matrix matrices[k] is contracted with the
k-th dimension of self, with the indices k given in dims (if provided).</p>
<p>FIXME: not optimal, does not exploit sparsity.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>matrices</code></strong> :&ensp;<code>numpy.ndarray</code> or <code>list</code> of <code>numpy.ndarray</code></dt>
<dd>The diagonals of the matrices to use in the product.</dd>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>Indices of the contractions. The default is None, indicating all
the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor">SparseTensor</a></code></dt>
<dd>The tensor after the contractions with the matrices.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensor_diagonal_matrix_product(self, matrices, dims=None):
    &#39;&#39;&#39;
    Contract a SparseTensor with matrices built from their diagonals.

    The second dimension of the matrix matrices[k] is contracted with the
    k-th dimension of self, with the indices k given in dims (if provided).

    FIXME: not optimal, does not exploit sparsity.

    Parameters
    ----------
    matrices : numpy.ndarray or list of numpy.ndarray
        The diagonals of the matrices to use in the product.
    dims : list or numpy.ndarray, optional
        Indices of the contractions. The default is None, indicating all
        the dimensions.

    Returns
    -------
    SparseTensor
        The tensor after the contractions with the matrices.

    &#39;&#39;&#39;
    if not isinstance(matrices, list):
        matrices = [matrices[:, i] for i in range(np.shape(matrices)[1])]

    if dims is None:
        assert len(matrices) == self.order, \
            &#39;len(matrices) must be self.order.&#39;
        dims = range(self.order)
    else:
        dims = np.array(dims)
        assert len(matrices) == dims.size, \
            &#39;len(matrices) must be equal to dims.size.&#39;

    matrices = [tensap.FullTensor(np.diag(np.reshape(x, [-1])))
                for x in matrices]
    return self.tensor_matrix_product(matrices, dims)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensor_matrix_product"><code class="name flex">
<span>def <span class="ident">tensor_matrix_product</span></span>(<span>self, matrices, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Contract a tensor with matrices.</p>
<p>The second dimension of the matrix matrices[k] is contracted with the
k-th dimension of self, with the indices k given in dims (if provided).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>matrices</code></strong> :&ensp;<code>numpy.ndarray</code> or <code>list</code> of <code>numpy.ndarray</code></dt>
<dd>The matrices to use in the product.</dd>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>Indices of the contractions. The default is None, indicating all
the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>out</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor">SparseTensor</a></code></dt>
<dd>The tensor after the contractions with the matrices.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensor_matrix_product(self, matrices, dims=None):
    &#39;&#39;&#39;
    Contract a tensor with matrices.

    The second dimension of the matrix matrices[k] is contracted with the
    k-th dimension of self, with the indices k given in dims (if provided).

    Parameters
    ----------
    matrices : numpy.ndarray or list of numpy.ndarray
        The matrices to use in the product.
    dims : list or numpy.ndarray, optional
        Indices of the contractions. The default is None, indicating all
        the dimensions.

    Returns
    -------
    out : SparseTensor
        The tensor after the contractions with the matrices.

    &#39;&#39;&#39;
    if dims is None:
        assert isinstance(matrices, (list, np.ndarray)), \
            &#39;matrices should be a list or a numpy.ndarray.&#39;
        assert len(matrices) == self.order, \
            &#39;len(matrices) must be self.order.&#39;
        dims = range(self.order)
    else:
        dims = np.atleast_1d(dims)
        if not isinstance(matrices, list):
            matrices = [matrices]
        assert len(matrices) == dims.size, \
            &#39;len(matrices) must be equal to dims.size.&#39;

    k = 0
    out = deepcopy(self)
    for mu in dims:
        perm_dims = np.concatenate(
            ([mu], np.setdiff1d(np.arange(out.order), mu)))
        out = out.transpose(perm_dims)
        if out.order == 1:
            out.shape[1] = 1
        ind = tensap.MultiIndices(
            out.indices.array[out.data != 0, :]).sub2ind(out.shape)
        x1, x2 = np.unravel_index(ind,
                                  [out.shape[0], np.prod(out.shape[1:])],
                                  order=&#39;F&#39;)
        x2u, x2uind = np.unique(x2, return_inverse=True)
        s = coo_matrix((out.data[out.data != 0],
                        (x1, x2uind)),
                       shape=(out.shape[0], np.max(x2uind)+1))
        a = np.transpose(s.transpose().dot(np.transpose(matrices[k])))
        y1, y2 = np.nonzero(a)
        out.shape[0] = matrices[k].shape[0]
        ind = np.ravel_multi_index((y1, np.reshape(x2u[y2], y1.shape)),
                                   (out.shape[0], np.prod(out.shape[1:])),
                                   order=&#39;F&#39;)
        out.indices = tensap.MultiIndices.ind2sub(out.shape, ind)
        out.data = np.ravel(a[a != 0])
        out = out.itranspose(perm_dims)
        k += 1
    return out</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensor_matrix_product_eval_diag"><code class="name flex">
<span>def <span class="ident">tensor_matrix_product_eval_diag</span></span>(<span>self, matrices)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate the diagonal of a tensor obtained by contraction with
matrices.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>matrices</code></strong> :&ensp;<code>list</code></dt>
<dd>The matrices to use in the product.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor">SparseTensor</a></code></dt>
<dd>The diagonal of the contractions of the tensor with the matrices.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensor_matrix_product_eval_diag(self, matrices):
    &#39;&#39;&#39;
    Evaluate the diagonal of a tensor obtained by contraction with
    matrices.

    Parameters
    ----------
    matrices : list
        The matrices to use in the product.

    Returns
    -------
    SparseTensor
        The diagonal of the contractions of the tensor with the matrices.

    &#39;&#39;&#39;
    y = matrices[0][:, self.indices.array[:, 0]]
    for k in np.arange(1, self.order):
        y *= matrices[k][:, self.indices.array[:, k]]
    return np.matmul(y, self.data)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensor_vector_product"><code class="name flex">
<span>def <span class="ident">tensor_vector_product</span></span>(<span>self, vectors, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the contraction of the tensor with vectors.</p>
<p>Compute the contraction of self with each vector contained in the list
vectors along dimensions specified by dims. The operation is such that
V[k] is contracted with the dims[k]-th dimension of self.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>vectors</code></strong> :&ensp;<code>numpy.ndarray</code> or <code>list</code> of <code>numpy.ndarray</code></dt>
<dd>The vectors to use in the product.</dd>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>Indices of the contractions. The default is None, indicating all
the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>out</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor">SparseTensor</a></code></dt>
<dd>The tensor after the contractions with the vectors.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensor_vector_product(self, vectors, dims=None):
    &#39;&#39;&#39;
    Compute the contraction of the tensor with vectors.

    Compute the contraction of self with each vector contained in the list
    vectors along dimensions specified by dims. The operation is such that
    V[k] is contracted with the dims[k]-th dimension of self.

    Parameters
    ----------
    vectors : numpy.ndarray or list of numpy.ndarray
        The vectors to use in the product.
    dims : list or numpy.ndarray, optional
        Indices of the contractions. The default is None, indicating all
        the dimensions.

    Returns
    -------
    out : SparseTensor
        The tensor after the contractions with the vectors.

    &#39;&#39;&#39;
    if dims is None:
        assert isinstance(vectors, list), &#39;vectors should be a list.&#39;
        assert len(vectors) == self.order, \
            &#39;len(vectors) must be self.order.&#39;
        dims = np.arange(self.order)
    else:
        dims = np.array(dims)
        if not isinstance(vectors, list):
            vectors = [vectors]
        assert len(vectors) == dims.size, \
            &#39;len(vectors) must be equal to dims.size.&#39;

    vectors = [np.ravel(x) for x in vectors]

    out = deepcopy(self)
    not_dims = np.setdiff1d(range(out.order), dims)
    if not_dims.size == 0:
        out.shape = []
    else:
        out.shape = out.shape[not_dims]

    for i in range(dims.size):
        a = out.data * vectors[i][out.indices.array[:, dims[i]]]

        out.indices.array = out.indices.array[:, np.setdiff1d(
            range(out.indices.array.shape[1]), dims[i])]
        out.indices.array = out.indices.array[a != 0, :]

        if out.indices.array.size != 0:
            out.indices.array, ind = np.unique(out.indices.array, axis=0,
                                               return_inverse=True)

            a = a[a != 0]
            out.data = np.bincount(ind, weights=a)

        dims -= dims &gt; dims[i]

    out.order -= len(vectors)

    if np.size(out.shape) == 0:
        out = out.data

    return out</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensordot_matrix_product_except_dim"><code class="name flex">
<span>def <span class="ident">tensordot_matrix_product_except_dim</span></span>(<span>self, y, M, dim)</span>
</code></dt>
<dd>
<div class="desc"><p>Particular type of contraction.</p>
<p>Compute a special contraction of two tensors self, y, a list of
matrices M and a particular dimension dim. Note that dim must
be a scalar, while M must be a list array with x.self.order
elements.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>The second tensor of the contraction.</dd>
<dt><strong><code>M</code></strong> :&ensp;<code>list</code></dt>
<dd>The list of matrices of the contraction.</dd>
<dt><strong><code>dim</code></strong> :&ensp;<code>int</code></dt>
<dd>The excluded dimension.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The result of the contraction.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensordot_matrix_product_except_dim(self, y, M, dim):
    &#39;&#39;&#39;
    Particular type of contraction.

    Compute a special contraction of two tensors self, y, a list of
    matrices M and a particular dimension dim. Note that dim must
    be a scalar, while M must be a list array with x.self.order
    elements.

    Parameters
    ----------
    y : Tensor
        The second tensor of the contraction.
    M : list
        The list of matrices of the contraction.
    dim : int
        The excluded dimension.

    Returns
    -------
    numpy.ndarray
        The result of the contraction.

    &#39;&#39;&#39;
    # dims = np.setdiff1d(np.arange(self.order), dim)
    # s = y.tensor_matrix_product(M[dims], dims)
    # return self.tensordot(s, dims, dims)
    raise NotImplementedError(&#39;Method not implemented.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.transpose"><code class="name flex">
<span>def <span class="ident">transpose</span></span>(<span>self, dims)</span>
</code></dt>
<dd>
<div class="desc"><p>Transpose (permute) the dimensions of the tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The new ordering of the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>out</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor">SparseTensor</a></code></dt>
<dd>The transposed (permuted) tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transpose(self, dims):
    &#39;&#39;&#39;
    Transpose (permute) the dimensions of the tensor.

    Parameters
    ----------
    dims : list or numpy.ndarray
        The new ordering of the dimensions.

    Returns
    -------
    out : SparseTensor
        The transposed (permuted) tensor.

    &#39;&#39;&#39;
    out = deepcopy(self)
    out.indices.array = out.indices.array[:, dims]
    out.shape = out.shape[dims]
    return out</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tensap.tensor_algebra.tensors" href="index.html">tensap.tensor_algebra.tensors</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor">SparseTensor</a></code></h4>
<ul class="">
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.cat" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.cat">cat</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.count_non_zero" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.count_non_zero">count_non_zero</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.dot" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.dot">dot</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.dot_with_rank_one_metric" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.dot_with_rank_one_metric">dot_with_rank_one_metric</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.eval_at_indices" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.eval_at_indices">eval_at_indices</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.eval_diag" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.eval_diag">eval_diag</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.full" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.full">full</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.itranspose" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.itranspose">itranspose</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.kron" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.kron">kron</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.ndim" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.ndim">ndim</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.norm" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.norm">norm</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.numpy" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.numpy">numpy</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.orth" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.orth">orth</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.reshape" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.reshape">reshape</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.size" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.size">size</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.sparse_storage" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.sparse_storage">sparse_storage</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.squeeze" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.squeeze">squeeze</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.storage" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.storage">storage</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.sub_tensor" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.sub_tensor">sub_tensor</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensor_diagonal_matrix_product" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensor_diagonal_matrix_product">tensor_diagonal_matrix_product</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensor_matrix_product" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensor_matrix_product">tensor_matrix_product</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensor_matrix_product_eval_diag" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensor_matrix_product_eval_diag">tensor_matrix_product_eval_diag</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensor_vector_product" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensor_vector_product">tensor_vector_product</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensordot_matrix_product_except_dim" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.tensordot_matrix_product_except_dim">tensordot_matrix_product_except_dim</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.transpose" href="#tensap.tensor_algebra.tensors.sparse_tensor.SparseTensor.transpose">transpose</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>
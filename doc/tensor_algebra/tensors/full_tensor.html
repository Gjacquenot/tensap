<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>tensap.tensor_algebra.tensors.full_tensor API documentation</title>
<meta name="description" content="Module full_tensor â€¦" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tensap.tensor_algebra.tensors.full_tensor</code></h1>
</header>
<section id="section-intro">
<p>Module full_tensor.</p>
<p>Copyright (c) 2020, Anthony Nouy, Erwan Grelier
This file is part of tensap (tensor approximation package).</p>
<p>tensap is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.</p>
<p>tensap is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
See the
GNU Lesser General Public License for more details.</p>
<p>You should have received a copy of the GNU Lesser General Public License
along with tensap.
If not, see <a href="https://www.gnu.org/licenses/">https://www.gnu.org/licenses/</a>.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;
Module full_tensor.

Copyright (c) 2020, Anthony Nouy, Erwan Grelier
This file is part of tensap (tensor approximation package).

tensap is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

tensap is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public License
along with tensap.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

&#39;&#39;&#39;

# from string import ascii_lowercase
import numpy as np
import tensap


class FullTensor:
    &#39;&#39;&#39;
    Class FullTensor.

    Attributes
    ----------
    data : numpy.ndarray
        The content of the tensor.
    order : int
        The order of the tensor.
    shape : numpy.ndarray
        The shape of the tensor.
    is_orth : bool
        Boolean indicating if the representation of the tensor is orthogonal
        (i.e. one mu-matricization is orthogonal).
    orth_dim : bool
        Boolean indicating, if is_orth = True, the dimension mu for which
        the mu-matricization of the tensor is orthogonal.

    &#39;&#39;&#39;

    # Override numpy&#39;s operations with reversed operands
    __array_priority__ = 1

    def __init__(self, data, order=None, shape=None):
        &#39;&#39;&#39;
        Constructor for the class FullTensor.

        Parameters
        ----------
        data : numpy.ndarray or tensap.FullTensor or tensorflow.Tensor
            The content of the tensor.
        order : int, optional
            The order of the tensor. The default is None, indicating to infer
            it from data.
        shape : list or numpy.ndarray, optional
            The shape of the tensor. The default is None, the shape is deduced
            from data.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        if hasattr(data, &#39;data&#39;):
            self.data = np.array(data.data)
        else:
            self.data = np.array(data)
        if shape is not None:
            self.data = np.reshape(self.data, shape, order=&#39;F&#39;)

        ndim = np.ndim(self.data)
        if order is not None and ndim != order:
            for d in np.arange(ndim, order):
                self.data = np.expand_dims(self.data, d)

        self.is_orth = False
        self.orth_dim = None

    @property
    def order(self):
        &#39;&#39;&#39;
        Compute the order of the tensor.

        Returns
        -------
        int
            The order of the tensor.

        &#39;&#39;&#39;
        return np.ndim(self.data)

    @property
    def ndim(self):
        &#39;&#39;&#39;
        Compute the order of the tensor. Equivalent to self.order.

        Returns
        -------
        int
            The order of the tensor.

        &#39;&#39;&#39;
        return self.data.ndim

    @property
    def size(self):
        &#39;&#39;&#39;
        Compute the number of elements of the tensor.

        Returns
        -------
        numpy.ndarray
            The number of elements of the tensor.

        &#39;&#39;&#39;
        return np.array(self.data.shape)

    @property
    def shape(self):
        &#39;&#39;&#39;
        Compute the shape of the tensor

        Returns
        -------
        numpy.ndarray
            The shape of the tensor.

        &#39;&#39;&#39;
        return np.array(self.data.shape)

    def tree_based_tensor(self):
        &#39;&#39;&#39;
        Convert a FullTensor into a TreeBasedTensor.

        Returns
        -------
        TreeBasedTensor
            The FullTensor in tree-based tensor format.

        &#39;&#39;&#39;
        tree = tensap.DimensionTree.trivial(self.order)
        tensors = [FullTensor(self)]
        for dim in range(self.order):
            tensors.append(FullTensor(np.eye(self.shape[dim])))
        return tensap.TreeBasedTensor(tensors, tree)

    def sparse(self):
        &#39;&#39;&#39;
        Conversion of a FullTensor into a SparseTensor.

        Returns
        -------
        tensap.SparseTensor
            A SparseTensor representation of the FullTensor.

        &#39;&#39;&#39;
        dat = np.reshape(self.data, -1, order=&#39;F&#39;)
        ind = np.nonzero(dat)[0]
        indices = tensap.MultiIndices.ind2sub(self.shape, ind)
        return tensap.SparseTensor(dat, indices, self.shape)

    def __repr__(self):
        return (&#39;&lt;{} FullTensor:{n}&#39; +
                &#39;{t}order = {},{n}&#39; +
                &#39;{t}shape = {},{n}&#39; +
                &#39;{t}is_orth = {},{n}&#39; +
                &#39;{t}orth_dim = {}&gt;&#39;).format(&#39;x&#39;.join(map(str, self.shape)),
                                            self.order,
                                            self.shape,
                                            self.is_orth,
                                            self.orth_dim,
                                            t=&#39;\t&#39;, n=&#39;\n&#39;)

    def __getitem__(self, key):
        return self.data.__getitem__(key)

    def __eq__(self, tensor2):
        return np.all(self.data == tensor2.data)

    def __add__(self, arg):
        if isinstance(arg, FullTensor):
            arg = arg.data
        return FullTensor(self.data + arg)

    def __radd__(self, arg):
        return self + arg

    def __sub__(self, arg):
        if isinstance(arg, FullTensor):
            arg = arg.data
        return FullTensor(self.data - arg)

    def __rsub__(self, arg):
        return -self + arg

    def __neg__(self):
        return FullTensor(-self.data)

    def __mul__(self, arg):
        if isinstance(arg, FullTensor):
            arg = arg.data
        return FullTensor(self.data * arg)

    def __rmul__(self, arg):
        return self * arg

    def __truediv__(self, arg):
        if isinstance(arg, FullTensor):
            arg = arg.data
        return FullTensor(self.data / arg)

    def __pow__(self, arg):
        assert np.isscalar(arg), &#39;The power must be a scalar.&#39;
        return FullTensor(self.data ** arg)

    def hadamard_product(self, arg):
        &#39;&#39;&#39;
        Compute the Hadamard product of two tensors.

        Equivalent to self * arg.

        Parameters
        ----------
        arg : tensap.FullTensor or numpy.ndarray
            The second tensor of the Hadamard product.

        Returns
        -------
        FullTensor
            The tensor resulting from the Hadamard product.

        &#39;&#39;&#39;
        return self * arg

    def storage(self):
        &#39;&#39;&#39;
        Return the storage complexity of the FullTensor.

        Returns
        -------
        int
            The storage complexity of the FullTensor.

        &#39;&#39;&#39;
        return np.size(self.data)

    def sparse_storage(self):
        &#39;&#39;&#39;
        Return the sparse storage complexity of the FullTensor.

        Returns
        -------
        int
            The sparse storage complexity of the FullTensor.

        &#39;&#39;&#39;
        return np.count_nonzero(self.data)

    def numpy(self):
        &#39;&#39;&#39;
        Convert the FullTensor to a numpy.ndarray.

        Returns
        -------
        numpy.ndarray
            The FullTensor as a numpy.ndarray.

        &#39;&#39;&#39;
        return self.data

    def eval_at_indices(self, indices, dims=None):
        &#39;&#39;&#39;
        Evaluate the tensor at indices.

        If dims is None, return
        s(k) = x(indices(k, 1), indices(k, 2), ..., indices(k, d)),
        1 &lt;= k &lt;= self.shape[0].

        If dims is not None, return a partial evaluation: up to a permutation
        (placing the dimensions dims on the left), return
        s(k, i_1, ..., i_d&#39;) = x(indices(k, 1), indices(k, 2), ...,
        indices(k, M), i_1, ..., i_d&#39;),
        1 &lt;= k &lt;= self.shape[0], with M = dims.size and d&#39; = self.order - M.

        Parameters
        ----------
        indices : list of numpy.ndarray
            The indices of the tensor.
        dims : list of numpy.ndarray, optional
            The dimensions associated with the indices. The default is None,
            indicating that indices refers to all the dimensions.

        Returns
        -------
        evaluations : numpy.ndarray or FullTensor
            The evaluations of the tensor.

        &#39;&#39;&#39;
        indices = np.atleast_2d(indices)
        if dims is None:
            dims = np.arange(self.order)
        else:
            dims = np.atleast_1d(dims)
            if indices.shape[1] != dims.size:
                indices = np.transpose(indices)
            assert dims.size == indices.shape[1], \
                &#39;Wrong size of multi-indices.&#39;
            sort_ind = np.argsort(dims)
            dims = dims[sort_ind]
            indices = indices[:, sort_ind]
        assert dims.size == indices.shape[1], &#39;Wrong size of multi-indices.&#39;

        if dims.size == self.order:
            data = self
            evaluations = np.array([data[tuple(i)] for i in indices.tolist()])
        elif dims.size == 1:
            ind = [&#39;:&#39;]*self.order
            ind[dims[0]] = np.ravel(indices).tolist()
            evaluations = self.sub_tensor(*ind)
        else:
            no_dims = tensap.fast_setdiff(np.arange(self.order), dims)
            indices = np.ravel_multi_index(np.transpose(indices),
                                           [self.shape[i] for i in dims])
            evaluations = self.matricize(dims).sub_tensor(indices, &#39;:&#39;)
            evaluations = evaluations.reshape([indices.size] +
                                              [self.shape[i] for i in no_dims])
            left_dims = np.arange(dims[0])
            evaluations = evaluations.transpose(
                np.concatenate((np.arange(1, left_dims.size + 1), [0],
                                np.arange(left_dims.size + 1,
                                          self.order - dims.size + 1))))
        return evaluations

    def eval_diag(self, dims=None):
        &#39;&#39;&#39;
        Extract the diagonal of the tensor.

        The tensor must be such that self.shape[mu] = n for all mu (in dims if
        provided).

        Parameters
        ----------
        dims : list of numpy.ndarray, optional
            The dimensions associated with the indices of the diagonal. The
            default is None,indicating that the indices refer to all the
            dimensions.

        Returns
        -------
        data : numpy.ndarray
            The evaluations of the diagonal of the tensor.

        &#39;&#39;&#39;
        if dims is None:
            dims = np.arange(self.order)
        else:
            dims = np.atleast_1d(dims)

        if dims.size == 1:
            data = self
        else:
            assert np.all([self.shape[x] == self.shape[dims[0]] for
                           x in dims]),\
             &#39;The shapes of the tensor in dimensions dims should be equal.&#39;
            ind = np.repeat(np.reshape(np.arange(self.shape[dims[0]]),
                                       [-1, 1]), dims.size, 1)
            data = self.eval_at_indices(ind, dims)
        return data

    def reshape(self, shape):
        &#39;&#39;&#39;
        Reshape the tensor.

        Parameters
        ----------
        shape : list or numpy.ndarray
            The new shape of the tensor.

        Returns
        -------
        tensor : FullTensor
            The reshaped tensor.

        &#39;&#39;&#39;
        tensor = FullTensor(self)
        tensor.data = np.reshape(tensor.data, shape, order=&#39;F&#39;)
        return tensor

    def transpose(self, dims):
        &#39;&#39;&#39;
        Transpose (permute) the dimensions of the tensor.

        Parameters
        ----------
        dims : list or numpy.ndarray
            The new ordering of the dimensions.

        Returns
        -------
        tensor : FullTensor
            The transposed (permuted) tensor.

        &#39;&#39;&#39;
        tensor = FullTensor(self)
        tensor.data = np.transpose(tensor.data, dims)
        return tensor

    def itranspose(self, dims):
        &#39;&#39;&#39;
        Return the inverse transpose (permutation) of the dimensions of the
        tensor.

        Parameters
        ----------
        dims : list or numpy.ndarray
            The original transpose (permutation) indices.

        Returns
        -------
        FullTensor
            The transposed (permuted) tensor.

        &#39;&#39;&#39;
        return self.transpose(np.argsort(dims))

    def squeeze(self, dims=None):
        &#39;&#39;&#39;
        Remove the singleton dimensions of the tensor.

        Parameters
        ----------
        dims : list or numpy.ndarray, optional
            Dimensions to squeeze. The default is None, indicating all the
            singleton dimensions.

        Returns
        -------
        out : float or FullTensor
            The squeezed tensor.

        &#39;&#39;&#39;
        if dims is not None:
            dims = tuple(dims)

        out = FullTensor(np.squeeze(self.data, dims))
        if out.order == 0:
            out = out.data
        return out

    def dot(self, tensor2):
        &#39;&#39;&#39;
        Return the inner product of two tensors.

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor of the inner products.

        Returns
        -------
        numpy.float
            The inner product of the two tensors.

        &#39;&#39;&#39;
        return np.sum(np.multiply(self.data, tensor2.data))

    def norm(self):
        &#39;&#39;&#39;
        Compute the canonical norm of the FullTensor.

        Returns
        -------
        numpy.float
            The norm of the tensor.

        &#39;&#39;&#39;
        return np.linalg.norm(self.data)

    def full(self):
        &#39;&#39;&#39;
        Return the tensor.

        Returns
        -------
        FullTensor
            The tensor.

        &#39;&#39;&#39;
        return self

    def sub_tensor(self, *indices):
        &#39;&#39;&#39;
        Extract a subtensor of the tensor.

        The result is a tensor s of shape
        len(indices[0]), ..., len(indices[self.order-1]),
        such that
        s(k1,...,kd) = x(indices[0][k1], ..., indices[self.order-1][kd]).

        Example: x.subTensor([1, 2], &#39;:&#39;, [2, 5, 6]) returns a tensor with
        shape [2, self.shape[1], 3].

        Parameters
        ----------
        *indices : list
            The indices to extract in each dimension. &#39;:&#39; indicates all the
            indices.

        Returns
        -------
        FullTensor
            The subtensor.

        &#39;&#39;&#39;
        data = self.data
        order = self.order
        for dim in range(self.order):
            ind_loc = np.atleast_1d(indices[dim])
            if ind_loc.size != 1 or ind_loc[0] != &#39;:&#39;:
                data = np.take(data, ind_loc, axis=dim)
                if order != data.ndim:
                    data = np.expand_dims(data, dim)
                order = data.ndim
        return FullTensor(data)

    def cat(self, tensor2, dims=None):
        &#39;&#39;&#39;
        Concatenate the tensors.

        Concatenates self and tensor2 in a tensor z such that:
        z(i_1 ,..., i_d) = x(i_1, ..., i_d) if i_k &lt;= sz[k]-1 for k in dims,
        z(i_1, ..., i_d) = y(i_1-sz[0], ..., i_d-sz[d-1]) if i_k &gt;= sz[k]
        for k in dims,
        z(i_1, ..., i_d) = 0 otherwise, with sz = self.shape and
        dims = range(self.order) if not provided.

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor to be concatenaed.
        dims : list or numpy.ndarray, optional
            The dimensions of the concatenation. The default is None,
            indicating all the dimensions.
        Returns
        -------
        data : FullTensor
            The concatenated tensors.

        &#39;&#39;&#39;
        assert self.order == tensor2.order, \
            &#39;The orders of the tensors must be equal.&#39;

        tensor1 = FullTensor(self)
        order = self.order
        shape1 = np.atleast_1d(self.shape)
        shape2 = np.atleast_1d(tensor2.shape)

        if dims is None:
            dims = range(self.order)

        dims = np.atleast_1d(dims)
        dims_not = tensap.fast_setdiff(np.arange(order), dims)
        assert np.all([a == b for a, b in zip(shape1[dims_not],
                                              shape2[dims_not])]), \
            &#39;The dimensions of the tensors are not compatible.&#39;

        if dims.size == 1:
            data = np.concatenate([tensor1.data, tensor2.data], dims[0])
        else:
            shape_out = np.array(shape1)
            shape_out[dims] = shape1[dims] + shape2[dims]

            padding = np.transpose([[0]*order, shape_out - shape1])
            data = np.pad(tensor1.data, padding)
            padding = np.transpose([shape_out - shape2, [0]*order])
            data += np.pad(tensor2.data, padding)

        return FullTensor(data)

    def reduce_sum(self, dims=None):
        &#39;&#39;&#39;
        Compute the sum of elements across dimensions dims of a tensor.

        Similar to tensorflow.reduce_sum.

        Parameters
        ----------
        dims : list or numpy.ndarray, optional
            The dimensions to be reduced. The default is None, indicating all
            the dimensions.

        Returns
        -------
        FullTensor
            The reduced tensor.

        &#39;&#39;&#39;
        return FullTensor(np.sum(self.data, dims, keepdims=True))

    def reduce_mean(self, dims=None):
        &#39;&#39;&#39;
        Compute the mean of elements across dimensions dims of a tensor.

        Similar to tensorflow.mean.

        Parameters
        ----------
        dims : list or numpy.ndarray, optional
            The dimensions to be reduced. The default is None, indicating all
            the dimensions.

        Returns
        -------
        FullTensor
            The reduced tensor.

        &#39;&#39;&#39;
        return FullTensor(np.mean(self.data, dims, keepdims=True))

    def kron(self, tensor2):
        &#39;&#39;&#39;
        Kronecker product of tensors.

        Similar to numpy.kron but for arbitrary tensors.

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor of the Kronecker product.

        Returns
        -------
        FullTensor
            The tensor resulting from the Kronecker product.

        &#39;&#39;&#39;
        order1 = self.order
        order2 = tensor2.order
        order_max = np.max((order1, order2))

        shape1 = np.concatenate((self.shape,
                                np.ones(order_max - order1, dtype=int)))
        shape2 = np.concatenate((tensor2.shape,
                                np.ones(order_max - order2, dtype=int)))

        data1 = np.reshape(self.data, [-1, 1])
        data2 = np.reshape(tensor2.data, [1, -1])

        perm = np.reshape(np.transpose(np.reshape(np.arange(2*order_max),
                                                  [2, order_max])),
                          2*order_max)

        data = np.reshape(np.transpose(np.reshape(np.matmul(data1, data2),
                                                  np.concatenate((shape1,
                                                                  shape2))),
                                       perm), shape1 * shape2)
        return FullTensor(data, shape=self.shape*tensor2.shape)

    def orth(self, dim=None):
        &#39;&#39;&#39;
        Orthogonalize the tensor.

        Parameters
        ----------
        dim : int, optional
            The dimension of the orthogonal dim-matricization of self. The
            default is None, returning a copy of the original tensor.

        Returns
        -------
        tensor : FullTensor
            A tensor whose dim-matricization is an orthogonal matrix
            corresponding to the Q factor of a QR factorization of the
            dim-matricization of self.
        r_matrix : numpy.ndarray
            The R factor.

        &#39;&#39;&#39;
        tensor = FullTensor(self)  # Copy the tensor

        if dim is None:
            return tensor, np.array([])

        if dim == -1:
            dim = tensor.order-1

        dims = np.concatenate((np.arange(dim),
                               np.arange(dim+1, tensor.order),
                               [dim]))
        tensor = tensor.transpose(dims)

        shape0 = np.array(tensor.shape)
        tensor = tensor.reshape([np.prod(shape0[:-1]), shape0[-1]])

        try:
            from tensorflow.python.ops.gen_linalg_ops import qr
            q_tf, r_tf = qr(tensor.data, full_matrices=False)
            tensor.data, r_matrix = q_tf.numpy(), r_tf.numpy()
        except ImportError:
            tensor.data, r_matrix = np.linalg.qr(tensor.data)

        shape0[-1] = r_matrix.shape[0]
        tensor = tensor.reshape(shape0)
        tensor = tensor.itranspose(dims)
        tensor.is_orth = True
        tensor.orth_dim = dim
        return tensor, r_matrix

    def dot_with_rank_one_metric(self, tensor2, matrix):
        &#39;&#39;&#39;
        Compute the weighted inner product of two tensors.

        Compute the weighted canonical inner product of self and tensor2,
        where the inner product related to dimension k is weighted by
        matrix[k]. It is equivalent to
        self.dot(tensor2.tensor_matrix_product(matrix)),
        but can be much faster.

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor of the inner product.
        matrix : list or numpy.ndarray or FullTensor
            The weight matrix.

        Returns
        -------
        numpy.float
            The weighted inner product.

        &#39;&#39;&#39;
        return self.dot(tensor2.tensor_matrix_product(matrix))

    def tensordot_matrix_product_except_dim(self, tensor2, matrices, dim):
        &#39;&#39;&#39;
        Particular type of contraction.

        Compute a special contraction of two tensors self, tensor2, a list of
        matrices matrices and a particular dimension dim. Note that dim must
        be a scalar, while matrices must be a list array with self.order
        elements.

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor of the contraction.
        matrices : list
            The list of matrices of the contraction.
        dim : int
            The excluded dimension.

        Returns
        -------
        numpy.ndarray
            The result of the contraction.

        &#39;&#39;&#39;
        assert isinstance(matrices, list), &#39;matrices should be a list.&#39;
        assert len(matrices) == self.order, \
            &#39;len(matrices) must be self.order.&#39;

        dims = tensap.fast_setdiff(np.arange(self.order), dim)
        matrices = [matrices[i] for i in dims]
        tmp = tensor2.tensor_matrix_product(matrices, dims)
        tmp = self.tensordot(tmp, dims, dims)
        return tmp

    def tensordot(self, tensor2, dims1, dims2=None):
        &#39;&#39;&#39;
        Contract two tensors along specified dimensions.

        Similar to tensorflow.tensordot.

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor of the contraction.
        dims1 : list or int
            The dimensions of contractions for the first tensor.
        dims2 : list or int, optional
            The dimensions of contractions for the second tensor. The default
            is None which indicates, if dims1 = 0, to perform the outer
            product of the two tensors, similarly to tensorflow.tensordot.

        Returns
        -------
        out : FullTensor
            The resulting tensor.

        &#39;&#39;&#39;
        dims1 = np.atleast_1d(dims1)
        if dims1.size == 1 and dims1 == 0 and dims2 is None:
            # Outer product (notation similar to tensorflow)
            out = FullTensor(np.tensordot(self.data, tensor2.data, 0))
        else:
            dims2 = np.atleast_1d(dims2)
            assert np.all([self.shape[i] == tensor2.shape[j] for i, j in
                           zip(dims1, dims2)]), \
                &#39;The dimensions of the tensors are not compatible.&#39;
            out = FullTensor(np.tensordot(self.data, tensor2.data,
                                          [dims1, dims2]))
        return out

    def tensordot_eval_diag(self, tensor2, dims1, dims2, diag_dims1,
                            diag_dims2, diag=False):
        &#39;&#39;&#39;
        Evaluate of the diagonal of a tensor obtained by contraction of two
        tensors.

        The contraction is performed along the dimensions dims1 for self and
        dims2 for tensor2, and the diagonal is evaluated according to the
        dimensions diag_dims1 for self and diag_dims2 for tensor2.

        The boolean diag indicates if the several diagonals are evaluated, for
        instance:
        - if diag is False, for order-4 tensors x and y,
        z = x.tensordot_eval_diag(y,[1,3],[2,3],2,0) returns an order-3 tensor
        z(i1,k,j2) = sum_{l1,l2} x(i1,l1,k,l2) y(k,j2,l1,l2)
        - if diag is True, for order-5 tensors x and y,
        z = x.tensordot_eval_diag(y,[1,3],[2,3],[0,2],[1,4]) returns an
        order-4 tensor
        z(k,l,i5,j1) = sum_{l1,l2} x(k,l1,l,l2,i5) y(j1,k,l1,l2,l)

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor of the product.
        dims1 : list or numpy.ndarray
            Dimensions of the first tensor for the contraction.
        dims2 : list or numpy.ndarray
            Dimensions of the second tensor for the contraction.
        diag_dims1 : list or numpy.ndarray
            Indices of the first tensor for the evaluation of the diagonal.
        diag_dims2 : list or numpy.ndarray
            Indices of the second tensor for the evaluation of the diagonal.
        diag : bool, optional
            Boolean enabling the evaluation of multiple diagonals. The default
            is False.

        Returns
        -------
        FullTensor
            The evaluated tensor.

        &#39;&#39;&#39;
        # Check if an outer product is asked with dims1 and dims2 equal to None
        if dims1 is None and dims2 is None:
            dims1 = []
            dims2 = []

        dims1 = np.atleast_1d(dims1)
        dims2 = np.atleast_1d(dims2)
        diag_dims1 = np.atleast_1d(diag_dims1)
        diag_dims2 = np.atleast_1d(diag_dims2)

        ind1 = np.arange(self.ndim)
        ind2 = ind1.size + np.arange(tensor2.ndim)
        if diag and diag_dims1.size != 0 and diag_dims2.size != 0:
            ind2[diag_dims2] = ind1[diag_dims1]
        elif not diag:
            ind1[diag_dims1] = ind1[diag_dims1[0]]
            ind2[diag_dims2] = ind1[diag_dims1[0]]
        if dims1.size != 0 and dims2.size != 0:
            ind2[dims2] = ind1[dims1]
        ind12 = np.concatenate((ind1, ind2))
        indexes = np.unique(ind12, return_index=True)[1]
        # Retain only the unique values without sorting the vector
        ind_out = np.array([ind12[index] for index in sorted(indexes)])
        # Remove from ind_out the contracted dimensions without sorting it
        ind_out = ind_out[[i not in np.atleast_1d(dims1) for i in ind_out]]
        array = np.einsum(self.data, ind1.tolist(), tensor2.data,
                          ind2.tolist(), ind_out.tolist())
        # alph = list(ascii_lowercase)
        # ind1 = [alph[i] for i in ind1]
        # ind2 = [alph[i] for i in ind2]
        # ind_out = [alph[i] for i in ind_out]
        # array = np.einsum(&#39;&#39;.join(ind1) + &#39;, &#39; + &#39;&#39;.join(ind2) + &#39; -&gt; &#39; +
        #                   &#39;&#39;.join(ind_out), self.data, tensor2.data)
        return FullTensor(array)

    def tensor_matrix_product(self, matrices, dims=None):
        &#39;&#39;&#39;
        Contract a tensor with matrices.

        The second dimension of the matrix matrices[k] is contracted with the
        k-th dimension of self, with the indices k given in dims (if provided).

        Parameters
        ----------
        matrices : numpy.ndarray or list of numpy.ndarray
            The matrices to use in the product.
        dims : list or numpy.ndarray, optional
            Indices of the contractions. The default is None, indicating all
            the dimensions.

        Returns
        -------
        FullTensor
            The tensor after the contractions with the matrices.

        &#39;&#39;&#39;
        if dims is None:
            assert isinstance(matrices, (list, np.ndarray)), \
                &#39;matrices should be a list or a numpy.ndarray.&#39;
            assert len(matrices) == self.order, \
                &#39;len(matrices) must be self.order.&#39;
            dims = range(self.order)
        else:
            dims = np.atleast_1d(dims)
            if not isinstance(matrices, list):
                matrices = [matrices]
            assert len(matrices) == dims.size, \
                &#39;len(matrices) must be equal to dims.size.&#39;

        # Numpy implementation
        # matrices = [np.array(x) for x in matrices]
        # data = self.numpy()
        # if self.order == 1:
        #     data = np.matmul(matrices[0], data)
        # else:
        #     k = 0
        #     for dim in np.nditer(dims):
        #         perm_dims = np.concatenate(([dim], np.arange(dim),
        #                                     np.arange(dim+1, self.order)))
        #         data = np.transpose(data, perm_dims)
        #         shape0 = np.array(data.shape)
        #         data = np.reshape(data, [shape0[0], np.prod(shape0[1:])])
        #         data = np.matmul(matrices[k], data)
        #         shape0[0] = matrices[k].shape[0]
        #         data = np.reshape(data, shape0)
        #         data = np.transpose(data, np.argsort(perm_dims))
        #         k += 1
        # return FullTensor(data)

        tensor = FullTensor(self)
        matrices = [FullTensor(x) for x in matrices]
        for i, dim in enumerate(dims):
            index = np.concatenate((
                tensap.fast_setdiff(np.arange(tensor.order), dim), [dim]))
            tensor = tensor.tensordot(matrices[i], dim, 1).itranspose(index)
        return tensor

    def tensor_vector_product(self, vectors, dims=None):
        &#39;&#39;&#39;
        Compute the contraction of the tensor with vectors.

        Compute the contraction of self with each vector contained in the list
        vectors along dimensions specified by dims. The operation is such that
        V[k] is contracted with the dims[k]-th dimension of self.

        Parameters
        ----------
        vectors : numpy.ndarray or list of numpy.ndarray
            The vectors to use in the product.
        dims : list or numpy.ndarray, optional
            Indices of the contractions. The default is None, indicating all
            the dimensions.

        Returns
        -------
        FullTensor
            The tensor after the contractions with the vectors.

        &#39;&#39;&#39;
        if dims is None:
            assert isinstance(vectors, list), &#39;vectors should be a list.&#39;
            assert len(vectors) == self.order, \
                &#39;len(vectors) must be self.order.&#39;
            dims = np.arange(self.order)
        else:
            dims = np.array(dims)
            if not isinstance(vectors, list):
                vectors = [vectors]
            assert len(vectors) == dims.size, \
                &#39;len(vectors) must be equal to dims.size.&#39;

        vectors = [FullTensor(x, 2, [1, -1]) for x in vectors]
        return self.tensor_matrix_product(vectors, dims).squeeze(dims.tolist())

    def tensor_matrix_product_eval_diag(self, matrices, dims=None):
        &#39;&#39;&#39;
        Evaluate the diagonal of a tensor obtained by contraction with
        matrices.

        Provides the diagonal of the tensor obtained by contracting the tensor
        with matrices H[k] along dimensions dims(k)+1, for k = 0, ...,
        dims.size-1.

        Parameters
        ----------
        matrices : list
            The matrices to use in the product.
        dims : list or numpy.ndarray, optional
            Indices of the contractions. The default is None, indicating all
            the dimensions.

        Returns
        -------
        out : FullTensor
            The diagonal of the contractions of the tensor with the matrices.

        &#39;&#39;&#39;
        if dims is None:
            assert isinstance(matrices, list), &#39;matrices should be a list.&#39;
            assert len(matrices) == self.order, \
                &#39;len(matrices) must be self.order.&#39;
            dims = np.arange(self.order)
        else:
            dims = np.atleast_1d(dims)
            if not isinstance(matrices, list):
                matrices = [matrices]
            assert len(matrices) == dims.size, \
                &#39;len(matrices) must be equal to dims.size.&#39;

        matrices = [FullTensor(x) for x in matrices]
        ind = np.flip(np.argsort(dims))
        out = matrices[ind[0]].tensordot(self, 1, dims[ind[0]])
        for i in ind[1:]:
            out = matrices[i].tensordot_eval_diag(out, 1, dims[i]+1, 0, 0)

        # if out.order == 1:
        #     out = out.numpy()
        return out

    def tensor_diagonal_matrix_product(self, matrices, dims=None):
        &#39;&#39;&#39;
        Contract a FullTensor with matrices built from their diagonals.

        The second dimension of the matrix matrices[k] is contracted with the
        k-th dimension of self, with the indices k given in dims (if provided).

        Parameters
        ----------
        matrices : numpy.ndarray or list of numpy.ndarray
            The diagonals of the matrices to use in the product.
        dims : list or numpy.ndarray, optional
            Indices of the contractions. The default is None, indicating all
            the dimensions.

        Returns
        -------
        FullTensor
            The tensor after the contractions with the matrices.

        &#39;&#39;&#39;
        if dims is None:
            assert isinstance(matrices, list), &#39;matrices should be a list.&#39;
            assert len(matrices) == self.order, \
                &#39;len(matrices) must be self.order.&#39;
            dims = range(self.order)
        else:
            dims = np.array(dims)
            if not isinstance(matrices, list):
                matrices = [matrices]
            assert len(matrices) == dims.size, \
                &#39;len(matrices) must be equal to dims.size.&#39;

        matrices = [FullTensor(np.diag(np.reshape(x, [-1])))
                    for x in matrices]
        return self.tensor_matrix_product(matrices, dims)

    def matricize(self, dims1, dims2=None):
        &#39;&#39;&#39;
        Return the matricization of the tensor.

        Parameters
        ----------
        dims1 : list or numpy.ndarray
            The dimensions of the tensor corresponding to the first dimension
            of the matricization.
        dims2 : list or numpy.ndarray, optional
            The dimensions of the tensor corresponding to the first dimension
            of the matricization. The default is None, for which they are
            deduced from dims1.

        Returns
        -------
        FullTensor
            The matricization of the tensor.

        &#39;&#39;&#39;
        dims1 = np.atleast_1d(dims1)
        if dims1.size == 1 and dims1 == -1:
            dims1 = np.array([self.order-1])
        if dims2 is None:
            dims2 = tensap.fast_setdiff(np.arange(self.order), dims1)
        else:
            dims2 = np.atleast_1d(dims2)
        shape1 = [self.shape[i] for i in dims1]
        shape2 = [self.shape[i] for i in dims2]

        tensor = FullTensor(self)
        tensor = tensor.transpose(np.concatenate((dims1, dims2)))
        tensor = tensor.reshape([np.prod(shape1), np.prod(shape2)])
        return FullTensor(tensor)

    def outer_product_eval_diag(self, tensor2, dims1, dims2, diag=False):
        &#39;&#39;&#39;
        Compute the diagonal of the outer product of two tensors.

        Equivalent to
        self.tensordot_eval_diag(tensor2, None, None, dims1, dims2, diag)

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor of the product.
        dims1 : list or numpy.ndarray
            Indices of the first tensor for the evaluation of the diagonal.
        dims2 : list or numpy.ndarray,
            Indices of the second tensor for the evaluation of the diagonal.
        diag : bool, optional
            Boolean enabling the evaluation of multiple diagonals. The default
            is False.

        Returns
        -------
        FullTensor
            The evaluated tensor.

        &#39;&#39;&#39;
        return self.tensordot_eval_diag(tensor2, None, None,
                                        dims1, dims2, diag)

    def principal_components(self, parameter=None):
        &#39;&#39;&#39;
        Compute the principal components of an order-2 tensor.

        Parameters
        ----------
        parameter : float or int, optional
            A parameter controlling the number of principal components.
            - If it is an integer, the number of principal components is the
            minimum between parameter and self.shape[0].
            - If it is a float smaller than 1, the number of principal
            components is determined such that ||x - VV&#39;x||_F &lt; t ||x||_F,
            with x the tensor, V the matrix of principal components, t the
            parameter, V&#39; the transpose of the matrix V and ||.||_F the
            Frobenius norm.
            The default is self.shape[0].

        Returns
        -------
        principal_components : numpy.ndarray
            The principal components of the tensor.
        singular_values : numpy.ndarray
            The diagonal matrix of the associated singular values.

        &#39;&#39;&#39;
        assert self.order == 2, &#39;The order of the tensor must be 2.&#39;
        if parameter is None or parameter &gt; self.shape[0]:
            parameter = self.shape[0]

        if parameter &lt; 1:
            truncator = tensap.Truncator(tolerance=parameter, max_rank=np.inf)
        else:
            truncator = tensap.Truncator(tolerance=0, max_rank=parameter)
        tensor = truncator.truncate(self)
        principal_components = tensor.space[0]
        singular_values = np.diag(tensor.core.data)
        return principal_components, singular_values

    def alpha_principal_components(self, alpha, parameter=None):
        &#39;&#39;&#39;
        Compute the alpha-principal components of a tensor.

        Return the principal components of the alpha-matricization
        M_alpha(self) of the tensor self of order d.

        See also the method principal_components.

        Parameters
        ----------
        alpha : int
            The index of the alpha-matricization.
        parameter : float or int, optional
            A parameter controlling the number of principal components.
            The default is M_alpha(self).shape[0].

        Returns
        -------
        principal_components : numpy.ndarray
            The principal components of the tensor.
        singular_values : numpy.ndarray
            The diagonal matrix of the associated singular values.

        &#39;&#39;&#39;
        principal_components, singular_values = \
            self.matricize(alpha).principal_components(parameter)
        return principal_components, singular_values

    def singular_values(self):
        &#39;&#39;&#39;
        Compute the higher-order singular values of a tensor (the collection
        of singular values of d different matricizations).

        Returns
        -------
        sin_val : numpy.ndarray or list of numpy.ndarray.
            The higher-order singular values.

        &#39;&#39;&#39;
        if self.order == 2:
            sin_val = np.linalg.svd(self.data, compute_uv=False)
        else:
            sin_val = []
            for ind in range(self.order):
                mat = self.matricize(ind)
                sin_val.append(np.linalg.svd(mat.data,
                                             compute_uv=False))
        return sin_val

    @staticmethod
    def create(generator, shape):
        &#39;&#39;&#39;
        Create a FullTensor of shape shape using a given generator.

        Parameters
        ----------
        generator : function
            Function generating a numpy.ndarray, given a shape.
        shape : numpy.ndarray or list
            The shape of the tensor.

        Returns
        -------
        FullTensor
            The created tensor.

        &#39;&#39;&#39;
        return FullTensor(generator(np.atleast_1d(shape)))

    @staticmethod
    def zeros(shape):
        &#39;&#39;&#39;
        Create a FullTensor of shape shape with entries equal to 0.

        Parameters
        ----------
        shape : numpy.ndarray or list
            The shape of the tensor.

        Returns
        -------
        FullTensor
            The created tensor.

        &#39;&#39;&#39;
        return FullTensor.create(np.zeros, shape)

    @staticmethod
    def ones(shape):
        &#39;&#39;&#39;
        Create a FullTensor of shape shape with entries equal to 1.

        Parameters
        ----------
        shape : numpy.ndarray or list
            The shape of the tensor.

        Returns
        -------
        FullTensor
            The created tensor.

        &#39;&#39;&#39;
        return FullTensor.create(np.ones, shape)

    @staticmethod
    def randn(shape):
        &#39;&#39;&#39;
        Create a FullTensor of shape shape with i.i.d. entries drawn according
        to the standard gaussian distribution.

        Parameters
        ----------
        shape : numpy.ndarray or list
            The shape of the tensor.

        Returns
        -------
        FullTensor
            The created tensor.

        &#39;&#39;&#39;
        return FullTensor.create(lambda x: np.random.randn(*x), shape)

    @staticmethod
    def rand(shape):
        &#39;&#39;&#39;
        Create a FullTensor of shape shape with i.i.d. entries drawn according
        to the uniform distribution on [0, 1].

        Parameters
        ----------
        shape : numpy.ndarray or list
            The shape of the tensor.

        Returns
        -------
        FullTensor
            The created tensor.

        &#39;&#39;&#39;
        return FullTensor.create(lambda x: np.random.rand(*x), shape)

    @staticmethod
    def diag(diag, order):
        &#39;&#39;&#39;
        Create a diagonal tensor x of order order, such that
        x[i, ..., i] = diag[i] for i = 0, ..., diag.size - 1.

        Parameters
        ----------
        diag : list or numpy.ndarray
            The diagonal of the tensor.
        order : int
            The order of the tensor.

        Returns
        -------
        FullTensor
            The created tensor.

        &#39;&#39;&#39;
        diag = np.atleast_1d(diag)

        ones_v = np.ones(order, dtype=int)
        shape_v = diag.size * ones_v

        data = np.zeros(shape_v)
        for ind, diag_ind in enumerate(diag):
            data[tuple(ind * ones_v)] = diag_ind
        return FullTensor(data)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor"><code class="flex name class">
<span>class <span class="ident">FullTensor</span></span>
<span>(</span><span>data, order=None, shape=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Class FullTensor.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The content of the tensor.</dd>
<dt><strong><code>order</code></strong> :&ensp;<code>int</code></dt>
<dd>The order of the tensor.</dd>
<dt><strong><code>shape</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The shape of the tensor.</dd>
<dt><strong><code>is_orth</code></strong> :&ensp;<code>bool</code></dt>
<dd>Boolean indicating if the representation of the tensor is orthogonal
(i.e. one mu-matricization is orthogonal).</dd>
<dt><strong><code>orth_dim</code></strong> :&ensp;<code>bool</code></dt>
<dd>Boolean indicating, if is_orth = True, the dimension mu for which
the mu-matricization of the tensor is orthogonal.</dd>
</dl>
<p>Constructor for the class FullTensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>numpy.ndarray</code> or <code>tensap.FullTensor</code> or <code>tensorflow.Tensor</code></dt>
<dd>The content of the tensor.</dd>
<dt><strong><code>order</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The order of the tensor. The default is None, indicating to infer
it from data.</dd>
<dt><strong><code>shape</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>The shape of the tensor. The default is None, the shape is deduced
from data.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FullTensor:
    &#39;&#39;&#39;
    Class FullTensor.

    Attributes
    ----------
    data : numpy.ndarray
        The content of the tensor.
    order : int
        The order of the tensor.
    shape : numpy.ndarray
        The shape of the tensor.
    is_orth : bool
        Boolean indicating if the representation of the tensor is orthogonal
        (i.e. one mu-matricization is orthogonal).
    orth_dim : bool
        Boolean indicating, if is_orth = True, the dimension mu for which
        the mu-matricization of the tensor is orthogonal.

    &#39;&#39;&#39;

    # Override numpy&#39;s operations with reversed operands
    __array_priority__ = 1

    def __init__(self, data, order=None, shape=None):
        &#39;&#39;&#39;
        Constructor for the class FullTensor.

        Parameters
        ----------
        data : numpy.ndarray or tensap.FullTensor or tensorflow.Tensor
            The content of the tensor.
        order : int, optional
            The order of the tensor. The default is None, indicating to infer
            it from data.
        shape : list or numpy.ndarray, optional
            The shape of the tensor. The default is None, the shape is deduced
            from data.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        if hasattr(data, &#39;data&#39;):
            self.data = np.array(data.data)
        else:
            self.data = np.array(data)
        if shape is not None:
            self.data = np.reshape(self.data, shape, order=&#39;F&#39;)

        ndim = np.ndim(self.data)
        if order is not None and ndim != order:
            for d in np.arange(ndim, order):
                self.data = np.expand_dims(self.data, d)

        self.is_orth = False
        self.orth_dim = None

    @property
    def order(self):
        &#39;&#39;&#39;
        Compute the order of the tensor.

        Returns
        -------
        int
            The order of the tensor.

        &#39;&#39;&#39;
        return np.ndim(self.data)

    @property
    def ndim(self):
        &#39;&#39;&#39;
        Compute the order of the tensor. Equivalent to self.order.

        Returns
        -------
        int
            The order of the tensor.

        &#39;&#39;&#39;
        return self.data.ndim

    @property
    def size(self):
        &#39;&#39;&#39;
        Compute the number of elements of the tensor.

        Returns
        -------
        numpy.ndarray
            The number of elements of the tensor.

        &#39;&#39;&#39;
        return np.array(self.data.shape)

    @property
    def shape(self):
        &#39;&#39;&#39;
        Compute the shape of the tensor

        Returns
        -------
        numpy.ndarray
            The shape of the tensor.

        &#39;&#39;&#39;
        return np.array(self.data.shape)

    def tree_based_tensor(self):
        &#39;&#39;&#39;
        Convert a FullTensor into a TreeBasedTensor.

        Returns
        -------
        TreeBasedTensor
            The FullTensor in tree-based tensor format.

        &#39;&#39;&#39;
        tree = tensap.DimensionTree.trivial(self.order)
        tensors = [FullTensor(self)]
        for dim in range(self.order):
            tensors.append(FullTensor(np.eye(self.shape[dim])))
        return tensap.TreeBasedTensor(tensors, tree)

    def sparse(self):
        &#39;&#39;&#39;
        Conversion of a FullTensor into a SparseTensor.

        Returns
        -------
        tensap.SparseTensor
            A SparseTensor representation of the FullTensor.

        &#39;&#39;&#39;
        dat = np.reshape(self.data, -1, order=&#39;F&#39;)
        ind = np.nonzero(dat)[0]
        indices = tensap.MultiIndices.ind2sub(self.shape, ind)
        return tensap.SparseTensor(dat, indices, self.shape)

    def __repr__(self):
        return (&#39;&lt;{} FullTensor:{n}&#39; +
                &#39;{t}order = {},{n}&#39; +
                &#39;{t}shape = {},{n}&#39; +
                &#39;{t}is_orth = {},{n}&#39; +
                &#39;{t}orth_dim = {}&gt;&#39;).format(&#39;x&#39;.join(map(str, self.shape)),
                                            self.order,
                                            self.shape,
                                            self.is_orth,
                                            self.orth_dim,
                                            t=&#39;\t&#39;, n=&#39;\n&#39;)

    def __getitem__(self, key):
        return self.data.__getitem__(key)

    def __eq__(self, tensor2):
        return np.all(self.data == tensor2.data)

    def __add__(self, arg):
        if isinstance(arg, FullTensor):
            arg = arg.data
        return FullTensor(self.data + arg)

    def __radd__(self, arg):
        return self + arg

    def __sub__(self, arg):
        if isinstance(arg, FullTensor):
            arg = arg.data
        return FullTensor(self.data - arg)

    def __rsub__(self, arg):
        return -self + arg

    def __neg__(self):
        return FullTensor(-self.data)

    def __mul__(self, arg):
        if isinstance(arg, FullTensor):
            arg = arg.data
        return FullTensor(self.data * arg)

    def __rmul__(self, arg):
        return self * arg

    def __truediv__(self, arg):
        if isinstance(arg, FullTensor):
            arg = arg.data
        return FullTensor(self.data / arg)

    def __pow__(self, arg):
        assert np.isscalar(arg), &#39;The power must be a scalar.&#39;
        return FullTensor(self.data ** arg)

    def hadamard_product(self, arg):
        &#39;&#39;&#39;
        Compute the Hadamard product of two tensors.

        Equivalent to self * arg.

        Parameters
        ----------
        arg : tensap.FullTensor or numpy.ndarray
            The second tensor of the Hadamard product.

        Returns
        -------
        FullTensor
            The tensor resulting from the Hadamard product.

        &#39;&#39;&#39;
        return self * arg

    def storage(self):
        &#39;&#39;&#39;
        Return the storage complexity of the FullTensor.

        Returns
        -------
        int
            The storage complexity of the FullTensor.

        &#39;&#39;&#39;
        return np.size(self.data)

    def sparse_storage(self):
        &#39;&#39;&#39;
        Return the sparse storage complexity of the FullTensor.

        Returns
        -------
        int
            The sparse storage complexity of the FullTensor.

        &#39;&#39;&#39;
        return np.count_nonzero(self.data)

    def numpy(self):
        &#39;&#39;&#39;
        Convert the FullTensor to a numpy.ndarray.

        Returns
        -------
        numpy.ndarray
            The FullTensor as a numpy.ndarray.

        &#39;&#39;&#39;
        return self.data

    def eval_at_indices(self, indices, dims=None):
        &#39;&#39;&#39;
        Evaluate the tensor at indices.

        If dims is None, return
        s(k) = x(indices(k, 1), indices(k, 2), ..., indices(k, d)),
        1 &lt;= k &lt;= self.shape[0].

        If dims is not None, return a partial evaluation: up to a permutation
        (placing the dimensions dims on the left), return
        s(k, i_1, ..., i_d&#39;) = x(indices(k, 1), indices(k, 2), ...,
        indices(k, M), i_1, ..., i_d&#39;),
        1 &lt;= k &lt;= self.shape[0], with M = dims.size and d&#39; = self.order - M.

        Parameters
        ----------
        indices : list of numpy.ndarray
            The indices of the tensor.
        dims : list of numpy.ndarray, optional
            The dimensions associated with the indices. The default is None,
            indicating that indices refers to all the dimensions.

        Returns
        -------
        evaluations : numpy.ndarray or FullTensor
            The evaluations of the tensor.

        &#39;&#39;&#39;
        indices = np.atleast_2d(indices)
        if dims is None:
            dims = np.arange(self.order)
        else:
            dims = np.atleast_1d(dims)
            if indices.shape[1] != dims.size:
                indices = np.transpose(indices)
            assert dims.size == indices.shape[1], \
                &#39;Wrong size of multi-indices.&#39;
            sort_ind = np.argsort(dims)
            dims = dims[sort_ind]
            indices = indices[:, sort_ind]
        assert dims.size == indices.shape[1], &#39;Wrong size of multi-indices.&#39;

        if dims.size == self.order:
            data = self
            evaluations = np.array([data[tuple(i)] for i in indices.tolist()])
        elif dims.size == 1:
            ind = [&#39;:&#39;]*self.order
            ind[dims[0]] = np.ravel(indices).tolist()
            evaluations = self.sub_tensor(*ind)
        else:
            no_dims = tensap.fast_setdiff(np.arange(self.order), dims)
            indices = np.ravel_multi_index(np.transpose(indices),
                                           [self.shape[i] for i in dims])
            evaluations = self.matricize(dims).sub_tensor(indices, &#39;:&#39;)
            evaluations = evaluations.reshape([indices.size] +
                                              [self.shape[i] for i in no_dims])
            left_dims = np.arange(dims[0])
            evaluations = evaluations.transpose(
                np.concatenate((np.arange(1, left_dims.size + 1), [0],
                                np.arange(left_dims.size + 1,
                                          self.order - dims.size + 1))))
        return evaluations

    def eval_diag(self, dims=None):
        &#39;&#39;&#39;
        Extract the diagonal of the tensor.

        The tensor must be such that self.shape[mu] = n for all mu (in dims if
        provided).

        Parameters
        ----------
        dims : list of numpy.ndarray, optional
            The dimensions associated with the indices of the diagonal. The
            default is None,indicating that the indices refer to all the
            dimensions.

        Returns
        -------
        data : numpy.ndarray
            The evaluations of the diagonal of the tensor.

        &#39;&#39;&#39;
        if dims is None:
            dims = np.arange(self.order)
        else:
            dims = np.atleast_1d(dims)

        if dims.size == 1:
            data = self
        else:
            assert np.all([self.shape[x] == self.shape[dims[0]] for
                           x in dims]),\
             &#39;The shapes of the tensor in dimensions dims should be equal.&#39;
            ind = np.repeat(np.reshape(np.arange(self.shape[dims[0]]),
                                       [-1, 1]), dims.size, 1)
            data = self.eval_at_indices(ind, dims)
        return data

    def reshape(self, shape):
        &#39;&#39;&#39;
        Reshape the tensor.

        Parameters
        ----------
        shape : list or numpy.ndarray
            The new shape of the tensor.

        Returns
        -------
        tensor : FullTensor
            The reshaped tensor.

        &#39;&#39;&#39;
        tensor = FullTensor(self)
        tensor.data = np.reshape(tensor.data, shape, order=&#39;F&#39;)
        return tensor

    def transpose(self, dims):
        &#39;&#39;&#39;
        Transpose (permute) the dimensions of the tensor.

        Parameters
        ----------
        dims : list or numpy.ndarray
            The new ordering of the dimensions.

        Returns
        -------
        tensor : FullTensor
            The transposed (permuted) tensor.

        &#39;&#39;&#39;
        tensor = FullTensor(self)
        tensor.data = np.transpose(tensor.data, dims)
        return tensor

    def itranspose(self, dims):
        &#39;&#39;&#39;
        Return the inverse transpose (permutation) of the dimensions of the
        tensor.

        Parameters
        ----------
        dims : list or numpy.ndarray
            The original transpose (permutation) indices.

        Returns
        -------
        FullTensor
            The transposed (permuted) tensor.

        &#39;&#39;&#39;
        return self.transpose(np.argsort(dims))

    def squeeze(self, dims=None):
        &#39;&#39;&#39;
        Remove the singleton dimensions of the tensor.

        Parameters
        ----------
        dims : list or numpy.ndarray, optional
            Dimensions to squeeze. The default is None, indicating all the
            singleton dimensions.

        Returns
        -------
        out : float or FullTensor
            The squeezed tensor.

        &#39;&#39;&#39;
        if dims is not None:
            dims = tuple(dims)

        out = FullTensor(np.squeeze(self.data, dims))
        if out.order == 0:
            out = out.data
        return out

    def dot(self, tensor2):
        &#39;&#39;&#39;
        Return the inner product of two tensors.

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor of the inner products.

        Returns
        -------
        numpy.float
            The inner product of the two tensors.

        &#39;&#39;&#39;
        return np.sum(np.multiply(self.data, tensor2.data))

    def norm(self):
        &#39;&#39;&#39;
        Compute the canonical norm of the FullTensor.

        Returns
        -------
        numpy.float
            The norm of the tensor.

        &#39;&#39;&#39;
        return np.linalg.norm(self.data)

    def full(self):
        &#39;&#39;&#39;
        Return the tensor.

        Returns
        -------
        FullTensor
            The tensor.

        &#39;&#39;&#39;
        return self

    def sub_tensor(self, *indices):
        &#39;&#39;&#39;
        Extract a subtensor of the tensor.

        The result is a tensor s of shape
        len(indices[0]), ..., len(indices[self.order-1]),
        such that
        s(k1,...,kd) = x(indices[0][k1], ..., indices[self.order-1][kd]).

        Example: x.subTensor([1, 2], &#39;:&#39;, [2, 5, 6]) returns a tensor with
        shape [2, self.shape[1], 3].

        Parameters
        ----------
        *indices : list
            The indices to extract in each dimension. &#39;:&#39; indicates all the
            indices.

        Returns
        -------
        FullTensor
            The subtensor.

        &#39;&#39;&#39;
        data = self.data
        order = self.order
        for dim in range(self.order):
            ind_loc = np.atleast_1d(indices[dim])
            if ind_loc.size != 1 or ind_loc[0] != &#39;:&#39;:
                data = np.take(data, ind_loc, axis=dim)
                if order != data.ndim:
                    data = np.expand_dims(data, dim)
                order = data.ndim
        return FullTensor(data)

    def cat(self, tensor2, dims=None):
        &#39;&#39;&#39;
        Concatenate the tensors.

        Concatenates self and tensor2 in a tensor z such that:
        z(i_1 ,..., i_d) = x(i_1, ..., i_d) if i_k &lt;= sz[k]-1 for k in dims,
        z(i_1, ..., i_d) = y(i_1-sz[0], ..., i_d-sz[d-1]) if i_k &gt;= sz[k]
        for k in dims,
        z(i_1, ..., i_d) = 0 otherwise, with sz = self.shape and
        dims = range(self.order) if not provided.

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor to be concatenaed.
        dims : list or numpy.ndarray, optional
            The dimensions of the concatenation. The default is None,
            indicating all the dimensions.
        Returns
        -------
        data : FullTensor
            The concatenated tensors.

        &#39;&#39;&#39;
        assert self.order == tensor2.order, \
            &#39;The orders of the tensors must be equal.&#39;

        tensor1 = FullTensor(self)
        order = self.order
        shape1 = np.atleast_1d(self.shape)
        shape2 = np.atleast_1d(tensor2.shape)

        if dims is None:
            dims = range(self.order)

        dims = np.atleast_1d(dims)
        dims_not = tensap.fast_setdiff(np.arange(order), dims)
        assert np.all([a == b for a, b in zip(shape1[dims_not],
                                              shape2[dims_not])]), \
            &#39;The dimensions of the tensors are not compatible.&#39;

        if dims.size == 1:
            data = np.concatenate([tensor1.data, tensor2.data], dims[0])
        else:
            shape_out = np.array(shape1)
            shape_out[dims] = shape1[dims] + shape2[dims]

            padding = np.transpose([[0]*order, shape_out - shape1])
            data = np.pad(tensor1.data, padding)
            padding = np.transpose([shape_out - shape2, [0]*order])
            data += np.pad(tensor2.data, padding)

        return FullTensor(data)

    def reduce_sum(self, dims=None):
        &#39;&#39;&#39;
        Compute the sum of elements across dimensions dims of a tensor.

        Similar to tensorflow.reduce_sum.

        Parameters
        ----------
        dims : list or numpy.ndarray, optional
            The dimensions to be reduced. The default is None, indicating all
            the dimensions.

        Returns
        -------
        FullTensor
            The reduced tensor.

        &#39;&#39;&#39;
        return FullTensor(np.sum(self.data, dims, keepdims=True))

    def reduce_mean(self, dims=None):
        &#39;&#39;&#39;
        Compute the mean of elements across dimensions dims of a tensor.

        Similar to tensorflow.mean.

        Parameters
        ----------
        dims : list or numpy.ndarray, optional
            The dimensions to be reduced. The default is None, indicating all
            the dimensions.

        Returns
        -------
        FullTensor
            The reduced tensor.

        &#39;&#39;&#39;
        return FullTensor(np.mean(self.data, dims, keepdims=True))

    def kron(self, tensor2):
        &#39;&#39;&#39;
        Kronecker product of tensors.

        Similar to numpy.kron but for arbitrary tensors.

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor of the Kronecker product.

        Returns
        -------
        FullTensor
            The tensor resulting from the Kronecker product.

        &#39;&#39;&#39;
        order1 = self.order
        order2 = tensor2.order
        order_max = np.max((order1, order2))

        shape1 = np.concatenate((self.shape,
                                np.ones(order_max - order1, dtype=int)))
        shape2 = np.concatenate((tensor2.shape,
                                np.ones(order_max - order2, dtype=int)))

        data1 = np.reshape(self.data, [-1, 1])
        data2 = np.reshape(tensor2.data, [1, -1])

        perm = np.reshape(np.transpose(np.reshape(np.arange(2*order_max),
                                                  [2, order_max])),
                          2*order_max)

        data = np.reshape(np.transpose(np.reshape(np.matmul(data1, data2),
                                                  np.concatenate((shape1,
                                                                  shape2))),
                                       perm), shape1 * shape2)
        return FullTensor(data, shape=self.shape*tensor2.shape)

    def orth(self, dim=None):
        &#39;&#39;&#39;
        Orthogonalize the tensor.

        Parameters
        ----------
        dim : int, optional
            The dimension of the orthogonal dim-matricization of self. The
            default is None, returning a copy of the original tensor.

        Returns
        -------
        tensor : FullTensor
            A tensor whose dim-matricization is an orthogonal matrix
            corresponding to the Q factor of a QR factorization of the
            dim-matricization of self.
        r_matrix : numpy.ndarray
            The R factor.

        &#39;&#39;&#39;
        tensor = FullTensor(self)  # Copy the tensor

        if dim is None:
            return tensor, np.array([])

        if dim == -1:
            dim = tensor.order-1

        dims = np.concatenate((np.arange(dim),
                               np.arange(dim+1, tensor.order),
                               [dim]))
        tensor = tensor.transpose(dims)

        shape0 = np.array(tensor.shape)
        tensor = tensor.reshape([np.prod(shape0[:-1]), shape0[-1]])

        try:
            from tensorflow.python.ops.gen_linalg_ops import qr
            q_tf, r_tf = qr(tensor.data, full_matrices=False)
            tensor.data, r_matrix = q_tf.numpy(), r_tf.numpy()
        except ImportError:
            tensor.data, r_matrix = np.linalg.qr(tensor.data)

        shape0[-1] = r_matrix.shape[0]
        tensor = tensor.reshape(shape0)
        tensor = tensor.itranspose(dims)
        tensor.is_orth = True
        tensor.orth_dim = dim
        return tensor, r_matrix

    def dot_with_rank_one_metric(self, tensor2, matrix):
        &#39;&#39;&#39;
        Compute the weighted inner product of two tensors.

        Compute the weighted canonical inner product of self and tensor2,
        where the inner product related to dimension k is weighted by
        matrix[k]. It is equivalent to
        self.dot(tensor2.tensor_matrix_product(matrix)),
        but can be much faster.

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor of the inner product.
        matrix : list or numpy.ndarray or FullTensor
            The weight matrix.

        Returns
        -------
        numpy.float
            The weighted inner product.

        &#39;&#39;&#39;
        return self.dot(tensor2.tensor_matrix_product(matrix))

    def tensordot_matrix_product_except_dim(self, tensor2, matrices, dim):
        &#39;&#39;&#39;
        Particular type of contraction.

        Compute a special contraction of two tensors self, tensor2, a list of
        matrices matrices and a particular dimension dim. Note that dim must
        be a scalar, while matrices must be a list array with self.order
        elements.

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor of the contraction.
        matrices : list
            The list of matrices of the contraction.
        dim : int
            The excluded dimension.

        Returns
        -------
        numpy.ndarray
            The result of the contraction.

        &#39;&#39;&#39;
        assert isinstance(matrices, list), &#39;matrices should be a list.&#39;
        assert len(matrices) == self.order, \
            &#39;len(matrices) must be self.order.&#39;

        dims = tensap.fast_setdiff(np.arange(self.order), dim)
        matrices = [matrices[i] for i in dims]
        tmp = tensor2.tensor_matrix_product(matrices, dims)
        tmp = self.tensordot(tmp, dims, dims)
        return tmp

    def tensordot(self, tensor2, dims1, dims2=None):
        &#39;&#39;&#39;
        Contract two tensors along specified dimensions.

        Similar to tensorflow.tensordot.

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor of the contraction.
        dims1 : list or int
            The dimensions of contractions for the first tensor.
        dims2 : list or int, optional
            The dimensions of contractions for the second tensor. The default
            is None which indicates, if dims1 = 0, to perform the outer
            product of the two tensors, similarly to tensorflow.tensordot.

        Returns
        -------
        out : FullTensor
            The resulting tensor.

        &#39;&#39;&#39;
        dims1 = np.atleast_1d(dims1)
        if dims1.size == 1 and dims1 == 0 and dims2 is None:
            # Outer product (notation similar to tensorflow)
            out = FullTensor(np.tensordot(self.data, tensor2.data, 0))
        else:
            dims2 = np.atleast_1d(dims2)
            assert np.all([self.shape[i] == tensor2.shape[j] for i, j in
                           zip(dims1, dims2)]), \
                &#39;The dimensions of the tensors are not compatible.&#39;
            out = FullTensor(np.tensordot(self.data, tensor2.data,
                                          [dims1, dims2]))
        return out

    def tensordot_eval_diag(self, tensor2, dims1, dims2, diag_dims1,
                            diag_dims2, diag=False):
        &#39;&#39;&#39;
        Evaluate of the diagonal of a tensor obtained by contraction of two
        tensors.

        The contraction is performed along the dimensions dims1 for self and
        dims2 for tensor2, and the diagonal is evaluated according to the
        dimensions diag_dims1 for self and diag_dims2 for tensor2.

        The boolean diag indicates if the several diagonals are evaluated, for
        instance:
        - if diag is False, for order-4 tensors x and y,
        z = x.tensordot_eval_diag(y,[1,3],[2,3],2,0) returns an order-3 tensor
        z(i1,k,j2) = sum_{l1,l2} x(i1,l1,k,l2) y(k,j2,l1,l2)
        - if diag is True, for order-5 tensors x and y,
        z = x.tensordot_eval_diag(y,[1,3],[2,3],[0,2],[1,4]) returns an
        order-4 tensor
        z(k,l,i5,j1) = sum_{l1,l2} x(k,l1,l,l2,i5) y(j1,k,l1,l2,l)

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor of the product.
        dims1 : list or numpy.ndarray
            Dimensions of the first tensor for the contraction.
        dims2 : list or numpy.ndarray
            Dimensions of the second tensor for the contraction.
        diag_dims1 : list or numpy.ndarray
            Indices of the first tensor for the evaluation of the diagonal.
        diag_dims2 : list or numpy.ndarray
            Indices of the second tensor for the evaluation of the diagonal.
        diag : bool, optional
            Boolean enabling the evaluation of multiple diagonals. The default
            is False.

        Returns
        -------
        FullTensor
            The evaluated tensor.

        &#39;&#39;&#39;
        # Check if an outer product is asked with dims1 and dims2 equal to None
        if dims1 is None and dims2 is None:
            dims1 = []
            dims2 = []

        dims1 = np.atleast_1d(dims1)
        dims2 = np.atleast_1d(dims2)
        diag_dims1 = np.atleast_1d(diag_dims1)
        diag_dims2 = np.atleast_1d(diag_dims2)

        ind1 = np.arange(self.ndim)
        ind2 = ind1.size + np.arange(tensor2.ndim)
        if diag and diag_dims1.size != 0 and diag_dims2.size != 0:
            ind2[diag_dims2] = ind1[diag_dims1]
        elif not diag:
            ind1[diag_dims1] = ind1[diag_dims1[0]]
            ind2[diag_dims2] = ind1[diag_dims1[0]]
        if dims1.size != 0 and dims2.size != 0:
            ind2[dims2] = ind1[dims1]
        ind12 = np.concatenate((ind1, ind2))
        indexes = np.unique(ind12, return_index=True)[1]
        # Retain only the unique values without sorting the vector
        ind_out = np.array([ind12[index] for index in sorted(indexes)])
        # Remove from ind_out the contracted dimensions without sorting it
        ind_out = ind_out[[i not in np.atleast_1d(dims1) for i in ind_out]]
        array = np.einsum(self.data, ind1.tolist(), tensor2.data,
                          ind2.tolist(), ind_out.tolist())
        # alph = list(ascii_lowercase)
        # ind1 = [alph[i] for i in ind1]
        # ind2 = [alph[i] for i in ind2]
        # ind_out = [alph[i] for i in ind_out]
        # array = np.einsum(&#39;&#39;.join(ind1) + &#39;, &#39; + &#39;&#39;.join(ind2) + &#39; -&gt; &#39; +
        #                   &#39;&#39;.join(ind_out), self.data, tensor2.data)
        return FullTensor(array)

    def tensor_matrix_product(self, matrices, dims=None):
        &#39;&#39;&#39;
        Contract a tensor with matrices.

        The second dimension of the matrix matrices[k] is contracted with the
        k-th dimension of self, with the indices k given in dims (if provided).

        Parameters
        ----------
        matrices : numpy.ndarray or list of numpy.ndarray
            The matrices to use in the product.
        dims : list or numpy.ndarray, optional
            Indices of the contractions. The default is None, indicating all
            the dimensions.

        Returns
        -------
        FullTensor
            The tensor after the contractions with the matrices.

        &#39;&#39;&#39;
        if dims is None:
            assert isinstance(matrices, (list, np.ndarray)), \
                &#39;matrices should be a list or a numpy.ndarray.&#39;
            assert len(matrices) == self.order, \
                &#39;len(matrices) must be self.order.&#39;
            dims = range(self.order)
        else:
            dims = np.atleast_1d(dims)
            if not isinstance(matrices, list):
                matrices = [matrices]
            assert len(matrices) == dims.size, \
                &#39;len(matrices) must be equal to dims.size.&#39;

        # Numpy implementation
        # matrices = [np.array(x) for x in matrices]
        # data = self.numpy()
        # if self.order == 1:
        #     data = np.matmul(matrices[0], data)
        # else:
        #     k = 0
        #     for dim in np.nditer(dims):
        #         perm_dims = np.concatenate(([dim], np.arange(dim),
        #                                     np.arange(dim+1, self.order)))
        #         data = np.transpose(data, perm_dims)
        #         shape0 = np.array(data.shape)
        #         data = np.reshape(data, [shape0[0], np.prod(shape0[1:])])
        #         data = np.matmul(matrices[k], data)
        #         shape0[0] = matrices[k].shape[0]
        #         data = np.reshape(data, shape0)
        #         data = np.transpose(data, np.argsort(perm_dims))
        #         k += 1
        # return FullTensor(data)

        tensor = FullTensor(self)
        matrices = [FullTensor(x) for x in matrices]
        for i, dim in enumerate(dims):
            index = np.concatenate((
                tensap.fast_setdiff(np.arange(tensor.order), dim), [dim]))
            tensor = tensor.tensordot(matrices[i], dim, 1).itranspose(index)
        return tensor

    def tensor_vector_product(self, vectors, dims=None):
        &#39;&#39;&#39;
        Compute the contraction of the tensor with vectors.

        Compute the contraction of self with each vector contained in the list
        vectors along dimensions specified by dims. The operation is such that
        V[k] is contracted with the dims[k]-th dimension of self.

        Parameters
        ----------
        vectors : numpy.ndarray or list of numpy.ndarray
            The vectors to use in the product.
        dims : list or numpy.ndarray, optional
            Indices of the contractions. The default is None, indicating all
            the dimensions.

        Returns
        -------
        FullTensor
            The tensor after the contractions with the vectors.

        &#39;&#39;&#39;
        if dims is None:
            assert isinstance(vectors, list), &#39;vectors should be a list.&#39;
            assert len(vectors) == self.order, \
                &#39;len(vectors) must be self.order.&#39;
            dims = np.arange(self.order)
        else:
            dims = np.array(dims)
            if not isinstance(vectors, list):
                vectors = [vectors]
            assert len(vectors) == dims.size, \
                &#39;len(vectors) must be equal to dims.size.&#39;

        vectors = [FullTensor(x, 2, [1, -1]) for x in vectors]
        return self.tensor_matrix_product(vectors, dims).squeeze(dims.tolist())

    def tensor_matrix_product_eval_diag(self, matrices, dims=None):
        &#39;&#39;&#39;
        Evaluate the diagonal of a tensor obtained by contraction with
        matrices.

        Provides the diagonal of the tensor obtained by contracting the tensor
        with matrices H[k] along dimensions dims(k)+1, for k = 0, ...,
        dims.size-1.

        Parameters
        ----------
        matrices : list
            The matrices to use in the product.
        dims : list or numpy.ndarray, optional
            Indices of the contractions. The default is None, indicating all
            the dimensions.

        Returns
        -------
        out : FullTensor
            The diagonal of the contractions of the tensor with the matrices.

        &#39;&#39;&#39;
        if dims is None:
            assert isinstance(matrices, list), &#39;matrices should be a list.&#39;
            assert len(matrices) == self.order, \
                &#39;len(matrices) must be self.order.&#39;
            dims = np.arange(self.order)
        else:
            dims = np.atleast_1d(dims)
            if not isinstance(matrices, list):
                matrices = [matrices]
            assert len(matrices) == dims.size, \
                &#39;len(matrices) must be equal to dims.size.&#39;

        matrices = [FullTensor(x) for x in matrices]
        ind = np.flip(np.argsort(dims))
        out = matrices[ind[0]].tensordot(self, 1, dims[ind[0]])
        for i in ind[1:]:
            out = matrices[i].tensordot_eval_diag(out, 1, dims[i]+1, 0, 0)

        # if out.order == 1:
        #     out = out.numpy()
        return out

    def tensor_diagonal_matrix_product(self, matrices, dims=None):
        &#39;&#39;&#39;
        Contract a FullTensor with matrices built from their diagonals.

        The second dimension of the matrix matrices[k] is contracted with the
        k-th dimension of self, with the indices k given in dims (if provided).

        Parameters
        ----------
        matrices : numpy.ndarray or list of numpy.ndarray
            The diagonals of the matrices to use in the product.
        dims : list or numpy.ndarray, optional
            Indices of the contractions. The default is None, indicating all
            the dimensions.

        Returns
        -------
        FullTensor
            The tensor after the contractions with the matrices.

        &#39;&#39;&#39;
        if dims is None:
            assert isinstance(matrices, list), &#39;matrices should be a list.&#39;
            assert len(matrices) == self.order, \
                &#39;len(matrices) must be self.order.&#39;
            dims = range(self.order)
        else:
            dims = np.array(dims)
            if not isinstance(matrices, list):
                matrices = [matrices]
            assert len(matrices) == dims.size, \
                &#39;len(matrices) must be equal to dims.size.&#39;

        matrices = [FullTensor(np.diag(np.reshape(x, [-1])))
                    for x in matrices]
        return self.tensor_matrix_product(matrices, dims)

    def matricize(self, dims1, dims2=None):
        &#39;&#39;&#39;
        Return the matricization of the tensor.

        Parameters
        ----------
        dims1 : list or numpy.ndarray
            The dimensions of the tensor corresponding to the first dimension
            of the matricization.
        dims2 : list or numpy.ndarray, optional
            The dimensions of the tensor corresponding to the first dimension
            of the matricization. The default is None, for which they are
            deduced from dims1.

        Returns
        -------
        FullTensor
            The matricization of the tensor.

        &#39;&#39;&#39;
        dims1 = np.atleast_1d(dims1)
        if dims1.size == 1 and dims1 == -1:
            dims1 = np.array([self.order-1])
        if dims2 is None:
            dims2 = tensap.fast_setdiff(np.arange(self.order), dims1)
        else:
            dims2 = np.atleast_1d(dims2)
        shape1 = [self.shape[i] for i in dims1]
        shape2 = [self.shape[i] for i in dims2]

        tensor = FullTensor(self)
        tensor = tensor.transpose(np.concatenate((dims1, dims2)))
        tensor = tensor.reshape([np.prod(shape1), np.prod(shape2)])
        return FullTensor(tensor)

    def outer_product_eval_diag(self, tensor2, dims1, dims2, diag=False):
        &#39;&#39;&#39;
        Compute the diagonal of the outer product of two tensors.

        Equivalent to
        self.tensordot_eval_diag(tensor2, None, None, dims1, dims2, diag)

        Parameters
        ----------
        tensor2 : FullTensor
            The second tensor of the product.
        dims1 : list or numpy.ndarray
            Indices of the first tensor for the evaluation of the diagonal.
        dims2 : list or numpy.ndarray,
            Indices of the second tensor for the evaluation of the diagonal.
        diag : bool, optional
            Boolean enabling the evaluation of multiple diagonals. The default
            is False.

        Returns
        -------
        FullTensor
            The evaluated tensor.

        &#39;&#39;&#39;
        return self.tensordot_eval_diag(tensor2, None, None,
                                        dims1, dims2, diag)

    def principal_components(self, parameter=None):
        &#39;&#39;&#39;
        Compute the principal components of an order-2 tensor.

        Parameters
        ----------
        parameter : float or int, optional
            A parameter controlling the number of principal components.
            - If it is an integer, the number of principal components is the
            minimum between parameter and self.shape[0].
            - If it is a float smaller than 1, the number of principal
            components is determined such that ||x - VV&#39;x||_F &lt; t ||x||_F,
            with x the tensor, V the matrix of principal components, t the
            parameter, V&#39; the transpose of the matrix V and ||.||_F the
            Frobenius norm.
            The default is self.shape[0].

        Returns
        -------
        principal_components : numpy.ndarray
            The principal components of the tensor.
        singular_values : numpy.ndarray
            The diagonal matrix of the associated singular values.

        &#39;&#39;&#39;
        assert self.order == 2, &#39;The order of the tensor must be 2.&#39;
        if parameter is None or parameter &gt; self.shape[0]:
            parameter = self.shape[0]

        if parameter &lt; 1:
            truncator = tensap.Truncator(tolerance=parameter, max_rank=np.inf)
        else:
            truncator = tensap.Truncator(tolerance=0, max_rank=parameter)
        tensor = truncator.truncate(self)
        principal_components = tensor.space[0]
        singular_values = np.diag(tensor.core.data)
        return principal_components, singular_values

    def alpha_principal_components(self, alpha, parameter=None):
        &#39;&#39;&#39;
        Compute the alpha-principal components of a tensor.

        Return the principal components of the alpha-matricization
        M_alpha(self) of the tensor self of order d.

        See also the method principal_components.

        Parameters
        ----------
        alpha : int
            The index of the alpha-matricization.
        parameter : float or int, optional
            A parameter controlling the number of principal components.
            The default is M_alpha(self).shape[0].

        Returns
        -------
        principal_components : numpy.ndarray
            The principal components of the tensor.
        singular_values : numpy.ndarray
            The diagonal matrix of the associated singular values.

        &#39;&#39;&#39;
        principal_components, singular_values = \
            self.matricize(alpha).principal_components(parameter)
        return principal_components, singular_values

    def singular_values(self):
        &#39;&#39;&#39;
        Compute the higher-order singular values of a tensor (the collection
        of singular values of d different matricizations).

        Returns
        -------
        sin_val : numpy.ndarray or list of numpy.ndarray.
            The higher-order singular values.

        &#39;&#39;&#39;
        if self.order == 2:
            sin_val = np.linalg.svd(self.data, compute_uv=False)
        else:
            sin_val = []
            for ind in range(self.order):
                mat = self.matricize(ind)
                sin_val.append(np.linalg.svd(mat.data,
                                             compute_uv=False))
        return sin_val

    @staticmethod
    def create(generator, shape):
        &#39;&#39;&#39;
        Create a FullTensor of shape shape using a given generator.

        Parameters
        ----------
        generator : function
            Function generating a numpy.ndarray, given a shape.
        shape : numpy.ndarray or list
            The shape of the tensor.

        Returns
        -------
        FullTensor
            The created tensor.

        &#39;&#39;&#39;
        return FullTensor(generator(np.atleast_1d(shape)))

    @staticmethod
    def zeros(shape):
        &#39;&#39;&#39;
        Create a FullTensor of shape shape with entries equal to 0.

        Parameters
        ----------
        shape : numpy.ndarray or list
            The shape of the tensor.

        Returns
        -------
        FullTensor
            The created tensor.

        &#39;&#39;&#39;
        return FullTensor.create(np.zeros, shape)

    @staticmethod
    def ones(shape):
        &#39;&#39;&#39;
        Create a FullTensor of shape shape with entries equal to 1.

        Parameters
        ----------
        shape : numpy.ndarray or list
            The shape of the tensor.

        Returns
        -------
        FullTensor
            The created tensor.

        &#39;&#39;&#39;
        return FullTensor.create(np.ones, shape)

    @staticmethod
    def randn(shape):
        &#39;&#39;&#39;
        Create a FullTensor of shape shape with i.i.d. entries drawn according
        to the standard gaussian distribution.

        Parameters
        ----------
        shape : numpy.ndarray or list
            The shape of the tensor.

        Returns
        -------
        FullTensor
            The created tensor.

        &#39;&#39;&#39;
        return FullTensor.create(lambda x: np.random.randn(*x), shape)

    @staticmethod
    def rand(shape):
        &#39;&#39;&#39;
        Create a FullTensor of shape shape with i.i.d. entries drawn according
        to the uniform distribution on [0, 1].

        Parameters
        ----------
        shape : numpy.ndarray or list
            The shape of the tensor.

        Returns
        -------
        FullTensor
            The created tensor.

        &#39;&#39;&#39;
        return FullTensor.create(lambda x: np.random.rand(*x), shape)

    @staticmethod
    def diag(diag, order):
        &#39;&#39;&#39;
        Create a diagonal tensor x of order order, such that
        x[i, ..., i] = diag[i] for i = 0, ..., diag.size - 1.

        Parameters
        ----------
        diag : list or numpy.ndarray
            The diagonal of the tensor.
        order : int
            The order of the tensor.

        Returns
        -------
        FullTensor
            The created tensor.

        &#39;&#39;&#39;
        diag = np.atleast_1d(diag)

        ones_v = np.ones(order, dtype=int)
        shape_v = diag.size * ones_v

        data = np.zeros(shape_v)
        for ind, diag_ind in enumerate(diag):
            data[tuple(ind * ones_v)] = diag_ind
        return FullTensor(data)</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.create"><code class="name flex">
<span>def <span class="ident">create</span></span>(<span>generator, shape)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a FullTensor of shape shape using a given generator.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>generator</code></strong> :&ensp;<code>function</code></dt>
<dd>Function generating a numpy.ndarray, given a shape.</dd>
<dt><strong><code>shape</code></strong> :&ensp;<code>numpy.ndarray</code> or <code>list</code></dt>
<dd>The shape of the tensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The created tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def create(generator, shape):
    &#39;&#39;&#39;
    Create a FullTensor of shape shape using a given generator.

    Parameters
    ----------
    generator : function
        Function generating a numpy.ndarray, given a shape.
    shape : numpy.ndarray or list
        The shape of the tensor.

    Returns
    -------
    FullTensor
        The created tensor.

    &#39;&#39;&#39;
    return FullTensor(generator(np.atleast_1d(shape)))</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.diag"><code class="name flex">
<span>def <span class="ident">diag</span></span>(<span>diag, order)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a diagonal tensor x of order order, such that
x[i, &hellip;, i] = diag[i] for i = 0, &hellip;, diag.size - 1.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>diag</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The diagonal of the tensor.</dd>
<dt><strong><code>order</code></strong> :&ensp;<code>int</code></dt>
<dd>The order of the tensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The created tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def diag(diag, order):
    &#39;&#39;&#39;
    Create a diagonal tensor x of order order, such that
    x[i, ..., i] = diag[i] for i = 0, ..., diag.size - 1.

    Parameters
    ----------
    diag : list or numpy.ndarray
        The diagonal of the tensor.
    order : int
        The order of the tensor.

    Returns
    -------
    FullTensor
        The created tensor.

    &#39;&#39;&#39;
    diag = np.atleast_1d(diag)

    ones_v = np.ones(order, dtype=int)
    shape_v = diag.size * ones_v

    data = np.zeros(shape_v)
    for ind, diag_ind in enumerate(diag):
        data[tuple(ind * ones_v)] = diag_ind
    return FullTensor(data)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.ones"><code class="name flex">
<span>def <span class="ident">ones</span></span>(<span>shape)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a FullTensor of shape shape with entries equal to 1.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>shape</code></strong> :&ensp;<code>numpy.ndarray</code> or <code>list</code></dt>
<dd>The shape of the tensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The created tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def ones(shape):
    &#39;&#39;&#39;
    Create a FullTensor of shape shape with entries equal to 1.

    Parameters
    ----------
    shape : numpy.ndarray or list
        The shape of the tensor.

    Returns
    -------
    FullTensor
        The created tensor.

    &#39;&#39;&#39;
    return FullTensor.create(np.ones, shape)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.rand"><code class="name flex">
<span>def <span class="ident">rand</span></span>(<span>shape)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a FullTensor of shape shape with i.i.d. entries drawn according
to the uniform distribution on [0, 1].</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>shape</code></strong> :&ensp;<code>numpy.ndarray</code> or <code>list</code></dt>
<dd>The shape of the tensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The created tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def rand(shape):
    &#39;&#39;&#39;
    Create a FullTensor of shape shape with i.i.d. entries drawn according
    to the uniform distribution on [0, 1].

    Parameters
    ----------
    shape : numpy.ndarray or list
        The shape of the tensor.

    Returns
    -------
    FullTensor
        The created tensor.

    &#39;&#39;&#39;
    return FullTensor.create(lambda x: np.random.rand(*x), shape)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.randn"><code class="name flex">
<span>def <span class="ident">randn</span></span>(<span>shape)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a FullTensor of shape shape with i.i.d. entries drawn according
to the standard gaussian distribution.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>shape</code></strong> :&ensp;<code>numpy.ndarray</code> or <code>list</code></dt>
<dd>The shape of the tensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The created tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def randn(shape):
    &#39;&#39;&#39;
    Create a FullTensor of shape shape with i.i.d. entries drawn according
    to the standard gaussian distribution.

    Parameters
    ----------
    shape : numpy.ndarray or list
        The shape of the tensor.

    Returns
    -------
    FullTensor
        The created tensor.

    &#39;&#39;&#39;
    return FullTensor.create(lambda x: np.random.randn(*x), shape)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.zeros"><code class="name flex">
<span>def <span class="ident">zeros</span></span>(<span>shape)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a FullTensor of shape shape with entries equal to 0.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>shape</code></strong> :&ensp;<code>numpy.ndarray</code> or <code>list</code></dt>
<dd>The shape of the tensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The created tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def zeros(shape):
    &#39;&#39;&#39;
    Create a FullTensor of shape shape with entries equal to 0.

    Parameters
    ----------
    shape : numpy.ndarray or list
        The shape of the tensor.

    Returns
    -------
    FullTensor
        The created tensor.

    &#39;&#39;&#39;
    return FullTensor.create(np.zeros, shape)</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.ndim"><code class="name">var <span class="ident">ndim</span></code></dt>
<dd>
<div class="desc"><p>Compute the order of the tensor. Equivalent to self.order.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The order of the tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def ndim(self):
    &#39;&#39;&#39;
    Compute the order of the tensor. Equivalent to self.order.

    Returns
    -------
    int
        The order of the tensor.

    &#39;&#39;&#39;
    return self.data.ndim</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.order"><code class="name">var <span class="ident">order</span></code></dt>
<dd>
<div class="desc"><p>Compute the order of the tensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The order of the tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def order(self):
    &#39;&#39;&#39;
    Compute the order of the tensor.

    Returns
    -------
    int
        The order of the tensor.

    &#39;&#39;&#39;
    return np.ndim(self.data)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.shape"><code class="name">var <span class="ident">shape</span></code></dt>
<dd>
<div class="desc"><p>Compute the shape of the tensor</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The shape of the tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def shape(self):
    &#39;&#39;&#39;
    Compute the shape of the tensor

    Returns
    -------
    numpy.ndarray
        The shape of the tensor.

    &#39;&#39;&#39;
    return np.array(self.data.shape)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.size"><code class="name">var <span class="ident">size</span></code></dt>
<dd>
<div class="desc"><p>Compute the number of elements of the tensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The number of elements of the tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def size(self):
    &#39;&#39;&#39;
    Compute the number of elements of the tensor.

    Returns
    -------
    numpy.ndarray
        The number of elements of the tensor.

    &#39;&#39;&#39;
    return np.array(self.data.shape)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.alpha_principal_components"><code class="name flex">
<span>def <span class="ident">alpha_principal_components</span></span>(<span>self, alpha, parameter=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the alpha-principal components of a tensor.</p>
<p>Return the principal components of the alpha-matricization
M_alpha(self) of the tensor self of order d.</p>
<p>See also the method principal_components.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>alpha</code></strong> :&ensp;<code>int</code></dt>
<dd>The index of the alpha-matricization.</dd>
<dt><strong><code>parameter</code></strong> :&ensp;<code>float</code> or <code>int</code>, optional</dt>
<dd>A parameter controlling the number of principal components.
The default is M_alpha(self).shape[0].</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>principal_components</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The principal components of the tensor.</dd>
<dt><strong><code>singular_values</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The diagonal matrix of the associated singular values.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def alpha_principal_components(self, alpha, parameter=None):
    &#39;&#39;&#39;
    Compute the alpha-principal components of a tensor.

    Return the principal components of the alpha-matricization
    M_alpha(self) of the tensor self of order d.

    See also the method principal_components.

    Parameters
    ----------
    alpha : int
        The index of the alpha-matricization.
    parameter : float or int, optional
        A parameter controlling the number of principal components.
        The default is M_alpha(self).shape[0].

    Returns
    -------
    principal_components : numpy.ndarray
        The principal components of the tensor.
    singular_values : numpy.ndarray
        The diagonal matrix of the associated singular values.

    &#39;&#39;&#39;
    principal_components, singular_values = \
        self.matricize(alpha).principal_components(parameter)
    return principal_components, singular_values</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.cat"><code class="name flex">
<span>def <span class="ident">cat</span></span>(<span>self, tensor2, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Concatenate the tensors.</p>
<p>Concatenates self and tensor2 in a tensor z such that:
z(i_1 ,&hellip;, i_d) = x(i_1, &hellip;, i_d) if i_k &lt;= sz[k]-1 for k in dims,
z(i_1, &hellip;, i_d) = y(i_1-sz[0], &hellip;, i_d-sz[d-1]) if i_k &gt;= sz[k]
for k in dims,
z(i_1, &hellip;, i_d) = 0 otherwise, with sz = self.shape and
dims = range(self.order) if not provided.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tensor2</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The second tensor to be concatenaed.</dd>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>The dimensions of the concatenation. The default is None,
indicating all the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The concatenated tensors.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cat(self, tensor2, dims=None):
    &#39;&#39;&#39;
    Concatenate the tensors.

    Concatenates self and tensor2 in a tensor z such that:
    z(i_1 ,..., i_d) = x(i_1, ..., i_d) if i_k &lt;= sz[k]-1 for k in dims,
    z(i_1, ..., i_d) = y(i_1-sz[0], ..., i_d-sz[d-1]) if i_k &gt;= sz[k]
    for k in dims,
    z(i_1, ..., i_d) = 0 otherwise, with sz = self.shape and
    dims = range(self.order) if not provided.

    Parameters
    ----------
    tensor2 : FullTensor
        The second tensor to be concatenaed.
    dims : list or numpy.ndarray, optional
        The dimensions of the concatenation. The default is None,
        indicating all the dimensions.
    Returns
    -------
    data : FullTensor
        The concatenated tensors.

    &#39;&#39;&#39;
    assert self.order == tensor2.order, \
        &#39;The orders of the tensors must be equal.&#39;

    tensor1 = FullTensor(self)
    order = self.order
    shape1 = np.atleast_1d(self.shape)
    shape2 = np.atleast_1d(tensor2.shape)

    if dims is None:
        dims = range(self.order)

    dims = np.atleast_1d(dims)
    dims_not = tensap.fast_setdiff(np.arange(order), dims)
    assert np.all([a == b for a, b in zip(shape1[dims_not],
                                          shape2[dims_not])]), \
        &#39;The dimensions of the tensors are not compatible.&#39;

    if dims.size == 1:
        data = np.concatenate([tensor1.data, tensor2.data], dims[0])
    else:
        shape_out = np.array(shape1)
        shape_out[dims] = shape1[dims] + shape2[dims]

        padding = np.transpose([[0]*order, shape_out - shape1])
        data = np.pad(tensor1.data, padding)
        padding = np.transpose([shape_out - shape2, [0]*order])
        data += np.pad(tensor2.data, padding)

    return FullTensor(data)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.dot"><code class="name flex">
<span>def <span class="ident">dot</span></span>(<span>self, tensor2)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the inner product of two tensors.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tensor2</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The second tensor of the inner products.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.float</code></dt>
<dd>The inner product of the two tensors.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dot(self, tensor2):
    &#39;&#39;&#39;
    Return the inner product of two tensors.

    Parameters
    ----------
    tensor2 : FullTensor
        The second tensor of the inner products.

    Returns
    -------
    numpy.float
        The inner product of the two tensors.

    &#39;&#39;&#39;
    return np.sum(np.multiply(self.data, tensor2.data))</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.dot_with_rank_one_metric"><code class="name flex">
<span>def <span class="ident">dot_with_rank_one_metric</span></span>(<span>self, tensor2, matrix)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the weighted inner product of two tensors.</p>
<p>Compute the weighted canonical inner product of self and tensor2,
where the inner product related to dimension k is weighted by
matrix[k]. It is equivalent to
self.dot(tensor2.tensor_matrix_product(matrix)),
but can be much faster.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tensor2</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The second tensor of the inner product.</dd>
<dt><strong><code>matrix</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code> or <code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The weight matrix.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.float</code></dt>
<dd>The weighted inner product.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dot_with_rank_one_metric(self, tensor2, matrix):
    &#39;&#39;&#39;
    Compute the weighted inner product of two tensors.

    Compute the weighted canonical inner product of self and tensor2,
    where the inner product related to dimension k is weighted by
    matrix[k]. It is equivalent to
    self.dot(tensor2.tensor_matrix_product(matrix)),
    but can be much faster.

    Parameters
    ----------
    tensor2 : FullTensor
        The second tensor of the inner product.
    matrix : list or numpy.ndarray or FullTensor
        The weight matrix.

    Returns
    -------
    numpy.float
        The weighted inner product.

    &#39;&#39;&#39;
    return self.dot(tensor2.tensor_matrix_product(matrix))</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.eval_at_indices"><code class="name flex">
<span>def <span class="ident">eval_at_indices</span></span>(<span>self, indices, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate the tensor at indices.</p>
<p>If dims is None, return
s(k) = x(indices(k, 1), indices(k, 2), &hellip;, indices(k, d)),
1 &lt;= k &lt;= self.shape[0].</p>
<p>If dims is not None, return a partial evaluation: up to a permutation
(placing the dimensions dims on the left), return
s(k, i_1, &hellip;, i_d') = x(indices(k, 1), indices(k, 2), &hellip;,
indices(k, M), i_1, &hellip;, i_d'),
1 &lt;= k &lt;= self.shape[0], with M = dims.size and d' = self.order - M.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>indices</code></strong> :&ensp;<code>list</code> of <code>numpy.ndarray</code></dt>
<dd>The indices of the tensor.</dd>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> of <code>numpy.ndarray</code>, optional</dt>
<dd>The dimensions associated with the indices. The default is None,
indicating that indices refers to all the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>evaluations</code></strong> :&ensp;<code>numpy.ndarray</code> or <code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The evaluations of the tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval_at_indices(self, indices, dims=None):
    &#39;&#39;&#39;
    Evaluate the tensor at indices.

    If dims is None, return
    s(k) = x(indices(k, 1), indices(k, 2), ..., indices(k, d)),
    1 &lt;= k &lt;= self.shape[0].

    If dims is not None, return a partial evaluation: up to a permutation
    (placing the dimensions dims on the left), return
    s(k, i_1, ..., i_d&#39;) = x(indices(k, 1), indices(k, 2), ...,
    indices(k, M), i_1, ..., i_d&#39;),
    1 &lt;= k &lt;= self.shape[0], with M = dims.size and d&#39; = self.order - M.

    Parameters
    ----------
    indices : list of numpy.ndarray
        The indices of the tensor.
    dims : list of numpy.ndarray, optional
        The dimensions associated with the indices. The default is None,
        indicating that indices refers to all the dimensions.

    Returns
    -------
    evaluations : numpy.ndarray or FullTensor
        The evaluations of the tensor.

    &#39;&#39;&#39;
    indices = np.atleast_2d(indices)
    if dims is None:
        dims = np.arange(self.order)
    else:
        dims = np.atleast_1d(dims)
        if indices.shape[1] != dims.size:
            indices = np.transpose(indices)
        assert dims.size == indices.shape[1], \
            &#39;Wrong size of multi-indices.&#39;
        sort_ind = np.argsort(dims)
        dims = dims[sort_ind]
        indices = indices[:, sort_ind]
    assert dims.size == indices.shape[1], &#39;Wrong size of multi-indices.&#39;

    if dims.size == self.order:
        data = self
        evaluations = np.array([data[tuple(i)] for i in indices.tolist()])
    elif dims.size == 1:
        ind = [&#39;:&#39;]*self.order
        ind[dims[0]] = np.ravel(indices).tolist()
        evaluations = self.sub_tensor(*ind)
    else:
        no_dims = tensap.fast_setdiff(np.arange(self.order), dims)
        indices = np.ravel_multi_index(np.transpose(indices),
                                       [self.shape[i] for i in dims])
        evaluations = self.matricize(dims).sub_tensor(indices, &#39;:&#39;)
        evaluations = evaluations.reshape([indices.size] +
                                          [self.shape[i] for i in no_dims])
        left_dims = np.arange(dims[0])
        evaluations = evaluations.transpose(
            np.concatenate((np.arange(1, left_dims.size + 1), [0],
                            np.arange(left_dims.size + 1,
                                      self.order - dims.size + 1))))
    return evaluations</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.eval_diag"><code class="name flex">
<span>def <span class="ident">eval_diag</span></span>(<span>self, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Extract the diagonal of the tensor.</p>
<p>The tensor must be such that self.shape[mu] = n for all mu (in dims if
provided).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> of <code>numpy.ndarray</code>, optional</dt>
<dd>The dimensions associated with the indices of the diagonal. The
default is None,indicating that the indices refer to all the
dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The evaluations of the diagonal of the tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval_diag(self, dims=None):
    &#39;&#39;&#39;
    Extract the diagonal of the tensor.

    The tensor must be such that self.shape[mu] = n for all mu (in dims if
    provided).

    Parameters
    ----------
    dims : list of numpy.ndarray, optional
        The dimensions associated with the indices of the diagonal. The
        default is None,indicating that the indices refer to all the
        dimensions.

    Returns
    -------
    data : numpy.ndarray
        The evaluations of the diagonal of the tensor.

    &#39;&#39;&#39;
    if dims is None:
        dims = np.arange(self.order)
    else:
        dims = np.atleast_1d(dims)

    if dims.size == 1:
        data = self
    else:
        assert np.all([self.shape[x] == self.shape[dims[0]] for
                       x in dims]),\
         &#39;The shapes of the tensor in dimensions dims should be equal.&#39;
        ind = np.repeat(np.reshape(np.arange(self.shape[dims[0]]),
                                   [-1, 1]), dims.size, 1)
        data = self.eval_at_indices(ind, dims)
    return data</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.full"><code class="name flex">
<span>def <span class="ident">full</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the tensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def full(self):
    &#39;&#39;&#39;
    Return the tensor.

    Returns
    -------
    FullTensor
        The tensor.

    &#39;&#39;&#39;
    return self</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.hadamard_product"><code class="name flex">
<span>def <span class="ident">hadamard_product</span></span>(<span>self, arg)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the Hadamard product of two tensors.</p>
<p>Equivalent to self * arg.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>arg</code></strong> :&ensp;<code>tensap.FullTensor</code> or <code>numpy.ndarray</code></dt>
<dd>The second tensor of the Hadamard product.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The tensor resulting from the Hadamard product.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def hadamard_product(self, arg):
    &#39;&#39;&#39;
    Compute the Hadamard product of two tensors.

    Equivalent to self * arg.

    Parameters
    ----------
    arg : tensap.FullTensor or numpy.ndarray
        The second tensor of the Hadamard product.

    Returns
    -------
    FullTensor
        The tensor resulting from the Hadamard product.

    &#39;&#39;&#39;
    return self * arg</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.itranspose"><code class="name flex">
<span>def <span class="ident">itranspose</span></span>(<span>self, dims)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the inverse transpose (permutation) of the dimensions of the
tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The original transpose (permutation) indices.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The transposed (permuted) tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def itranspose(self, dims):
    &#39;&#39;&#39;
    Return the inverse transpose (permutation) of the dimensions of the
    tensor.

    Parameters
    ----------
    dims : list or numpy.ndarray
        The original transpose (permutation) indices.

    Returns
    -------
    FullTensor
        The transposed (permuted) tensor.

    &#39;&#39;&#39;
    return self.transpose(np.argsort(dims))</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.kron"><code class="name flex">
<span>def <span class="ident">kron</span></span>(<span>self, tensor2)</span>
</code></dt>
<dd>
<div class="desc"><p>Kronecker product of tensors.</p>
<p>Similar to numpy.kron but for arbitrary tensors.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tensor2</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The second tensor of the Kronecker product.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The tensor resulting from the Kronecker product.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def kron(self, tensor2):
    &#39;&#39;&#39;
    Kronecker product of tensors.

    Similar to numpy.kron but for arbitrary tensors.

    Parameters
    ----------
    tensor2 : FullTensor
        The second tensor of the Kronecker product.

    Returns
    -------
    FullTensor
        The tensor resulting from the Kronecker product.

    &#39;&#39;&#39;
    order1 = self.order
    order2 = tensor2.order
    order_max = np.max((order1, order2))

    shape1 = np.concatenate((self.shape,
                            np.ones(order_max - order1, dtype=int)))
    shape2 = np.concatenate((tensor2.shape,
                            np.ones(order_max - order2, dtype=int)))

    data1 = np.reshape(self.data, [-1, 1])
    data2 = np.reshape(tensor2.data, [1, -1])

    perm = np.reshape(np.transpose(np.reshape(np.arange(2*order_max),
                                              [2, order_max])),
                      2*order_max)

    data = np.reshape(np.transpose(np.reshape(np.matmul(data1, data2),
                                              np.concatenate((shape1,
                                                              shape2))),
                                   perm), shape1 * shape2)
    return FullTensor(data, shape=self.shape*tensor2.shape)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.matricize"><code class="name flex">
<span>def <span class="ident">matricize</span></span>(<span>self, dims1, dims2=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the matricization of the tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims1</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The dimensions of the tensor corresponding to the first dimension
of the matricization.</dd>
<dt><strong><code>dims2</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>The dimensions of the tensor corresponding to the first dimension
of the matricization. The default is None, for which they are
deduced from dims1.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The matricization of the tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def matricize(self, dims1, dims2=None):
    &#39;&#39;&#39;
    Return the matricization of the tensor.

    Parameters
    ----------
    dims1 : list or numpy.ndarray
        The dimensions of the tensor corresponding to the first dimension
        of the matricization.
    dims2 : list or numpy.ndarray, optional
        The dimensions of the tensor corresponding to the first dimension
        of the matricization. The default is None, for which they are
        deduced from dims1.

    Returns
    -------
    FullTensor
        The matricization of the tensor.

    &#39;&#39;&#39;
    dims1 = np.atleast_1d(dims1)
    if dims1.size == 1 and dims1 == -1:
        dims1 = np.array([self.order-1])
    if dims2 is None:
        dims2 = tensap.fast_setdiff(np.arange(self.order), dims1)
    else:
        dims2 = np.atleast_1d(dims2)
    shape1 = [self.shape[i] for i in dims1]
    shape2 = [self.shape[i] for i in dims2]

    tensor = FullTensor(self)
    tensor = tensor.transpose(np.concatenate((dims1, dims2)))
    tensor = tensor.reshape([np.prod(shape1), np.prod(shape2)])
    return FullTensor(tensor)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.norm"><code class="name flex">
<span>def <span class="ident">norm</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the canonical norm of the FullTensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.float</code></dt>
<dd>The norm of the tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def norm(self):
    &#39;&#39;&#39;
    Compute the canonical norm of the FullTensor.

    Returns
    -------
    numpy.float
        The norm of the tensor.

    &#39;&#39;&#39;
    return np.linalg.norm(self.data)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.numpy"><code class="name flex">
<span>def <span class="ident">numpy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert the FullTensor to a numpy.ndarray.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The FullTensor as a numpy.ndarray.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def numpy(self):
    &#39;&#39;&#39;
    Convert the FullTensor to a numpy.ndarray.

    Returns
    -------
    numpy.ndarray
        The FullTensor as a numpy.ndarray.

    &#39;&#39;&#39;
    return self.data</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.orth"><code class="name flex">
<span>def <span class="ident">orth</span></span>(<span>self, dim=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Orthogonalize the tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dim</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The dimension of the orthogonal dim-matricization of self. The
default is None, returning a copy of the original tensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tensor</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>A tensor whose dim-matricization is an orthogonal matrix
corresponding to the Q factor of a QR factorization of the
dim-matricization of self.</dd>
<dt><strong><code>r_matrix</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The R factor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def orth(self, dim=None):
    &#39;&#39;&#39;
    Orthogonalize the tensor.

    Parameters
    ----------
    dim : int, optional
        The dimension of the orthogonal dim-matricization of self. The
        default is None, returning a copy of the original tensor.

    Returns
    -------
    tensor : FullTensor
        A tensor whose dim-matricization is an orthogonal matrix
        corresponding to the Q factor of a QR factorization of the
        dim-matricization of self.
    r_matrix : numpy.ndarray
        The R factor.

    &#39;&#39;&#39;
    tensor = FullTensor(self)  # Copy the tensor

    if dim is None:
        return tensor, np.array([])

    if dim == -1:
        dim = tensor.order-1

    dims = np.concatenate((np.arange(dim),
                           np.arange(dim+1, tensor.order),
                           [dim]))
    tensor = tensor.transpose(dims)

    shape0 = np.array(tensor.shape)
    tensor = tensor.reshape([np.prod(shape0[:-1]), shape0[-1]])

    try:
        from tensorflow.python.ops.gen_linalg_ops import qr
        q_tf, r_tf = qr(tensor.data, full_matrices=False)
        tensor.data, r_matrix = q_tf.numpy(), r_tf.numpy()
    except ImportError:
        tensor.data, r_matrix = np.linalg.qr(tensor.data)

    shape0[-1] = r_matrix.shape[0]
    tensor = tensor.reshape(shape0)
    tensor = tensor.itranspose(dims)
    tensor.is_orth = True
    tensor.orth_dim = dim
    return tensor, r_matrix</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.outer_product_eval_diag"><code class="name flex">
<span>def <span class="ident">outer_product_eval_diag</span></span>(<span>self, tensor2, dims1, dims2, diag=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the diagonal of the outer product of two tensors.</p>
<p>Equivalent to
self.tensordot_eval_diag(tensor2, None, None, dims1, dims2, diag)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tensor2</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The second tensor of the product.</dd>
<dt><strong><code>dims1</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>Indices of the first tensor for the evaluation of the diagonal.</dd>
<dt><strong><code>dims2</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray,</code></dt>
<dd>Indices of the second tensor for the evaluation of the diagonal.</dd>
<dt><strong><code>diag</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Boolean enabling the evaluation of multiple diagonals. The default
is False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The evaluated tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def outer_product_eval_diag(self, tensor2, dims1, dims2, diag=False):
    &#39;&#39;&#39;
    Compute the diagonal of the outer product of two tensors.

    Equivalent to
    self.tensordot_eval_diag(tensor2, None, None, dims1, dims2, diag)

    Parameters
    ----------
    tensor2 : FullTensor
        The second tensor of the product.
    dims1 : list or numpy.ndarray
        Indices of the first tensor for the evaluation of the diagonal.
    dims2 : list or numpy.ndarray,
        Indices of the second tensor for the evaluation of the diagonal.
    diag : bool, optional
        Boolean enabling the evaluation of multiple diagonals. The default
        is False.

    Returns
    -------
    FullTensor
        The evaluated tensor.

    &#39;&#39;&#39;
    return self.tensordot_eval_diag(tensor2, None, None,
                                    dims1, dims2, diag)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.principal_components"><code class="name flex">
<span>def <span class="ident">principal_components</span></span>(<span>self, parameter=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the principal components of an order-2 tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>parameter</code></strong> :&ensp;<code>float</code> or <code>int</code>, optional</dt>
<dd>A parameter controlling the number of principal components.
- If it is an integer, the number of principal components is the
minimum between parameter and self.shape[0].
- If it is a float smaller than 1, the number of principal
components is determined such that ||x - VV'x||_F &lt; t ||x||_F,
with x the tensor, V the matrix of principal components, t the
parameter, V' the transpose of the matrix V and ||.||_F the
Frobenius norm.
The default is self.shape[0].</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>principal_components</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The principal components of the tensor.</dd>
<dt><strong><code>singular_values</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The diagonal matrix of the associated singular values.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def principal_components(self, parameter=None):
    &#39;&#39;&#39;
    Compute the principal components of an order-2 tensor.

    Parameters
    ----------
    parameter : float or int, optional
        A parameter controlling the number of principal components.
        - If it is an integer, the number of principal components is the
        minimum between parameter and self.shape[0].
        - If it is a float smaller than 1, the number of principal
        components is determined such that ||x - VV&#39;x||_F &lt; t ||x||_F,
        with x the tensor, V the matrix of principal components, t the
        parameter, V&#39; the transpose of the matrix V and ||.||_F the
        Frobenius norm.
        The default is self.shape[0].

    Returns
    -------
    principal_components : numpy.ndarray
        The principal components of the tensor.
    singular_values : numpy.ndarray
        The diagonal matrix of the associated singular values.

    &#39;&#39;&#39;
    assert self.order == 2, &#39;The order of the tensor must be 2.&#39;
    if parameter is None or parameter &gt; self.shape[0]:
        parameter = self.shape[0]

    if parameter &lt; 1:
        truncator = tensap.Truncator(tolerance=parameter, max_rank=np.inf)
    else:
        truncator = tensap.Truncator(tolerance=0, max_rank=parameter)
    tensor = truncator.truncate(self)
    principal_components = tensor.space[0]
    singular_values = np.diag(tensor.core.data)
    return principal_components, singular_values</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.reduce_mean"><code class="name flex">
<span>def <span class="ident">reduce_mean</span></span>(<span>self, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the mean of elements across dimensions dims of a tensor.</p>
<p>Similar to tensorflow.mean.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>The dimensions to be reduced. The default is None, indicating all
the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The reduced tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reduce_mean(self, dims=None):
    &#39;&#39;&#39;
    Compute the mean of elements across dimensions dims of a tensor.

    Similar to tensorflow.mean.

    Parameters
    ----------
    dims : list or numpy.ndarray, optional
        The dimensions to be reduced. The default is None, indicating all
        the dimensions.

    Returns
    -------
    FullTensor
        The reduced tensor.

    &#39;&#39;&#39;
    return FullTensor(np.mean(self.data, dims, keepdims=True))</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.reduce_sum"><code class="name flex">
<span>def <span class="ident">reduce_sum</span></span>(<span>self, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the sum of elements across dimensions dims of a tensor.</p>
<p>Similar to tensorflow.reduce_sum.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>The dimensions to be reduced. The default is None, indicating all
the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The reduced tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reduce_sum(self, dims=None):
    &#39;&#39;&#39;
    Compute the sum of elements across dimensions dims of a tensor.

    Similar to tensorflow.reduce_sum.

    Parameters
    ----------
    dims : list or numpy.ndarray, optional
        The dimensions to be reduced. The default is None, indicating all
        the dimensions.

    Returns
    -------
    FullTensor
        The reduced tensor.

    &#39;&#39;&#39;
    return FullTensor(np.sum(self.data, dims, keepdims=True))</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.reshape"><code class="name flex">
<span>def <span class="ident">reshape</span></span>(<span>self, shape)</span>
</code></dt>
<dd>
<div class="desc"><p>Reshape the tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>shape</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The new shape of the tensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tensor</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The reshaped tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reshape(self, shape):
    &#39;&#39;&#39;
    Reshape the tensor.

    Parameters
    ----------
    shape : list or numpy.ndarray
        The new shape of the tensor.

    Returns
    -------
    tensor : FullTensor
        The reshaped tensor.

    &#39;&#39;&#39;
    tensor = FullTensor(self)
    tensor.data = np.reshape(tensor.data, shape, order=&#39;F&#39;)
    return tensor</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.singular_values"><code class="name flex">
<span>def <span class="ident">singular_values</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the higher-order singular values of a tensor (the collection
of singular values of d different matricizations).</p>
<h2 id="returns">Returns</h2>
<p>sin_val : numpy.ndarray or list of numpy.ndarray.
The higher-order singular values.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def singular_values(self):
    &#39;&#39;&#39;
    Compute the higher-order singular values of a tensor (the collection
    of singular values of d different matricizations).

    Returns
    -------
    sin_val : numpy.ndarray or list of numpy.ndarray.
        The higher-order singular values.

    &#39;&#39;&#39;
    if self.order == 2:
        sin_val = np.linalg.svd(self.data, compute_uv=False)
    else:
        sin_val = []
        for ind in range(self.order):
            mat = self.matricize(ind)
            sin_val.append(np.linalg.svd(mat.data,
                                         compute_uv=False))
    return sin_val</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.sparse"><code class="name flex">
<span>def <span class="ident">sparse</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Conversion of a FullTensor into a SparseTensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensap.SparseTensor</code></dt>
<dd>A SparseTensor representation of the FullTensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sparse(self):
    &#39;&#39;&#39;
    Conversion of a FullTensor into a SparseTensor.

    Returns
    -------
    tensap.SparseTensor
        A SparseTensor representation of the FullTensor.

    &#39;&#39;&#39;
    dat = np.reshape(self.data, -1, order=&#39;F&#39;)
    ind = np.nonzero(dat)[0]
    indices = tensap.MultiIndices.ind2sub(self.shape, ind)
    return tensap.SparseTensor(dat, indices, self.shape)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.sparse_storage"><code class="name flex">
<span>def <span class="ident">sparse_storage</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the sparse storage complexity of the FullTensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The sparse storage complexity of the FullTensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sparse_storage(self):
    &#39;&#39;&#39;
    Return the sparse storage complexity of the FullTensor.

    Returns
    -------
    int
        The sparse storage complexity of the FullTensor.

    &#39;&#39;&#39;
    return np.count_nonzero(self.data)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.squeeze"><code class="name flex">
<span>def <span class="ident">squeeze</span></span>(<span>self, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Remove the singleton dimensions of the tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>Dimensions to squeeze. The default is None, indicating all the
singleton dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>out</code></strong> :&ensp;<code>float</code> or <code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The squeezed tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def squeeze(self, dims=None):
    &#39;&#39;&#39;
    Remove the singleton dimensions of the tensor.

    Parameters
    ----------
    dims : list or numpy.ndarray, optional
        Dimensions to squeeze. The default is None, indicating all the
        singleton dimensions.

    Returns
    -------
    out : float or FullTensor
        The squeezed tensor.

    &#39;&#39;&#39;
    if dims is not None:
        dims = tuple(dims)

    out = FullTensor(np.squeeze(self.data, dims))
    if out.order == 0:
        out = out.data
    return out</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.storage"><code class="name flex">
<span>def <span class="ident">storage</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the storage complexity of the FullTensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The storage complexity of the FullTensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def storage(self):
    &#39;&#39;&#39;
    Return the storage complexity of the FullTensor.

    Returns
    -------
    int
        The storage complexity of the FullTensor.

    &#39;&#39;&#39;
    return np.size(self.data)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.sub_tensor"><code class="name flex">
<span>def <span class="ident">sub_tensor</span></span>(<span>self, *indices)</span>
</code></dt>
<dd>
<div class="desc"><p>Extract a subtensor of the tensor.</p>
<p>The result is a tensor s of shape
len(indices[0]), &hellip;, len(indices[self.order-1]),
such that
s(k1,&hellip;,kd) = x(indices[0][k1], &hellip;, indices[self.order-1][kd]).</p>
<p>Example: x.subTensor([1, 2], ':', [2, 5, 6]) returns a tensor with
shape [2, self.shape[1], 3].</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>*indices</code></strong> :&ensp;<code>list</code></dt>
<dd>The indices to extract in each dimension. ':' indicates all the
indices.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The subtensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sub_tensor(self, *indices):
    &#39;&#39;&#39;
    Extract a subtensor of the tensor.

    The result is a tensor s of shape
    len(indices[0]), ..., len(indices[self.order-1]),
    such that
    s(k1,...,kd) = x(indices[0][k1], ..., indices[self.order-1][kd]).

    Example: x.subTensor([1, 2], &#39;:&#39;, [2, 5, 6]) returns a tensor with
    shape [2, self.shape[1], 3].

    Parameters
    ----------
    *indices : list
        The indices to extract in each dimension. &#39;:&#39; indicates all the
        indices.

    Returns
    -------
    FullTensor
        The subtensor.

    &#39;&#39;&#39;
    data = self.data
    order = self.order
    for dim in range(self.order):
        ind_loc = np.atleast_1d(indices[dim])
        if ind_loc.size != 1 or ind_loc[0] != &#39;:&#39;:
            data = np.take(data, ind_loc, axis=dim)
            if order != data.ndim:
                data = np.expand_dims(data, dim)
            order = data.ndim
    return FullTensor(data)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensor_diagonal_matrix_product"><code class="name flex">
<span>def <span class="ident">tensor_diagonal_matrix_product</span></span>(<span>self, matrices, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Contract a FullTensor with matrices built from their diagonals.</p>
<p>The second dimension of the matrix matrices[k] is contracted with the
k-th dimension of self, with the indices k given in dims (if provided).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>matrices</code></strong> :&ensp;<code>numpy.ndarray</code> or <code>list</code> of <code>numpy.ndarray</code></dt>
<dd>The diagonals of the matrices to use in the product.</dd>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>Indices of the contractions. The default is None, indicating all
the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The tensor after the contractions with the matrices.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensor_diagonal_matrix_product(self, matrices, dims=None):
    &#39;&#39;&#39;
    Contract a FullTensor with matrices built from their diagonals.

    The second dimension of the matrix matrices[k] is contracted with the
    k-th dimension of self, with the indices k given in dims (if provided).

    Parameters
    ----------
    matrices : numpy.ndarray or list of numpy.ndarray
        The diagonals of the matrices to use in the product.
    dims : list or numpy.ndarray, optional
        Indices of the contractions. The default is None, indicating all
        the dimensions.

    Returns
    -------
    FullTensor
        The tensor after the contractions with the matrices.

    &#39;&#39;&#39;
    if dims is None:
        assert isinstance(matrices, list), &#39;matrices should be a list.&#39;
        assert len(matrices) == self.order, \
            &#39;len(matrices) must be self.order.&#39;
        dims = range(self.order)
    else:
        dims = np.array(dims)
        if not isinstance(matrices, list):
            matrices = [matrices]
        assert len(matrices) == dims.size, \
            &#39;len(matrices) must be equal to dims.size.&#39;

    matrices = [FullTensor(np.diag(np.reshape(x, [-1])))
                for x in matrices]
    return self.tensor_matrix_product(matrices, dims)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensor_matrix_product"><code class="name flex">
<span>def <span class="ident">tensor_matrix_product</span></span>(<span>self, matrices, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Contract a tensor with matrices.</p>
<p>The second dimension of the matrix matrices[k] is contracted with the
k-th dimension of self, with the indices k given in dims (if provided).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>matrices</code></strong> :&ensp;<code>numpy.ndarray</code> or <code>list</code> of <code>numpy.ndarray</code></dt>
<dd>The matrices to use in the product.</dd>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>Indices of the contractions. The default is None, indicating all
the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The tensor after the contractions with the matrices.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensor_matrix_product(self, matrices, dims=None):
    &#39;&#39;&#39;
    Contract a tensor with matrices.

    The second dimension of the matrix matrices[k] is contracted with the
    k-th dimension of self, with the indices k given in dims (if provided).

    Parameters
    ----------
    matrices : numpy.ndarray or list of numpy.ndarray
        The matrices to use in the product.
    dims : list or numpy.ndarray, optional
        Indices of the contractions. The default is None, indicating all
        the dimensions.

    Returns
    -------
    FullTensor
        The tensor after the contractions with the matrices.

    &#39;&#39;&#39;
    if dims is None:
        assert isinstance(matrices, (list, np.ndarray)), \
            &#39;matrices should be a list or a numpy.ndarray.&#39;
        assert len(matrices) == self.order, \
            &#39;len(matrices) must be self.order.&#39;
        dims = range(self.order)
    else:
        dims = np.atleast_1d(dims)
        if not isinstance(matrices, list):
            matrices = [matrices]
        assert len(matrices) == dims.size, \
            &#39;len(matrices) must be equal to dims.size.&#39;

    # Numpy implementation
    # matrices = [np.array(x) for x in matrices]
    # data = self.numpy()
    # if self.order == 1:
    #     data = np.matmul(matrices[0], data)
    # else:
    #     k = 0
    #     for dim in np.nditer(dims):
    #         perm_dims = np.concatenate(([dim], np.arange(dim),
    #                                     np.arange(dim+1, self.order)))
    #         data = np.transpose(data, perm_dims)
    #         shape0 = np.array(data.shape)
    #         data = np.reshape(data, [shape0[0], np.prod(shape0[1:])])
    #         data = np.matmul(matrices[k], data)
    #         shape0[0] = matrices[k].shape[0]
    #         data = np.reshape(data, shape0)
    #         data = np.transpose(data, np.argsort(perm_dims))
    #         k += 1
    # return FullTensor(data)

    tensor = FullTensor(self)
    matrices = [FullTensor(x) for x in matrices]
    for i, dim in enumerate(dims):
        index = np.concatenate((
            tensap.fast_setdiff(np.arange(tensor.order), dim), [dim]))
        tensor = tensor.tensordot(matrices[i], dim, 1).itranspose(index)
    return tensor</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensor_matrix_product_eval_diag"><code class="name flex">
<span>def <span class="ident">tensor_matrix_product_eval_diag</span></span>(<span>self, matrices, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate the diagonal of a tensor obtained by contraction with
matrices.</p>
<p>Provides the diagonal of the tensor obtained by contracting the tensor
with matrices H[k] along dimensions dims(k)+1, for k = 0, &hellip;,
dims.size-1.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>matrices</code></strong> :&ensp;<code>list</code></dt>
<dd>The matrices to use in the product.</dd>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>Indices of the contractions. The default is None, indicating all
the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>out</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The diagonal of the contractions of the tensor with the matrices.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensor_matrix_product_eval_diag(self, matrices, dims=None):
    &#39;&#39;&#39;
    Evaluate the diagonal of a tensor obtained by contraction with
    matrices.

    Provides the diagonal of the tensor obtained by contracting the tensor
    with matrices H[k] along dimensions dims(k)+1, for k = 0, ...,
    dims.size-1.

    Parameters
    ----------
    matrices : list
        The matrices to use in the product.
    dims : list or numpy.ndarray, optional
        Indices of the contractions. The default is None, indicating all
        the dimensions.

    Returns
    -------
    out : FullTensor
        The diagonal of the contractions of the tensor with the matrices.

    &#39;&#39;&#39;
    if dims is None:
        assert isinstance(matrices, list), &#39;matrices should be a list.&#39;
        assert len(matrices) == self.order, \
            &#39;len(matrices) must be self.order.&#39;
        dims = np.arange(self.order)
    else:
        dims = np.atleast_1d(dims)
        if not isinstance(matrices, list):
            matrices = [matrices]
        assert len(matrices) == dims.size, \
            &#39;len(matrices) must be equal to dims.size.&#39;

    matrices = [FullTensor(x) for x in matrices]
    ind = np.flip(np.argsort(dims))
    out = matrices[ind[0]].tensordot(self, 1, dims[ind[0]])
    for i in ind[1:]:
        out = matrices[i].tensordot_eval_diag(out, 1, dims[i]+1, 0, 0)

    # if out.order == 1:
    #     out = out.numpy()
    return out</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensor_vector_product"><code class="name flex">
<span>def <span class="ident">tensor_vector_product</span></span>(<span>self, vectors, dims=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the contraction of the tensor with vectors.</p>
<p>Compute the contraction of self with each vector contained in the list
vectors along dimensions specified by dims. The operation is such that
V[k] is contracted with the dims[k]-th dimension of self.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>vectors</code></strong> :&ensp;<code>numpy.ndarray</code> or <code>list</code> of <code>numpy.ndarray</code></dt>
<dd>The vectors to use in the product.</dd>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>Indices of the contractions. The default is None, indicating all
the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The tensor after the contractions with the vectors.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensor_vector_product(self, vectors, dims=None):
    &#39;&#39;&#39;
    Compute the contraction of the tensor with vectors.

    Compute the contraction of self with each vector contained in the list
    vectors along dimensions specified by dims. The operation is such that
    V[k] is contracted with the dims[k]-th dimension of self.

    Parameters
    ----------
    vectors : numpy.ndarray or list of numpy.ndarray
        The vectors to use in the product.
    dims : list or numpy.ndarray, optional
        Indices of the contractions. The default is None, indicating all
        the dimensions.

    Returns
    -------
    FullTensor
        The tensor after the contractions with the vectors.

    &#39;&#39;&#39;
    if dims is None:
        assert isinstance(vectors, list), &#39;vectors should be a list.&#39;
        assert len(vectors) == self.order, \
            &#39;len(vectors) must be self.order.&#39;
        dims = np.arange(self.order)
    else:
        dims = np.array(dims)
        if not isinstance(vectors, list):
            vectors = [vectors]
        assert len(vectors) == dims.size, \
            &#39;len(vectors) must be equal to dims.size.&#39;

    vectors = [FullTensor(x, 2, [1, -1]) for x in vectors]
    return self.tensor_matrix_product(vectors, dims).squeeze(dims.tolist())</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensordot"><code class="name flex">
<span>def <span class="ident">tensordot</span></span>(<span>self, tensor2, dims1, dims2=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Contract two tensors along specified dimensions.</p>
<p>Similar to tensorflow.tensordot.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tensor2</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The second tensor of the contraction.</dd>
<dt><strong><code>dims1</code></strong> :&ensp;<code>list</code> or <code>int</code></dt>
<dd>The dimensions of contractions for the first tensor.</dd>
<dt><strong><code>dims2</code></strong> :&ensp;<code>list</code> or <code>int</code>, optional</dt>
<dd>The dimensions of contractions for the second tensor. The default
is None which indicates, if dims1 = 0, to perform the outer
product of the two tensors, similarly to tensorflow.tensordot.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>out</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The resulting tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensordot(self, tensor2, dims1, dims2=None):
    &#39;&#39;&#39;
    Contract two tensors along specified dimensions.

    Similar to tensorflow.tensordot.

    Parameters
    ----------
    tensor2 : FullTensor
        The second tensor of the contraction.
    dims1 : list or int
        The dimensions of contractions for the first tensor.
    dims2 : list or int, optional
        The dimensions of contractions for the second tensor. The default
        is None which indicates, if dims1 = 0, to perform the outer
        product of the two tensors, similarly to tensorflow.tensordot.

    Returns
    -------
    out : FullTensor
        The resulting tensor.

    &#39;&#39;&#39;
    dims1 = np.atleast_1d(dims1)
    if dims1.size == 1 and dims1 == 0 and dims2 is None:
        # Outer product (notation similar to tensorflow)
        out = FullTensor(np.tensordot(self.data, tensor2.data, 0))
    else:
        dims2 = np.atleast_1d(dims2)
        assert np.all([self.shape[i] == tensor2.shape[j] for i, j in
                       zip(dims1, dims2)]), \
            &#39;The dimensions of the tensors are not compatible.&#39;
        out = FullTensor(np.tensordot(self.data, tensor2.data,
                                      [dims1, dims2]))
    return out</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensordot_eval_diag"><code class="name flex">
<span>def <span class="ident">tensordot_eval_diag</span></span>(<span>self, tensor2, dims1, dims2, diag_dims1, diag_dims2, diag=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate of the diagonal of a tensor obtained by contraction of two
tensors.</p>
<p>The contraction is performed along the dimensions dims1 for self and
dims2 for tensor2, and the diagonal is evaluated according to the
dimensions diag_dims1 for self and diag_dims2 for tensor2.</p>
<p>The boolean diag indicates if the several diagonals are evaluated, for
instance:
- if diag is False, for order-4 tensors x and y,
z = x.tensordot_eval_diag(y,[1,3],[2,3],2,0) returns an order-3 tensor
z(i1,k,j2) = sum_{l1,l2} x(i1,l1,k,l2) y(k,j2,l1,l2)
- if diag is True, for order-5 tensors x and y,
z = x.tensordot_eval_diag(y,[1,3],[2,3],[0,2],[1,4]) returns an
order-4 tensor
z(k,l,i5,j1) = sum_{l1,l2} x(k,l1,l,l2,i5) y(j1,k,l1,l2,l)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tensor2</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The second tensor of the product.</dd>
<dt><strong><code>dims1</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>Dimensions of the first tensor for the contraction.</dd>
<dt><strong><code>dims2</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>Dimensions of the second tensor for the contraction.</dd>
<dt><strong><code>diag_dims1</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>Indices of the first tensor for the evaluation of the diagonal.</dd>
<dt><strong><code>diag_dims2</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>Indices of the second tensor for the evaluation of the diagonal.</dd>
<dt><strong><code>diag</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Boolean enabling the evaluation of multiple diagonals. The default
is False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The evaluated tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensordot_eval_diag(self, tensor2, dims1, dims2, diag_dims1,
                        diag_dims2, diag=False):
    &#39;&#39;&#39;
    Evaluate of the diagonal of a tensor obtained by contraction of two
    tensors.

    The contraction is performed along the dimensions dims1 for self and
    dims2 for tensor2, and the diagonal is evaluated according to the
    dimensions diag_dims1 for self and diag_dims2 for tensor2.

    The boolean diag indicates if the several diagonals are evaluated, for
    instance:
    - if diag is False, for order-4 tensors x and y,
    z = x.tensordot_eval_diag(y,[1,3],[2,3],2,0) returns an order-3 tensor
    z(i1,k,j2) = sum_{l1,l2} x(i1,l1,k,l2) y(k,j2,l1,l2)
    - if diag is True, for order-5 tensors x and y,
    z = x.tensordot_eval_diag(y,[1,3],[2,3],[0,2],[1,4]) returns an
    order-4 tensor
    z(k,l,i5,j1) = sum_{l1,l2} x(k,l1,l,l2,i5) y(j1,k,l1,l2,l)

    Parameters
    ----------
    tensor2 : FullTensor
        The second tensor of the product.
    dims1 : list or numpy.ndarray
        Dimensions of the first tensor for the contraction.
    dims2 : list or numpy.ndarray
        Dimensions of the second tensor for the contraction.
    diag_dims1 : list or numpy.ndarray
        Indices of the first tensor for the evaluation of the diagonal.
    diag_dims2 : list or numpy.ndarray
        Indices of the second tensor for the evaluation of the diagonal.
    diag : bool, optional
        Boolean enabling the evaluation of multiple diagonals. The default
        is False.

    Returns
    -------
    FullTensor
        The evaluated tensor.

    &#39;&#39;&#39;
    # Check if an outer product is asked with dims1 and dims2 equal to None
    if dims1 is None and dims2 is None:
        dims1 = []
        dims2 = []

    dims1 = np.atleast_1d(dims1)
    dims2 = np.atleast_1d(dims2)
    diag_dims1 = np.atleast_1d(diag_dims1)
    diag_dims2 = np.atleast_1d(diag_dims2)

    ind1 = np.arange(self.ndim)
    ind2 = ind1.size + np.arange(tensor2.ndim)
    if diag and diag_dims1.size != 0 and diag_dims2.size != 0:
        ind2[diag_dims2] = ind1[diag_dims1]
    elif not diag:
        ind1[diag_dims1] = ind1[diag_dims1[0]]
        ind2[diag_dims2] = ind1[diag_dims1[0]]
    if dims1.size != 0 and dims2.size != 0:
        ind2[dims2] = ind1[dims1]
    ind12 = np.concatenate((ind1, ind2))
    indexes = np.unique(ind12, return_index=True)[1]
    # Retain only the unique values without sorting the vector
    ind_out = np.array([ind12[index] for index in sorted(indexes)])
    # Remove from ind_out the contracted dimensions without sorting it
    ind_out = ind_out[[i not in np.atleast_1d(dims1) for i in ind_out]]
    array = np.einsum(self.data, ind1.tolist(), tensor2.data,
                      ind2.tolist(), ind_out.tolist())
    # alph = list(ascii_lowercase)
    # ind1 = [alph[i] for i in ind1]
    # ind2 = [alph[i] for i in ind2]
    # ind_out = [alph[i] for i in ind_out]
    # array = np.einsum(&#39;&#39;.join(ind1) + &#39;, &#39; + &#39;&#39;.join(ind2) + &#39; -&gt; &#39; +
    #                   &#39;&#39;.join(ind_out), self.data, tensor2.data)
    return FullTensor(array)</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensordot_matrix_product_except_dim"><code class="name flex">
<span>def <span class="ident">tensordot_matrix_product_except_dim</span></span>(<span>self, tensor2, matrices, dim)</span>
</code></dt>
<dd>
<div class="desc"><p>Particular type of contraction.</p>
<p>Compute a special contraction of two tensors self, tensor2, a list of
matrices matrices and a particular dimension dim. Note that dim must
be a scalar, while matrices must be a list array with self.order
elements.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tensor2</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The second tensor of the contraction.</dd>
<dt><strong><code>matrices</code></strong> :&ensp;<code>list</code></dt>
<dd>The list of matrices of the contraction.</dd>
<dt><strong><code>dim</code></strong> :&ensp;<code>int</code></dt>
<dd>The excluded dimension.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The result of the contraction.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensordot_matrix_product_except_dim(self, tensor2, matrices, dim):
    &#39;&#39;&#39;
    Particular type of contraction.

    Compute a special contraction of two tensors self, tensor2, a list of
    matrices matrices and a particular dimension dim. Note that dim must
    be a scalar, while matrices must be a list array with self.order
    elements.

    Parameters
    ----------
    tensor2 : FullTensor
        The second tensor of the contraction.
    matrices : list
        The list of matrices of the contraction.
    dim : int
        The excluded dimension.

    Returns
    -------
    numpy.ndarray
        The result of the contraction.

    &#39;&#39;&#39;
    assert isinstance(matrices, list), &#39;matrices should be a list.&#39;
    assert len(matrices) == self.order, \
        &#39;len(matrices) must be self.order.&#39;

    dims = tensap.fast_setdiff(np.arange(self.order), dim)
    matrices = [matrices[i] for i in dims]
    tmp = tensor2.tensor_matrix_product(matrices, dims)
    tmp = self.tensordot(tmp, dims, dims)
    return tmp</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.transpose"><code class="name flex">
<span>def <span class="ident">transpose</span></span>(<span>self, dims)</span>
</code></dt>
<dd>
<div class="desc"><p>Transpose (permute) the dimensions of the tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The new ordering of the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tensor</code></strong> :&ensp;<code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></dt>
<dd>The transposed (permuted) tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transpose(self, dims):
    &#39;&#39;&#39;
    Transpose (permute) the dimensions of the tensor.

    Parameters
    ----------
    dims : list or numpy.ndarray
        The new ordering of the dimensions.

    Returns
    -------
    tensor : FullTensor
        The transposed (permuted) tensor.

    &#39;&#39;&#39;
    tensor = FullTensor(self)
    tensor.data = np.transpose(tensor.data, dims)
    return tensor</code></pre>
</details>
</dd>
<dt id="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tree_based_tensor"><code class="name flex">
<span>def <span class="ident">tree_based_tensor</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert a FullTensor into a TreeBasedTensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>TreeBasedTensor</code></dt>
<dd>The FullTensor in tree-based tensor format.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tree_based_tensor(self):
    &#39;&#39;&#39;
    Convert a FullTensor into a TreeBasedTensor.

    Returns
    -------
    TreeBasedTensor
        The FullTensor in tree-based tensor format.

    &#39;&#39;&#39;
    tree = tensap.DimensionTree.trivial(self.order)
    tensors = [FullTensor(self)]
    for dim in range(self.order):
        tensors.append(FullTensor(np.eye(self.shape[dim])))
    return tensap.TreeBasedTensor(tensors, tree)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tensap.tensor_algebra.tensors" href="index.html">tensap.tensor_algebra.tensors</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor">FullTensor</a></code></h4>
<ul class="">
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.alpha_principal_components" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.alpha_principal_components">alpha_principal_components</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.cat" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.cat">cat</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.create" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.create">create</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.diag" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.diag">diag</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.dot" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.dot">dot</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.dot_with_rank_one_metric" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.dot_with_rank_one_metric">dot_with_rank_one_metric</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.eval_at_indices" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.eval_at_indices">eval_at_indices</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.eval_diag" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.eval_diag">eval_diag</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.full" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.full">full</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.hadamard_product" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.hadamard_product">hadamard_product</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.itranspose" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.itranspose">itranspose</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.kron" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.kron">kron</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.matricize" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.matricize">matricize</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.ndim" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.ndim">ndim</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.norm" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.norm">norm</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.numpy" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.numpy">numpy</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.ones" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.ones">ones</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.order" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.order">order</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.orth" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.orth">orth</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.outer_product_eval_diag" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.outer_product_eval_diag">outer_product_eval_diag</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.principal_components" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.principal_components">principal_components</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.rand" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.rand">rand</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.randn" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.randn">randn</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.reduce_mean" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.reduce_mean">reduce_mean</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.reduce_sum" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.reduce_sum">reduce_sum</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.reshape" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.reshape">reshape</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.shape" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.shape">shape</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.singular_values" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.singular_values">singular_values</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.size" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.size">size</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.sparse" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.sparse">sparse</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.sparse_storage" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.sparse_storage">sparse_storage</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.squeeze" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.squeeze">squeeze</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.storage" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.storage">storage</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.sub_tensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.sub_tensor">sub_tensor</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensor_diagonal_matrix_product" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensor_diagonal_matrix_product">tensor_diagonal_matrix_product</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensor_matrix_product" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensor_matrix_product">tensor_matrix_product</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensor_matrix_product_eval_diag" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensor_matrix_product_eval_diag">tensor_matrix_product_eval_diag</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensor_vector_product" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensor_vector_product">tensor_vector_product</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensordot" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensordot">tensordot</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensordot_eval_diag" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensordot_eval_diag">tensordot_eval_diag</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensordot_matrix_product_except_dim" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.tensordot_matrix_product_except_dim">tensordot_matrix_product_except_dim</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.transpose" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.transpose">transpose</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.tree_based_tensor" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.tree_based_tensor">tree_based_tensor</a></code></li>
<li><code><a title="tensap.tensor_algebra.tensors.full_tensor.FullTensor.zeros" href="#tensap.tensor_algebra.tensors.full_tensor.FullTensor.zeros">zeros</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>
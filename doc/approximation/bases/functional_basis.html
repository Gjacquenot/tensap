<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>tensap.approximation.bases.functional_basis API documentation</title>
<meta name="description" content="Module functional_basis â€¦" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tensap.approximation.bases.functional_basis</code></h1>
</header>
<section id="section-intro">
<p>Module functional_basis.</p>
<p>Copyright (c) 2020, Anthony Nouy, Erwan Grelier
This file is part of tensap (tensor approximation package).</p>
<p>tensap is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.</p>
<p>tensap is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
See the
GNU Lesser General Public License for more details.</p>
<p>You should have received a copy of the GNU Lesser General Public License
along with tensap.
If not, see <a href="https://www.gnu.org/licenses/">https://www.gnu.org/licenses/</a>.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;
Module functional_basis.

Copyright (c) 2020, Anthony Nouy, Erwan Grelier
This file is part of tensap (tensor approximation package).

tensap is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

tensap is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public License
along with tensap.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

&#39;&#39;&#39;

from abc import abstractmethod
from scipy.sparse import diags
import numpy as np
import tensap


class FunctionalBasis:
    &#39;&#39;&#39;
    Class FunctionalBasis.

    Attributes
    ----------
    measure : tensap.Measure
        The measure associated with the FunctionalBasis.

    is_orthonormal : bool
        Indicates if the basis is orthonormal with respect to the associated
        measure.

    &#39;&#39;&#39;

    def __init__(self):
        &#39;&#39;&#39;
        Constructor for the class FunctionalBasis.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        self.measure = None
        self.is_orthonormal = False

    def __repr__(self):
        return (&#39;&lt;{}:{n}&#39; +
                &#39;{t}measure = {},{n}&#39; +
                &#39;{t}is_orthonormal = {}&gt;&#39;).format(self.__class__.__name__,
                                                  self.measure,
                                                  self.is_orthonormal,
                                                  t=&#39;\t&#39;, n=&#39;\n&#39;)

    def random(self, n=1, measure=None):
        &#39;&#39;&#39;
        Evaluate the basis using n points drawn randomly according to measure
        if provided, or to self.measure otherwise.

        Parameters
        ----------
        n : int, optional
            The number of random evaluations. The default is 1.
        measure : tensap.ProbabilityMeasure, optional
            The probability measure used for the generation of the input
            points. The default is None, indicating to use self.measure.

        Returns
        -------
        basis_eval : numpy.ndarray
            Random evaluations of the basis functions.
        x : numpy.ndarray
            The input points.

        &#39;&#39;&#39;
        if measure is None:
            measure = self.measure
        if not isinstance(measure, tensap.ProbabilityMeasure):
            raise ValueError(&#39;Must provide a ProbabilityMeasure.&#39;)

        x = measure.random(n)
        basis_eval = np.reshape(self.eval(x), (n, self.cardinal()))
        return basis_eval, x

    @staticmethod
    def storage():
        &#39;&#39;&#39;
        Return the storage requirement of the FunctionalBasis.

        Returns
        -------
        int
            The storage requirement of the FunctionalBasis.

        &#39;&#39;&#39;
        return 0

    def adaptation_path(self):
        &#39;&#39;&#39;
        Return the adaptation path of the functional basis.

        Returns
        -------
        numpy.ndarray
            Boolean array, where n is the dimension of the functional basis,
            and m is the number of elements in the adaptation path,
            column P[:,i] corresponds to a sparsity pattern.

        &#39;&#39;&#39;
        return np.triu(np.full([self.cardinal()]*2, True))

    def interpolate(self, y, x=None):
        &#39;&#39;&#39;
        Provide an interpolation on a functional basis of a function (or values
        of the function) y associated with a set of n interpolation points x.

        Parameters
        ----------
        y : function or list or numpy.ndarray
            The function to interpolate, or values of it.
        x : list or numpy.ndarray, optional
            The interpolation points. The default is None, indicating to
            deduce them from the basis.

        Returns
        -------
        f : tensap.FunctionalBasisArray
            The computed interpolation.

        &#39;&#39;&#39;
        if x is None:
            x = self.interpolation_points()
        try:
            y = y(x)
        except Exception:
            pass

        if np.ndim(y) == 1:
            y = np.reshape(y, [-1, 1])

        hx = self.eval(x)
        data = np.linalg.solve(hx, y)
        f = tensap.FunctionalBasisArray(data, self, np.shape(y)[1])
        f.measure = self.measure
        return f

    @staticmethod
    def mean():
        &#39;&#39;&#39;
        Return the mean of the basis functions.

        Returns
        -------
        numpy.ndarray
            The mean of the basis functions.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    def expectation(self):
        &#39;&#39;&#39;
        Return the expectation of the basis functions. Equivalent to
        self.mean().

        Returns
        -------
        numpy.ndarray
            The expectation of the basis functions.

        &#39;&#39;&#39;
        return self.mean()

    @staticmethod
    def conditional_expectation():
        &#39;&#39;&#39;
        Compute the conditional expectation of self with respect to
        the random variables dims (a subset of range(d)). The expectation
        with respect to other variables (in the complementary set of
        dims) is taken with respect to the probability measure given by
        tensap.RandomVector XdimsC if provided, or with respect to the
        probability measure associated with the corresponding bases of
        the function.

        Parameters
        ----------
        dims : numpy.ndarray
            The dimensions in which the expectation is computed.
        XdimsC: tensap.RandomVector, optional
            The random vector used for the computation of the conditional
            expectation. The default is None, indicating to use the
        probability measure associated with the basis.

        Returns
        -------
        f : tensap.FunctionalBasisArray
            The conditional expectation of the function.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    @staticmethod
    def kron():
        &#39;&#39;&#39;
        Compute the Kronecker product of two bases. For two functional bases
        f_i, i = 1, ..., n and g_j, j = 1, ..., m, return a functional basis
        h_k, k = 1, ..., nm.

        Returns
        -------
        tensap.FunctionalBasis
            The obtained basis.

        &#39;&#39;&#39;
        NotImplementedError(&#39;Method not implemented.&#39;)

    def projection(self, fun, G):
        &#39;&#39;&#39;
        Compute the projection of the function fun onto the functional basis
        using the integration rule G.

        Parameters
        ----------
        fun : function or tensap.Function
            The function to project.
        G : tensap.IntegrationRule
            The integration rule used for the projection.

        Returns
        -------
        tensap.FunctionalBasisArray
            The projection of the function fun onto the functional basis using
            the integration rule G.

        &#39;&#39;&#39;

        A = self.eval(G.points)
        W = diags(G.weights)

        y = fun(G.points)
        if self.is_orthonormal:
            u = np.matmul(np.transpose(A), W.dot(y))
        else:
            u = np.linalg.solve(np.matmul(np.transpose(A), W.dot(A)),
                                np.matmul(np.transpose(A), W.dot(y)))
        if u.ndim == 1:
            u = np.reshape(u, [-1, 1])
        return tensap.FunctionalBasisArray(u, self, u.shape[1])

    def interpolation_points(self, *args):
        &#39;&#39;&#39;
        Return the interpolation points for the basis.

        See also FunctionalBasis.magic_points.

        Parameters
        ----------
        *args : tuple
            The inputs arguments of the method FunctionalBasis.magic_points.

        Returns
        -------
        numpy.ndarray
            The interpolation points for the basis.

        &#39;&#39;&#39;
        return self.magic_points(*args)[0]

    def magic_points(self, x=None, J=None):
        &#39;&#39;&#39;
        Provide the magic points associated with a functional basis f selected
        in a given set of points x.

        The method uses magicIndices(F,numel(f)) on the matrix F of evaluations
        of f at points x.

        Parameters
        ----------
        x : list or numpy.ndarray, optional
            The points used to construct the matrix F. The default is None,
            indicating to choose x automatically based on self.measure.
        J : numpy.ndarray, optional
            The default is None. If not none, selected the magic indices with
            tensap.magic_indices(F[:, J], self.cardinal(), &#39;left&#39;)[0]

        Returns
        -------
        points : numpy.ndarray
            The magic points.
        ind : numpy.ndarray
            The locations of the magic points in x.
        output : dict
            A dictionnary of outputs of the method.

        &#39;&#39;&#39;
        if x is None:
            if isinstance(self.measure, (tensap.DiscreteMeasure,
                                         tensap.DiscreteRandomVariable)):
                x = self.measure.values
            else:
                x = self.measure.random(self.cardinal()*100)

        if np.ndim(x) == 1:
            x = np.expand_dims(x, 1)

        assert x.shape[0] &gt;= self.cardinal(), \
            (&#39;The number of points must be higher than the number of basis &#39; +
             &#39;functions.&#39;)

        F = self.eval(x)
        if J is not None:
            ind = tensap.magic_indices(F[:, J], self.cardinal(), &#39;left&#39;)[0]
        else:
            ind = tensap.magic_indices(F)[0]
        points = x[ind, :]
        if np.ndim(points) == 1:
            points = np.expand_dims(points, 1)

        # Estimation of the Lebesgue constant
        h_x = np.transpose(self.eval(points))
        A = np.transpose(np.linalg.solve(h_x, np.transpose(F)))

        output = {&#39;lebesgue_constant&#39;: np.max(np.sum(np.abs(A), 1))}

        return points, ind, output

    def domain(self):
        &#39;&#39;&#39;
        Return the domain of the set of basis functions, which is the support
        of the associated measure.

        Returns
        -------
        numpy.ndarray
            The domain of the set of basis functions

        &#39;&#39;&#39;
        return self.measure.support()

    def christoffel(self, x):
        # TODO christoffel
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def orthonormalize(self):
        &#39;&#39;&#39;
        Orthonormalize the basis.

        Returns
        -------
        out : tensap.SubFunctionalBasis
            The orthonormalized basis.

        &#39;&#39;&#39;
        G = self.gram_matrix()
        out = self
        if np.linalg.norm(G - np.eye(G.shape[0]), 2):
            A = np.linalg.inv(np.linalg.cholesky(G))
            out = tensap.SubFunctionalBasis(self, np.transpose(A))
        out.is_orthonormal = True
        return out

    def optimal_sampling_measure(self):
        # TODO optimal_sampling_measure
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def plot(self, indices=None, n=10000, *args):
        &#39;&#39;&#39;
        Plot the functions of the basis.

        Parameters
        ----------
        indices : list or numpy.ndarray, optional
            Indices of the functions to be plotted. The default is None,
            indicating all the functions.
        n : int, optional
            The number of points used for the plot. The default is 10000.
        *args : tuple
            Additional parameters used by matplotlib.pyplot&#39;s function plot.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        assert self.ndim() == 1, &#39;Method not implemented.&#39;

        import matplotlib.pyplot as plt

        sup = self.measure.truncated_support()
        if np.size(n) == 1:
            x = np.linspace(sup[0], sup[1], n)
        else:
            x = np.ravel(n)

        if indices is None:
            hx = self.eval(x)
        else:
            hx = self.eval(x, indices)

        plt.plot(x, hx, *args)
        plt.show()

    @abstractmethod
    def cardinal(self):
        &#39;&#39;&#39;
        Return the number of basis functions.

        Returns
        -------
        int
            The number of basis functions.

        &#39;&#39;&#39;

    @abstractmethod
    def ndim(self):
        &#39;&#39;&#39;
        Return the dimension n for f defined in R^n.

        Returns
        -------
        int
            The dimension n for f defined in R^n.

        &#39;&#39;&#39;

    @abstractmethod
    def eval(self, x):
        &#39;&#39;&#39;
        Return the evaluation of the basis functions at the points x.

        Parameters
        ----------
        x : list or numpy.ndarray
            The points at which the basis functions are to be evaluted.

        Returns
        -------
        numpy.ndarray
            The evaluations of the basis functions at the points x.

        &#39;&#39;&#39;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis"><code class="flex name class">
<span>class <span class="ident">FunctionalBasis</span></span>
</code></dt>
<dd>
<div class="desc"><p>Class FunctionalBasis.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>measure</code></strong> :&ensp;<code>tensap.Measure</code></dt>
<dd>The measure associated with the FunctionalBasis.</dd>
<dt><strong><code>is_orthonormal</code></strong> :&ensp;<code>bool</code></dt>
<dd>Indicates if the basis is orthonormal with respect to the associated
measure.</dd>
</dl>
<p>Constructor for the class FunctionalBasis.</p>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FunctionalBasis:
    &#39;&#39;&#39;
    Class FunctionalBasis.

    Attributes
    ----------
    measure : tensap.Measure
        The measure associated with the FunctionalBasis.

    is_orthonormal : bool
        Indicates if the basis is orthonormal with respect to the associated
        measure.

    &#39;&#39;&#39;

    def __init__(self):
        &#39;&#39;&#39;
        Constructor for the class FunctionalBasis.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        self.measure = None
        self.is_orthonormal = False

    def __repr__(self):
        return (&#39;&lt;{}:{n}&#39; +
                &#39;{t}measure = {},{n}&#39; +
                &#39;{t}is_orthonormal = {}&gt;&#39;).format(self.__class__.__name__,
                                                  self.measure,
                                                  self.is_orthonormal,
                                                  t=&#39;\t&#39;, n=&#39;\n&#39;)

    def random(self, n=1, measure=None):
        &#39;&#39;&#39;
        Evaluate the basis using n points drawn randomly according to measure
        if provided, or to self.measure otherwise.

        Parameters
        ----------
        n : int, optional
            The number of random evaluations. The default is 1.
        measure : tensap.ProbabilityMeasure, optional
            The probability measure used for the generation of the input
            points. The default is None, indicating to use self.measure.

        Returns
        -------
        basis_eval : numpy.ndarray
            Random evaluations of the basis functions.
        x : numpy.ndarray
            The input points.

        &#39;&#39;&#39;
        if measure is None:
            measure = self.measure
        if not isinstance(measure, tensap.ProbabilityMeasure):
            raise ValueError(&#39;Must provide a ProbabilityMeasure.&#39;)

        x = measure.random(n)
        basis_eval = np.reshape(self.eval(x), (n, self.cardinal()))
        return basis_eval, x

    @staticmethod
    def storage():
        &#39;&#39;&#39;
        Return the storage requirement of the FunctionalBasis.

        Returns
        -------
        int
            The storage requirement of the FunctionalBasis.

        &#39;&#39;&#39;
        return 0

    def adaptation_path(self):
        &#39;&#39;&#39;
        Return the adaptation path of the functional basis.

        Returns
        -------
        numpy.ndarray
            Boolean array, where n is the dimension of the functional basis,
            and m is the number of elements in the adaptation path,
            column P[:,i] corresponds to a sparsity pattern.

        &#39;&#39;&#39;
        return np.triu(np.full([self.cardinal()]*2, True))

    def interpolate(self, y, x=None):
        &#39;&#39;&#39;
        Provide an interpolation on a functional basis of a function (or values
        of the function) y associated with a set of n interpolation points x.

        Parameters
        ----------
        y : function or list or numpy.ndarray
            The function to interpolate, or values of it.
        x : list or numpy.ndarray, optional
            The interpolation points. The default is None, indicating to
            deduce them from the basis.

        Returns
        -------
        f : tensap.FunctionalBasisArray
            The computed interpolation.

        &#39;&#39;&#39;
        if x is None:
            x = self.interpolation_points()
        try:
            y = y(x)
        except Exception:
            pass

        if np.ndim(y) == 1:
            y = np.reshape(y, [-1, 1])

        hx = self.eval(x)
        data = np.linalg.solve(hx, y)
        f = tensap.FunctionalBasisArray(data, self, np.shape(y)[1])
        f.measure = self.measure
        return f

    @staticmethod
    def mean():
        &#39;&#39;&#39;
        Return the mean of the basis functions.

        Returns
        -------
        numpy.ndarray
            The mean of the basis functions.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    def expectation(self):
        &#39;&#39;&#39;
        Return the expectation of the basis functions. Equivalent to
        self.mean().

        Returns
        -------
        numpy.ndarray
            The expectation of the basis functions.

        &#39;&#39;&#39;
        return self.mean()

    @staticmethod
    def conditional_expectation():
        &#39;&#39;&#39;
        Compute the conditional expectation of self with respect to
        the random variables dims (a subset of range(d)). The expectation
        with respect to other variables (in the complementary set of
        dims) is taken with respect to the probability measure given by
        tensap.RandomVector XdimsC if provided, or with respect to the
        probability measure associated with the corresponding bases of
        the function.

        Parameters
        ----------
        dims : numpy.ndarray
            The dimensions in which the expectation is computed.
        XdimsC: tensap.RandomVector, optional
            The random vector used for the computation of the conditional
            expectation. The default is None, indicating to use the
        probability measure associated with the basis.

        Returns
        -------
        f : tensap.FunctionalBasisArray
            The conditional expectation of the function.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    @staticmethod
    def kron():
        &#39;&#39;&#39;
        Compute the Kronecker product of two bases. For two functional bases
        f_i, i = 1, ..., n and g_j, j = 1, ..., m, return a functional basis
        h_k, k = 1, ..., nm.

        Returns
        -------
        tensap.FunctionalBasis
            The obtained basis.

        &#39;&#39;&#39;
        NotImplementedError(&#39;Method not implemented.&#39;)

    def projection(self, fun, G):
        &#39;&#39;&#39;
        Compute the projection of the function fun onto the functional basis
        using the integration rule G.

        Parameters
        ----------
        fun : function or tensap.Function
            The function to project.
        G : tensap.IntegrationRule
            The integration rule used for the projection.

        Returns
        -------
        tensap.FunctionalBasisArray
            The projection of the function fun onto the functional basis using
            the integration rule G.

        &#39;&#39;&#39;

        A = self.eval(G.points)
        W = diags(G.weights)

        y = fun(G.points)
        if self.is_orthonormal:
            u = np.matmul(np.transpose(A), W.dot(y))
        else:
            u = np.linalg.solve(np.matmul(np.transpose(A), W.dot(A)),
                                np.matmul(np.transpose(A), W.dot(y)))
        if u.ndim == 1:
            u = np.reshape(u, [-1, 1])
        return tensap.FunctionalBasisArray(u, self, u.shape[1])

    def interpolation_points(self, *args):
        &#39;&#39;&#39;
        Return the interpolation points for the basis.

        See also FunctionalBasis.magic_points.

        Parameters
        ----------
        *args : tuple
            The inputs arguments of the method FunctionalBasis.magic_points.

        Returns
        -------
        numpy.ndarray
            The interpolation points for the basis.

        &#39;&#39;&#39;
        return self.magic_points(*args)[0]

    def magic_points(self, x=None, J=None):
        &#39;&#39;&#39;
        Provide the magic points associated with a functional basis f selected
        in a given set of points x.

        The method uses magicIndices(F,numel(f)) on the matrix F of evaluations
        of f at points x.

        Parameters
        ----------
        x : list or numpy.ndarray, optional
            The points used to construct the matrix F. The default is None,
            indicating to choose x automatically based on self.measure.
        J : numpy.ndarray, optional
            The default is None. If not none, selected the magic indices with
            tensap.magic_indices(F[:, J], self.cardinal(), &#39;left&#39;)[0]

        Returns
        -------
        points : numpy.ndarray
            The magic points.
        ind : numpy.ndarray
            The locations of the magic points in x.
        output : dict
            A dictionnary of outputs of the method.

        &#39;&#39;&#39;
        if x is None:
            if isinstance(self.measure, (tensap.DiscreteMeasure,
                                         tensap.DiscreteRandomVariable)):
                x = self.measure.values
            else:
                x = self.measure.random(self.cardinal()*100)

        if np.ndim(x) == 1:
            x = np.expand_dims(x, 1)

        assert x.shape[0] &gt;= self.cardinal(), \
            (&#39;The number of points must be higher than the number of basis &#39; +
             &#39;functions.&#39;)

        F = self.eval(x)
        if J is not None:
            ind = tensap.magic_indices(F[:, J], self.cardinal(), &#39;left&#39;)[0]
        else:
            ind = tensap.magic_indices(F)[0]
        points = x[ind, :]
        if np.ndim(points) == 1:
            points = np.expand_dims(points, 1)

        # Estimation of the Lebesgue constant
        h_x = np.transpose(self.eval(points))
        A = np.transpose(np.linalg.solve(h_x, np.transpose(F)))

        output = {&#39;lebesgue_constant&#39;: np.max(np.sum(np.abs(A), 1))}

        return points, ind, output

    def domain(self):
        &#39;&#39;&#39;
        Return the domain of the set of basis functions, which is the support
        of the associated measure.

        Returns
        -------
        numpy.ndarray
            The domain of the set of basis functions

        &#39;&#39;&#39;
        return self.measure.support()

    def christoffel(self, x):
        # TODO christoffel
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def orthonormalize(self):
        &#39;&#39;&#39;
        Orthonormalize the basis.

        Returns
        -------
        out : tensap.SubFunctionalBasis
            The orthonormalized basis.

        &#39;&#39;&#39;
        G = self.gram_matrix()
        out = self
        if np.linalg.norm(G - np.eye(G.shape[0]), 2):
            A = np.linalg.inv(np.linalg.cholesky(G))
            out = tensap.SubFunctionalBasis(self, np.transpose(A))
        out.is_orthonormal = True
        return out

    def optimal_sampling_measure(self):
        # TODO optimal_sampling_measure
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    def plot(self, indices=None, n=10000, *args):
        &#39;&#39;&#39;
        Plot the functions of the basis.

        Parameters
        ----------
        indices : list or numpy.ndarray, optional
            Indices of the functions to be plotted. The default is None,
            indicating all the functions.
        n : int, optional
            The number of points used for the plot. The default is 10000.
        *args : tuple
            Additional parameters used by matplotlib.pyplot&#39;s function plot.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        assert self.ndim() == 1, &#39;Method not implemented.&#39;

        import matplotlib.pyplot as plt

        sup = self.measure.truncated_support()
        if np.size(n) == 1:
            x = np.linspace(sup[0], sup[1], n)
        else:
            x = np.ravel(n)

        if indices is None:
            hx = self.eval(x)
        else:
            hx = self.eval(x, indices)

        plt.plot(x, hx, *args)
        plt.show()

    @abstractmethod
    def cardinal(self):
        &#39;&#39;&#39;
        Return the number of basis functions.

        Returns
        -------
        int
            The number of basis functions.

        &#39;&#39;&#39;

    @abstractmethod
    def ndim(self):
        &#39;&#39;&#39;
        Return the dimension n for f defined in R^n.

        Returns
        -------
        int
            The dimension n for f defined in R^n.

        &#39;&#39;&#39;

    @abstractmethod
    def eval(self, x):
        &#39;&#39;&#39;
        Return the evaluation of the basis functions at the points x.

        Parameters
        ----------
        x : list or numpy.ndarray
            The points at which the basis functions are to be evaluted.

        Returns
        -------
        numpy.ndarray
            The evaluations of the basis functions at the points x.

        &#39;&#39;&#39;</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="tensap.approximation.bases.full_tensor_product_functional_basis.FullTensorProductFunctionalBasis" href="full_tensor_product_functional_basis.html#tensap.approximation.bases.full_tensor_product_functional_basis.FullTensorProductFunctionalBasis">FullTensorProductFunctionalBasis</a></li>
<li><a title="tensap.approximation.bases.polynomial_functional_basis.PolynomialFunctionalBasis" href="polynomial_functional_basis.html#tensap.approximation.bases.polynomial_functional_basis.PolynomialFunctionalBasis">PolynomialFunctionalBasis</a></li>
<li><a title="tensap.approximation.bases.sparse_tensor_product_functional_basis.SparseTensorProductFunctionalBasis" href="sparse_tensor_product_functional_basis.html#tensap.approximation.bases.sparse_tensor_product_functional_basis.SparseTensorProductFunctionalBasis">SparseTensorProductFunctionalBasis</a></li>
<li><a title="tensap.approximation.bases.sub_functional_basis.SubFunctionalBasis" href="sub_functional_basis.html#tensap.approximation.bases.sub_functional_basis.SubFunctionalBasis">SubFunctionalBasis</a></li>
<li><a title="tensap.approximation.bases.user_defined_functional_basis.UserDefinedFunctionalBasis" href="user_defined_functional_basis.html#tensap.approximation.bases.user_defined_functional_basis.UserDefinedFunctionalBasis">UserDefinedFunctionalBasis</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.conditional_expectation"><code class="name flex">
<span>def <span class="ident">conditional_expectation</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the conditional expectation of self with respect to
the random variables dims (a subset of range(d)). The expectation
with respect to other variables (in the complementary set of
dims) is taken with respect to the probability measure given by
tensap.RandomVector XdimsC if provided, or with respect to the
probability measure associated with the corresponding bases of
the function.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The dimensions in which the expectation is computed.</dd>
<dt><strong><code>XdimsC</code></strong> :&ensp;<code>tensap.RandomVector</code>, optional</dt>
<dd>The random vector used for the computation of the conditional
expectation. The default is None, indicating to use the</dd>
</dl>
<p>probability measure associated with the basis.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>f</code></strong> :&ensp;<code>tensap.FunctionalBasisArray</code></dt>
<dd>The conditional expectation of the function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def conditional_expectation():
    &#39;&#39;&#39;
    Compute the conditional expectation of self with respect to
    the random variables dims (a subset of range(d)). The expectation
    with respect to other variables (in the complementary set of
    dims) is taken with respect to the probability measure given by
    tensap.RandomVector XdimsC if provided, or with respect to the
    probability measure associated with the corresponding bases of
    the function.

    Parameters
    ----------
    dims : numpy.ndarray
        The dimensions in which the expectation is computed.
    XdimsC: tensap.RandomVector, optional
        The random vector used for the computation of the conditional
        expectation. The default is None, indicating to use the
    probability measure associated with the basis.

    Returns
    -------
    f : tensap.FunctionalBasisArray
        The conditional expectation of the function.

    &#39;&#39;&#39;
    raise NotImplementedError(&#39;No generic implementation of the method.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.kron"><code class="name flex">
<span>def <span class="ident">kron</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the Kronecker product of two bases. For two functional bases
f_i, i = 1, &hellip;, n and g_j, j = 1, &hellip;, m, return a functional basis
h_k, k = 1, &hellip;, nm.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensap.FunctionalBasis</code></dt>
<dd>The obtained basis.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def kron():
    &#39;&#39;&#39;
    Compute the Kronecker product of two bases. For two functional bases
    f_i, i = 1, ..., n and g_j, j = 1, ..., m, return a functional basis
    h_k, k = 1, ..., nm.

    Returns
    -------
    tensap.FunctionalBasis
        The obtained basis.

    &#39;&#39;&#39;
    NotImplementedError(&#39;Method not implemented.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.mean"><code class="name flex">
<span>def <span class="ident">mean</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the mean of the basis functions.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The mean of the basis functions.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def mean():
    &#39;&#39;&#39;
    Return the mean of the basis functions.

    Returns
    -------
    numpy.ndarray
        The mean of the basis functions.

    &#39;&#39;&#39;
    raise NotImplementedError(&#39;No generic implementation of the method.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.storage"><code class="name flex">
<span>def <span class="ident">storage</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the storage requirement of the FunctionalBasis.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The storage requirement of the FunctionalBasis.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def storage():
    &#39;&#39;&#39;
    Return the storage requirement of the FunctionalBasis.

    Returns
    -------
    int
        The storage requirement of the FunctionalBasis.

    &#39;&#39;&#39;
    return 0</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.adaptation_path"><code class="name flex">
<span>def <span class="ident">adaptation_path</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the adaptation path of the functional basis.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>Boolean array, where n is the dimension of the functional basis,
and m is the number of elements in the adaptation path,
column P[:,i] corresponds to a sparsity pattern.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def adaptation_path(self):
    &#39;&#39;&#39;
    Return the adaptation path of the functional basis.

    Returns
    -------
    numpy.ndarray
        Boolean array, where n is the dimension of the functional basis,
        and m is the number of elements in the adaptation path,
        column P[:,i] corresponds to a sparsity pattern.

    &#39;&#39;&#39;
    return np.triu(np.full([self.cardinal()]*2, True))</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.cardinal"><code class="name flex">
<span>def <span class="ident">cardinal</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the number of basis functions.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The number of basis functions.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def cardinal(self):
    &#39;&#39;&#39;
    Return the number of basis functions.

    Returns
    -------
    int
        The number of basis functions.

    &#39;&#39;&#39;</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.christoffel"><code class="name flex">
<span>def <span class="ident">christoffel</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def christoffel(self, x):
    # TODO christoffel
    raise NotImplementedError(&#39;Method not implemented.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.domain"><code class="name flex">
<span>def <span class="ident">domain</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the domain of the set of basis functions, which is the support
of the associated measure.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The domain of the set of basis functions</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def domain(self):
    &#39;&#39;&#39;
    Return the domain of the set of basis functions, which is the support
    of the associated measure.

    Returns
    -------
    numpy.ndarray
        The domain of the set of basis functions

    &#39;&#39;&#39;
    return self.measure.support()</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.eval"><code class="name flex">
<span>def <span class="ident">eval</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the evaluation of the basis functions at the points x.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The points at which the basis functions are to be evaluted.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The evaluations of the basis functions at the points x.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def eval(self, x):
    &#39;&#39;&#39;
    Return the evaluation of the basis functions at the points x.

    Parameters
    ----------
    x : list or numpy.ndarray
        The points at which the basis functions are to be evaluted.

    Returns
    -------
    numpy.ndarray
        The evaluations of the basis functions at the points x.

    &#39;&#39;&#39;</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.expectation"><code class="name flex">
<span>def <span class="ident">expectation</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the expectation of the basis functions. Equivalent to
self.mean().</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The expectation of the basis functions.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expectation(self):
    &#39;&#39;&#39;
    Return the expectation of the basis functions. Equivalent to
    self.mean().

    Returns
    -------
    numpy.ndarray
        The expectation of the basis functions.

    &#39;&#39;&#39;
    return self.mean()</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.interpolate"><code class="name flex">
<span>def <span class="ident">interpolate</span></span>(<span>self, y, x=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Provide an interpolation on a functional basis of a function (or values
of the function) y associated with a set of n interpolation points x.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>function</code> or <code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The function to interpolate, or values of it.</dd>
<dt><strong><code>x</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>The interpolation points. The default is None, indicating to
deduce them from the basis.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>f</code></strong> :&ensp;<code>tensap.FunctionalBasisArray</code></dt>
<dd>The computed interpolation.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def interpolate(self, y, x=None):
    &#39;&#39;&#39;
    Provide an interpolation on a functional basis of a function (or values
    of the function) y associated with a set of n interpolation points x.

    Parameters
    ----------
    y : function or list or numpy.ndarray
        The function to interpolate, or values of it.
    x : list or numpy.ndarray, optional
        The interpolation points. The default is None, indicating to
        deduce them from the basis.

    Returns
    -------
    f : tensap.FunctionalBasisArray
        The computed interpolation.

    &#39;&#39;&#39;
    if x is None:
        x = self.interpolation_points()
    try:
        y = y(x)
    except Exception:
        pass

    if np.ndim(y) == 1:
        y = np.reshape(y, [-1, 1])

    hx = self.eval(x)
    data = np.linalg.solve(hx, y)
    f = tensap.FunctionalBasisArray(data, self, np.shape(y)[1])
    f.measure = self.measure
    return f</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.interpolation_points"><code class="name flex">
<span>def <span class="ident">interpolation_points</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the interpolation points for the basis.</p>
<p>See also FunctionalBasis.magic_points.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>*args</code></strong> :&ensp;<code>tuple</code></dt>
<dd>The inputs arguments of the method FunctionalBasis.magic_points.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The interpolation points for the basis.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def interpolation_points(self, *args):
    &#39;&#39;&#39;
    Return the interpolation points for the basis.

    See also FunctionalBasis.magic_points.

    Parameters
    ----------
    *args : tuple
        The inputs arguments of the method FunctionalBasis.magic_points.

    Returns
    -------
    numpy.ndarray
        The interpolation points for the basis.

    &#39;&#39;&#39;
    return self.magic_points(*args)[0]</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.magic_points"><code class="name flex">
<span>def <span class="ident">magic_points</span></span>(<span>self, x=None, J=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Provide the magic points associated with a functional basis f selected
in a given set of points x.</p>
<p>The method uses magicIndices(F,numel(f)) on the matrix F of evaluations
of f at points x.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>The points used to construct the matrix F. The default is None,
indicating to choose x automatically based on self.measure.</dd>
<dt><strong><code>J</code></strong> :&ensp;<code>numpy.ndarray</code>, optional</dt>
<dd>The default is None. If not none, selected the magic indices with
tensap.magic_indices(F[:, J], self.cardinal(), 'left')[0]</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>points</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The magic points.</dd>
<dt><strong><code>ind</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The locations of the magic points in x.</dd>
<dt><strong><code>output</code></strong> :&ensp;<code>dict</code></dt>
<dd>A dictionnary of outputs of the method.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def magic_points(self, x=None, J=None):
    &#39;&#39;&#39;
    Provide the magic points associated with a functional basis f selected
    in a given set of points x.

    The method uses magicIndices(F,numel(f)) on the matrix F of evaluations
    of f at points x.

    Parameters
    ----------
    x : list or numpy.ndarray, optional
        The points used to construct the matrix F. The default is None,
        indicating to choose x automatically based on self.measure.
    J : numpy.ndarray, optional
        The default is None. If not none, selected the magic indices with
        tensap.magic_indices(F[:, J], self.cardinal(), &#39;left&#39;)[0]

    Returns
    -------
    points : numpy.ndarray
        The magic points.
    ind : numpy.ndarray
        The locations of the magic points in x.
    output : dict
        A dictionnary of outputs of the method.

    &#39;&#39;&#39;
    if x is None:
        if isinstance(self.measure, (tensap.DiscreteMeasure,
                                     tensap.DiscreteRandomVariable)):
            x = self.measure.values
        else:
            x = self.measure.random(self.cardinal()*100)

    if np.ndim(x) == 1:
        x = np.expand_dims(x, 1)

    assert x.shape[0] &gt;= self.cardinal(), \
        (&#39;The number of points must be higher than the number of basis &#39; +
         &#39;functions.&#39;)

    F = self.eval(x)
    if J is not None:
        ind = tensap.magic_indices(F[:, J], self.cardinal(), &#39;left&#39;)[0]
    else:
        ind = tensap.magic_indices(F)[0]
    points = x[ind, :]
    if np.ndim(points) == 1:
        points = np.expand_dims(points, 1)

    # Estimation of the Lebesgue constant
    h_x = np.transpose(self.eval(points))
    A = np.transpose(np.linalg.solve(h_x, np.transpose(F)))

    output = {&#39;lebesgue_constant&#39;: np.max(np.sum(np.abs(A), 1))}

    return points, ind, output</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.ndim"><code class="name flex">
<span>def <span class="ident">ndim</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the dimension n for f defined in R^n.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The dimension n for f defined in R^n.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def ndim(self):
    &#39;&#39;&#39;
    Return the dimension n for f defined in R^n.

    Returns
    -------
    int
        The dimension n for f defined in R^n.

    &#39;&#39;&#39;</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.optimal_sampling_measure"><code class="name flex">
<span>def <span class="ident">optimal_sampling_measure</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def optimal_sampling_measure(self):
    # TODO optimal_sampling_measure
    raise NotImplementedError(&#39;Method not implemented.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.orthonormalize"><code class="name flex">
<span>def <span class="ident">orthonormalize</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Orthonormalize the basis.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>out</code></strong> :&ensp;<code>tensap.SubFunctionalBasis</code></dt>
<dd>The orthonormalized basis.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def orthonormalize(self):
    &#39;&#39;&#39;
    Orthonormalize the basis.

    Returns
    -------
    out : tensap.SubFunctionalBasis
        The orthonormalized basis.

    &#39;&#39;&#39;
    G = self.gram_matrix()
    out = self
    if np.linalg.norm(G - np.eye(G.shape[0]), 2):
        A = np.linalg.inv(np.linalg.cholesky(G))
        out = tensap.SubFunctionalBasis(self, np.transpose(A))
    out.is_orthonormal = True
    return out</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, indices=None, n=10000, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the functions of the basis.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>indices</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>Indices of the functions to be plotted. The default is None,
indicating all the functions.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of points used for the plot. The default is 10000.</dd>
<dt><strong><code>*args</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Additional parameters used by matplotlib.pyplot's function plot.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self, indices=None, n=10000, *args):
    &#39;&#39;&#39;
    Plot the functions of the basis.

    Parameters
    ----------
    indices : list or numpy.ndarray, optional
        Indices of the functions to be plotted. The default is None,
        indicating all the functions.
    n : int, optional
        The number of points used for the plot. The default is 10000.
    *args : tuple
        Additional parameters used by matplotlib.pyplot&#39;s function plot.

    Returns
    -------
    None.

    &#39;&#39;&#39;
    assert self.ndim() == 1, &#39;Method not implemented.&#39;

    import matplotlib.pyplot as plt

    sup = self.measure.truncated_support()
    if np.size(n) == 1:
        x = np.linspace(sup[0], sup[1], n)
    else:
        x = np.ravel(n)

    if indices is None:
        hx = self.eval(x)
    else:
        hx = self.eval(x, indices)

    plt.plot(x, hx, *args)
    plt.show()</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.projection"><code class="name flex">
<span>def <span class="ident">projection</span></span>(<span>self, fun, G)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the projection of the function fun onto the functional basis
using the integration rule G.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fun</code></strong> :&ensp;<code>function</code> or <code>tensap.Function</code></dt>
<dd>The function to project.</dd>
<dt><strong><code>G</code></strong> :&ensp;<code>tensap.IntegrationRule</code></dt>
<dd>The integration rule used for the projection.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensap.FunctionalBasisArray</code></dt>
<dd>The projection of the function fun onto the functional basis using
the integration rule G.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def projection(self, fun, G):
    &#39;&#39;&#39;
    Compute the projection of the function fun onto the functional basis
    using the integration rule G.

    Parameters
    ----------
    fun : function or tensap.Function
        The function to project.
    G : tensap.IntegrationRule
        The integration rule used for the projection.

    Returns
    -------
    tensap.FunctionalBasisArray
        The projection of the function fun onto the functional basis using
        the integration rule G.

    &#39;&#39;&#39;

    A = self.eval(G.points)
    W = diags(G.weights)

    y = fun(G.points)
    if self.is_orthonormal:
        u = np.matmul(np.transpose(A), W.dot(y))
    else:
        u = np.linalg.solve(np.matmul(np.transpose(A), W.dot(A)),
                            np.matmul(np.transpose(A), W.dot(y)))
    if u.ndim == 1:
        u = np.reshape(u, [-1, 1])
    return tensap.FunctionalBasisArray(u, self, u.shape[1])</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis.FunctionalBasis.random"><code class="name flex">
<span>def <span class="ident">random</span></span>(<span>self, n=1, measure=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluate the basis using n points drawn randomly according to measure
if provided, or to self.measure otherwise.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of random evaluations. The default is 1.</dd>
<dt><strong><code>measure</code></strong> :&ensp;<code>tensap.ProbabilityMeasure</code>, optional</dt>
<dd>The probability measure used for the generation of the input
points. The default is None, indicating to use self.measure.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>basis_eval</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>Random evaluations of the basis functions.</dd>
<dt><strong><code>x</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The input points.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def random(self, n=1, measure=None):
    &#39;&#39;&#39;
    Evaluate the basis using n points drawn randomly according to measure
    if provided, or to self.measure otherwise.

    Parameters
    ----------
    n : int, optional
        The number of random evaluations. The default is 1.
    measure : tensap.ProbabilityMeasure, optional
        The probability measure used for the generation of the input
        points. The default is None, indicating to use self.measure.

    Returns
    -------
    basis_eval : numpy.ndarray
        Random evaluations of the basis functions.
    x : numpy.ndarray
        The input points.

    &#39;&#39;&#39;
    if measure is None:
        measure = self.measure
    if not isinstance(measure, tensap.ProbabilityMeasure):
        raise ValueError(&#39;Must provide a ProbabilityMeasure.&#39;)

    x = measure.random(n)
    basis_eval = np.reshape(self.eval(x), (n, self.cardinal()))
    return basis_eval, x</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tensap.approximation.bases" href="index.html">tensap.approximation.bases</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis" href="#tensap.approximation.bases.functional_basis.FunctionalBasis">FunctionalBasis</a></code></h4>
<ul class="">
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.adaptation_path" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.adaptation_path">adaptation_path</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.cardinal" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.cardinal">cardinal</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.christoffel" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.christoffel">christoffel</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.conditional_expectation" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.conditional_expectation">conditional_expectation</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.domain" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.domain">domain</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.eval" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.eval">eval</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.expectation" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.expectation">expectation</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.interpolate" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.interpolate">interpolate</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.interpolation_points" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.interpolation_points">interpolation_points</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.kron" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.kron">kron</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.magic_points" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.magic_points">magic_points</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.mean" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.mean">mean</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.ndim" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.ndim">ndim</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.optimal_sampling_measure" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.optimal_sampling_measure">optimal_sampling_measure</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.orthonormalize" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.orthonormalize">orthonormalize</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.plot" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.plot">plot</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.projection" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.projection">projection</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.random" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.random">random</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis.FunctionalBasis.storage" href="#tensap.approximation.bases.functional_basis.FunctionalBasis.storage">storage</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>
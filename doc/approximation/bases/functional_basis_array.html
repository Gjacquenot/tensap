<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>tensap.approximation.bases.functional_basis_array API documentation</title>
<meta name="description" content="Module functional_basis_array â€¦" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tensap.approximation.bases.functional_basis_array</code></h1>
</header>
<section id="section-intro">
<p>Module functional_basis_array.</p>
<p>Copyright (c) 2020, Anthony Nouy, Erwan Grelier
This file is part of tensap (tensor approximation package).</p>
<p>tensap is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.</p>
<p>tensap is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
See the
GNU Lesser General Public License for more details.</p>
<p>You should have received a copy of the GNU Lesser General Public License
along with tensap.
If not, see <a href="https://www.gnu.org/licenses/">https://www.gnu.org/licenses/</a>.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;
Module functional_basis_array.

Copyright (c) 2020, Anthony Nouy, Erwan Grelier
This file is part of tensap (tensor approximation package).

tensap is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

tensap is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public License
along with tensap.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

&#39;&#39;&#39;

from copy import deepcopy
import numpy as np
import tensap


class FunctionalBasisArray(tensap.Function):
    &#39;&#39;&#39;
    Class FunctionalBasisArray.

    Attributes
    ----------
    data : numpy.ndarray, optional
            The coefficents of the function on the basis. The default is None.
    basis : tensap.FunctionalBasis, optional
        The basis. The default is None.
    shape : list or numpy.ndarray, optional
        Array such that the function is with values in
        R^(shape[0] x shape[1] x ...). The default is 1.

    &#39;&#39;&#39;

    def __init__(self, data=None, basis=None, shape=None):
        &#39;&#39;&#39;
        Constructor for the class FunctionalBasisArray

        Parameters
        ----------
        data : numpy.ndarray, optional
            The coefficents of the function on the basis. The default is None.
        basis : tensap.FunctionalBasis, optional
            The basis. The default is None.
        shape : list or numpy.ndarray, optional
            Array such that the function is with values in
            R^(shape[0] x shape[1] x ...). The default is 1.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        tensap.Function.__init__(self)

        if shape is None and (data is not None or basis is not None):
            shape = 1

        self.data = np.ravel(data)
        self.basis = deepcopy(basis)
        self.shape = np.atleast_1d(shape)
        self.output_shape = self.shape
        self.data = np.reshape(self.data,
                               np.concatenate(([basis.cardinal()],
                                               self.shape)))

    def __add__(self, g):
        return FunctionalBasisArray(self.data + g.data, self.basis, self.shape)

    def __neg__(self):
        return FunctionalBasisArray(-self.data, self.basis, self.shape)

    def __sub__(self, g):
        return FunctionalBasisArray(self.data - g.data, self.basis, self.shape)

    def __mul__(self, g):
        if isinstance(g, FunctionalBasisArray):
            g = g.data
        return FunctionalBasisArray(self.data * g, self.basis, self.shape)

    def matmul(self, v):
        &#39;&#39;&#39;
        Compute the matrix multiplication of self.data with v.

        Parameters
        ----------
        v : numpy.ndarray
            The array used in the matrix multiplication.

        Returns
        -------
        tensap.FunctionalBasisArray
            The result of the matrix multiplication.

        &#39;&#39;&#39;
        data = np.matmul(self.data, v)
        return FunctionalBasisArray(data, self.basis, data.shape[1:])

    def matdiv(self, v):
        &#39;&#39;&#39;
        Compute the matrix multiplication of self.data with the inverse of v.

        Parameters
        ----------
        v : numpy.ndarray
            The array used in the matrix multiplication.

        Returns
        -------
        tensap.FunctionalBasisArray
            The result of the matrix multiplication.

        &#39;&#39;&#39;
        data = np.transpose(np.linalg.solve(np.transpose(v),
                                            np.transpose(self.data)))
        return FunctionalBasisArray(data, self.basis, self.shape)

    def dot(self, g, dim=None):
        &#39;&#39;&#39;
        Compute the dot product between the arrays self.data and g.data
        treated as collections of vectors. The function calculates
        the dot product of corresponding vectors along the first
        array dimension whose size does not equal 1.

        Parameters
        ----------
        g : tensap.FunctionalBasisArray
            The second object of the dot product.
        dim : int or list or numpy.ndarray, optional
            The dimension along which the dot product is computed. The default
            is None, indicating all the dimensions.

        Returns
        -------
        float or numpy.ndarray
            The result of the dot product.

        &#39;&#39;&#39;
        return np.sum(self.data * g.data, dim, keepdims=True)

    def norm(self, p=&#39;fro&#39;):
        &#39;&#39;&#39;
        Compute the p-norm of the array self.data.

        See also numpy.linalg.norm.

        Parameters
        ----------
        p : int or numpy.inf or -numpy.inf or string, optional
            The order of the norm. The default is &#39;fro&#39;.

        Returns
        -------
        float
            The norm of self.data.

        &#39;&#39;&#39;
        return np.linalg.norm(np.reshape(self.data,
                                         [self.basis.cardinal(), -1],
                                         order=&#39;F&#39;), p)

    @staticmethod
    def is_random():
        &#39;&#39;&#39;
        Determine if the object is random.

        Returns
        -------
        bool
            Boolean equal to True if the object is random.

        &#39;&#39;&#39;
        return True

    def mean(self, measure=None):
        &#39;&#39;&#39;
        Compute the expectation of the function, according to the measure
        associated with the tensap.ProbabilityMeasure measure if provided, or
        to the standard tensap.ProbabilityMeasure associated with each
        polynomial if not.

        Parameters
        ----------
        measure : tensap.ProbabilityMeasure, optional
            The probability measure used for the computation of the
            expectation. The default is None, indicating to use the standard
            tensap.ProbabilityMeasure associated with each polynomial.

        Returns
        -------
        numpy.ndarray
            The expectation of the function.

        &#39;&#39;&#39;
        M = self.basis.mean(measure)
        M = np.tile(np.ravel(M), np.concatenate((self.shape, [1])))
        M = np.transpose(M, np.concatenate(([np.ndim(M)-1],
                                            range(np.ndim(M)-1))))
        return np.sum(self.data*M, 0, keepdims=True)

    def expectation(self, measure=None):
        &#39;&#39;&#39;
        Compute the expectation of the function, according to the measure
        associated with the tensap.ProbabilityMeasure measure if provided, or
        to the standard tensap.ProbabilityMeasure associated with each
        polynomial if not.

        Parameters
        ----------
        measure : tensap.ProbabilityMeasure, optional
            The probability measure used for the computation of the
            expectation. The default is None, indicating to use the standard
            tensap.ProbabilityMeasure associated with each polynomial.

        Returns
        -------
        numpy.ndarray
            The expectation of the function.

        &#39;&#39;&#39;
        return self.mean(measure)

    def variance(self, measure=None):
        &#39;&#39;&#39;
        Compute the variance of the function, according to the measure
        associated with the tensap.ProbabilityMeasure measure if provided, or
        to the standard tensap.ProbabilityMeasure associated with each
        polynomial if not.

        Parameters
        ----------
        measure : tensap.ProbabilityMeasure, optional
            The probability measure used for the computation of the variance.
            The default is None, indicating to use the standard
            tensap.ProbabilityMeasure associated with each polynomial.

        Returns
        -------
        numpy.ndarray
            The variance of the function.

        &#39;&#39;&#39;
        m = self.expectation(measure)
        return self.dot_product_expectation(self, None, measure) - m**2

    def std(self, *args):
        &#39;&#39;&#39;
        Compute the standard deviation of the function, according to the
        measure associated with the tensap.ProbabilityMeasure measure if
        provided, or to the standard tensap.ProbabilityMeasure associated with
        each polynomial if not.

        Parameters
        ----------
        measure : tensap.ProbabilityMeasure, optional
            The probability measure used for the computation of the standard
            deviation. The default is None, indicating to use the standard
            tensap.ProbabilityMeasure associated with each polynomial.

        Returns
        -------
        numpy.ndarray
            The standard deviation of the function.

        &#39;&#39;&#39;
        return np.sqrt(self.variance(*args))

    def dot_product_expectation(self, g, dims=None, measure=None):
        &#39;&#39;&#39;
        Compute the expectation of self(X)g(X), where X is the probability
        measure associated with the underlying basis, or measure if provided.

        For vector-valued functions of X, dims specifies the dimensions of
        self and g corresponding to the RandomVector measure.

        Parameters
        ----------
        g : tensap.FunctionalBasisArray
            The second function of the product.
        dims : list or numpy.ndarray, optional
            The dimensions of self and g corresponding to the RandomVector
            measure. The default is None.
        measure : tensap.ProbabilityMeasure, optional
            The probability measure used for the computation of the
            expectation. The default is None, indicating to use the probability
            measure associated with the underlying basis.

        Raises
        ------
        NotImplementedError
            If the method is not implemented.

        Returns
        -------
        float or numpy.ndarray
            The result of the dot product.

        &#39;&#39;&#39;
        if dims is None:
            dims = range(self.basis.cardinal())
        if not (self.basis == g.basis) or not self.basis.is_orthonormal:
            raise NotImplementedError(&#39;Method not implemented.&#39;)

        return self.dot(g, 0)

    def norm_expectation(self, measure=None):
        &#39;&#39;&#39;
        Compute the L^2 norm of self(measure). If measure is not provided, use
        the probability measure associated with the underlying basis of self.

        Parameters
        ----------
        measure : tap.ProbabilityMeasure, optional
            DESCRIPTION. The default is None.

        Returns
        -------
        float
            The L2 norm of the function.

        &#39;&#39;&#39;
        return np.sqrt(self.dot_product_expectation(self, None, measure))

    def conditional_expectation(self, dims, *args):
        &#39;&#39;&#39;
        Compute the conditional expectation of self with respect to
        the random variables dims (a subset of range(d)). The expectation
        with respect to other variables (in the complementary set of
        dims) is taken with respect to the probability measure given by
        tensap.RandomVector XdimsC if provided, or with respect to the
        probability measure associated with the corresponding bases of
        the function.

        Parameters
        ----------
        dims : numpy.ndarray
            The dimensions in which the expectation is computed.
        *args : tuple
            Additional parameters. See also the method conditional_expectation
            of the underlying basis.

        Returns
        -------
        f : tensap.FunctionalBasisArray
            The conditional expectation of the function.

        &#39;&#39;&#39;
        h = self.basis.conditional_expectation(dims, *args)
        f = deepcopy(self)
        f.data = np.matmul(h.data, np.reshape(self.data,
                                              [self.basis.cardinal(),
                                               np.prod(self.shape)],
                                              order=&#39;F&#39;))
        f.data = np.reshape(f.data, (f.data.shape[0], f.shape), order=&#39;F&#39;)
        f.basis = h.basis
        return f

    def variance_conditional_expectation(self, alpha):
        &#39;&#39;&#39;
        Compute the variance of the conditional expectation of the function in
        dimensions in alpha.

        Parameters
        ----------
        alpha : numpy.ndarray
            The dimensions in which the variance of the conditional expectation
            of the function if computed.

        Returns
        -------
        numpy.ndarray
            The variance of the conditional expectation of the function.

        &#39;&#39;&#39;
        alpha = np.atleast_2d(alpha)
        m = self.expectation()
        v = np.zeros((np.shape(alpha)[0], np.prod(self.shape)))
        for i in range(np.shape(alpha)[0]):
            u = alpha[i, :]
            if np.all([isinstance(x, bool) for x in u]):
                u = np.nonzero(u)[0]

            if np.size(u) == 0:
                v[i, :] = 0
            else:
                mi = self.conditional_expectation(u)
                vi = mi.dot_product_expectation(mi) - m**2
                v[i, :] = np.ravel(vi)

        return np.reshape(v, np.concatenate(([np.shape(alpha)[0]],
                                             self.shape)), order=&#39;F&#39;)

    def eval(self, x, *args):
        if np.ndim(x) == 1:
            x = np.expand_dims(x, 1)
        H = self.basis.eval(x, *args)
        return self.eval_with_bases_evals(H, *args)

    def eval_with_bases_evals(self, H):
        &#39;&#39;&#39;
        Compute the evaluations of the function using the evaluations of the
        basis H.

        Parameters
        ----------
        H : numpy.ndarray
            The evaluations of the basis.

        Returns
        -------
        numpy.ndarray
            The evaluations of the function.

        &#39;&#39;&#39;
        y = np.matmul(H, np.reshape(self.data, [self.basis.cardinal(),
                                                np.prod(self.shape)],
                                    order=&#39;F&#39;))
        return np.reshape(y, np.concatenate(([H.shape[0]], self.shape)),
                          order=&#39;F&#39;)

    def eval_derivative(self, n, x):
        &#39;&#39;&#39;
        Compute the n-derivative of the function at points x in R^d, with n a
        multi-index of size d.

        Parameters
        ----------
        n : int or list or numpy.ndarray
            The derivation order in all the dimensions, or the derivation
            orders for each dimension.
        x : numpy.ndarray
            The points used for the evaluation of the derivative.

        Raises
        ------
        NotImplementedError
            If the method is not implemented for the basis.

        Returns
        -------
        numpy.ndarray
            The evaluation of the n-derivative of the function at the points x.

        &#39;&#39;&#39;
        try:
            H = self.basis.eval_derivative(n, x)
            return self.eval_with_bases_evals(H)
        except Exception:
            raise NotImplementedError(&#39;Method not implemented for the basis.&#39;)

    def derivative(self, n):
        &#39;&#39;&#39;
        Compute the n-derivative of the function.

        Parameters
        ----------
        n : int
            The derivation order.

        Returns
        -------
        df : tensap.FunctionalBasisArray()
            The n-derivative of the function.

        &#39;&#39;&#39;
        df = deepcopy(self)
        df.basis = self.basis.derivative(n)
        return df

    def random(self, n=1, measure=None):
        &#39;&#39;&#39;
        Compute evaluations of the function at an array of points of size n,
        drawn randomly according to the tensap.ProbabilityMeasure measure if
        provided, or to the standard tensap.ProbabilityMeasure associated with
        each polynomial if not.

        Parameters
        ----------
        n : int, optional
            The number of random evaluations. The default is 1.
        measure : tensap.ProbabilityMeasure, optional
            The probability measure used to draw the points of evaluation. The
            default is None, indicating to use the standard
            tensap.ProbabilityMeasure associated with each polynomial.

        Returns
        -------
        numpy.ndarray
            The random evaluations of the function.
        numpy.ndarray
            The points used for the evaluations of the function.

        &#39;&#39;&#39;
        fx, x = self.basis.random(n, measure)
        y = np.matmul(fx, np.reshape(self.data, [self.basis.cardinal(),
                                                 np.prod(self.shape)],
                                     order=&#39;F&#39;))
        return np.reshape(y, np.concatenate(([fx.shape[0]], self.shape)),
                          order=&#39;F&#39;), x

    def get_random_vector(self):
        &#39;&#39;&#39;
        Return the random vector associated with the basis functions of the
        object.

        Returns
        -------
        tensap.RandomVector
            The random vector associated with the basis functions of the
            object.

        &#39;&#39;&#39;
        return self.basis.get_random_vector()

    def storage(self):
        &#39;&#39;&#39;
        The storage complexity of the object.

        Returns
        -------
        int
            The storage complexity of the object.

        &#39;&#39;&#39;
        return np.size(self.data)

    def sparse_storage(self):
        &#39;&#39;&#39;
        The storage complexity of the object, taking into account the sparsity.

        Returns
        -------
        int
            The storage complexity of the object, taking into account the
            sparsity.

        &#39;&#39;&#39;
        return np.count_nonzero(self.data)

    def projection(self, basis, indices=None):
        &#39;&#39;&#39;
        Projection of the object on a functional basis using multi-indices
        indices if provided, or the multi-indices associated with
        the functional basis if not.

        Parameters
        ----------
        basis : tensap.FunctionalBasis (tensap.FullTensorProductFunctionalBasis
                or tensap.SparseTensorProductFunctionalBasis)
            The basis used for the projection.
        indices : tensap.MultiIndices, optional
            The multi-indices used for the projection. The default is None,
            indicating to use basis.indices.

        Returns
        -------
        FunctionalBasisArray
            The obtained projection.

        &#39;&#39;&#39;
        if indices is None:
            if isinstance(basis, tensap.SparseTensorProductFunctionalBasis):
                indices = basis.indices
            else:
                raise ValueError(&#39;Must specify a MultiIndices.&#39;)

        if self.basis.ndim() == basis.ndim() and \
                self.basis.cardinal() &lt;= basis.cardinal():
            d = np.zeros((basis.cardinal(), np.prod(self.shape)))
            _, ia, ib = self.basis.indices.intersect_indices(indices)
            d[ib, :] = self.data[ia, :]
            if np.ndim(self.data) != np.ndim(d):
                d = np.reshape(d, [basis.cardinal(), self.shape], order=&#39;F&#39;)

            if isinstance(basis, tensap.FullTensorProductFunctionalBasis):
                H = tensap.FullTensorProductIntegrationRule(basis.bases)
            elif isinstance(basis, tensap.SparseTensorProductFunctionalBasis):
                H = tensap.SparseTensorProductFunctionalBasis(basis.bases,
                                                              indices)
            g = FunctionalBasisArray(d, H, self.shape)
        else:
            raise NotImplementedError(&#39;Method not implemented.&#39;)
        return g

    def sub_functional_basis(self):
        &#39;&#39;&#39;
        Converts the FunctionalBasisArray into a tensap.SubFunctionalbasis.

        Returns
        -------
        tensap.SubFunctionalbasis
            The FunctionalBasisArray as a tensap.SubFunctionalbasis.

        &#39;&#39;&#39;
        return tensap.SubFunctionalBasis(self.basis, self.data)

    def get_coefficients(self):
        &#39;&#39;&#39;
        Return the coefficients of the object.

        Returns
        -------
        numpy.ndarray
            The coefficients of the object.

        &#39;&#39;&#39;
        return np.reshape(self.data, np.concatenate(([self.basis.cardinal()],
                                                     self.shape)),
                          order=&#39;F&#39;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray"><code class="flex name class">
<span>class <span class="ident">FunctionalBasisArray</span></span>
<span>(</span><span>data=None, basis=None, shape=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Class FunctionalBasisArray.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>numpy.ndarray</code>, optional</dt>
<dd>The coefficents of the function on the basis. The default is None.</dd>
<dt><strong><code>basis</code></strong> :&ensp;<code>tensap.FunctionalBasis</code>, optional</dt>
<dd>The basis. The default is None.</dd>
<dt><strong><code>shape</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>Array such that the function is with values in
R^(shape[0] x shape[1] x &hellip;). The default is 1.</dd>
</dl>
<p>Constructor for the class FunctionalBasisArray</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>numpy.ndarray</code>, optional</dt>
<dd>The coefficents of the function on the basis. The default is None.</dd>
<dt><strong><code>basis</code></strong> :&ensp;<code>tensap.FunctionalBasis</code>, optional</dt>
<dd>The basis. The default is None.</dd>
<dt><strong><code>shape</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>Array such that the function is with values in
R^(shape[0] x shape[1] x &hellip;). The default is 1.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FunctionalBasisArray(tensap.Function):
    &#39;&#39;&#39;
    Class FunctionalBasisArray.

    Attributes
    ----------
    data : numpy.ndarray, optional
            The coefficents of the function on the basis. The default is None.
    basis : tensap.FunctionalBasis, optional
        The basis. The default is None.
    shape : list or numpy.ndarray, optional
        Array such that the function is with values in
        R^(shape[0] x shape[1] x ...). The default is 1.

    &#39;&#39;&#39;

    def __init__(self, data=None, basis=None, shape=None):
        &#39;&#39;&#39;
        Constructor for the class FunctionalBasisArray

        Parameters
        ----------
        data : numpy.ndarray, optional
            The coefficents of the function on the basis. The default is None.
        basis : tensap.FunctionalBasis, optional
            The basis. The default is None.
        shape : list or numpy.ndarray, optional
            Array such that the function is with values in
            R^(shape[0] x shape[1] x ...). The default is 1.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        tensap.Function.__init__(self)

        if shape is None and (data is not None or basis is not None):
            shape = 1

        self.data = np.ravel(data)
        self.basis = deepcopy(basis)
        self.shape = np.atleast_1d(shape)
        self.output_shape = self.shape
        self.data = np.reshape(self.data,
                               np.concatenate(([basis.cardinal()],
                                               self.shape)))

    def __add__(self, g):
        return FunctionalBasisArray(self.data + g.data, self.basis, self.shape)

    def __neg__(self):
        return FunctionalBasisArray(-self.data, self.basis, self.shape)

    def __sub__(self, g):
        return FunctionalBasisArray(self.data - g.data, self.basis, self.shape)

    def __mul__(self, g):
        if isinstance(g, FunctionalBasisArray):
            g = g.data
        return FunctionalBasisArray(self.data * g, self.basis, self.shape)

    def matmul(self, v):
        &#39;&#39;&#39;
        Compute the matrix multiplication of self.data with v.

        Parameters
        ----------
        v : numpy.ndarray
            The array used in the matrix multiplication.

        Returns
        -------
        tensap.FunctionalBasisArray
            The result of the matrix multiplication.

        &#39;&#39;&#39;
        data = np.matmul(self.data, v)
        return FunctionalBasisArray(data, self.basis, data.shape[1:])

    def matdiv(self, v):
        &#39;&#39;&#39;
        Compute the matrix multiplication of self.data with the inverse of v.

        Parameters
        ----------
        v : numpy.ndarray
            The array used in the matrix multiplication.

        Returns
        -------
        tensap.FunctionalBasisArray
            The result of the matrix multiplication.

        &#39;&#39;&#39;
        data = np.transpose(np.linalg.solve(np.transpose(v),
                                            np.transpose(self.data)))
        return FunctionalBasisArray(data, self.basis, self.shape)

    def dot(self, g, dim=None):
        &#39;&#39;&#39;
        Compute the dot product between the arrays self.data and g.data
        treated as collections of vectors. The function calculates
        the dot product of corresponding vectors along the first
        array dimension whose size does not equal 1.

        Parameters
        ----------
        g : tensap.FunctionalBasisArray
            The second object of the dot product.
        dim : int or list or numpy.ndarray, optional
            The dimension along which the dot product is computed. The default
            is None, indicating all the dimensions.

        Returns
        -------
        float or numpy.ndarray
            The result of the dot product.

        &#39;&#39;&#39;
        return np.sum(self.data * g.data, dim, keepdims=True)

    def norm(self, p=&#39;fro&#39;):
        &#39;&#39;&#39;
        Compute the p-norm of the array self.data.

        See also numpy.linalg.norm.

        Parameters
        ----------
        p : int or numpy.inf or -numpy.inf or string, optional
            The order of the norm. The default is &#39;fro&#39;.

        Returns
        -------
        float
            The norm of self.data.

        &#39;&#39;&#39;
        return np.linalg.norm(np.reshape(self.data,
                                         [self.basis.cardinal(), -1],
                                         order=&#39;F&#39;), p)

    @staticmethod
    def is_random():
        &#39;&#39;&#39;
        Determine if the object is random.

        Returns
        -------
        bool
            Boolean equal to True if the object is random.

        &#39;&#39;&#39;
        return True

    def mean(self, measure=None):
        &#39;&#39;&#39;
        Compute the expectation of the function, according to the measure
        associated with the tensap.ProbabilityMeasure measure if provided, or
        to the standard tensap.ProbabilityMeasure associated with each
        polynomial if not.

        Parameters
        ----------
        measure : tensap.ProbabilityMeasure, optional
            The probability measure used for the computation of the
            expectation. The default is None, indicating to use the standard
            tensap.ProbabilityMeasure associated with each polynomial.

        Returns
        -------
        numpy.ndarray
            The expectation of the function.

        &#39;&#39;&#39;
        M = self.basis.mean(measure)
        M = np.tile(np.ravel(M), np.concatenate((self.shape, [1])))
        M = np.transpose(M, np.concatenate(([np.ndim(M)-1],
                                            range(np.ndim(M)-1))))
        return np.sum(self.data*M, 0, keepdims=True)

    def expectation(self, measure=None):
        &#39;&#39;&#39;
        Compute the expectation of the function, according to the measure
        associated with the tensap.ProbabilityMeasure measure if provided, or
        to the standard tensap.ProbabilityMeasure associated with each
        polynomial if not.

        Parameters
        ----------
        measure : tensap.ProbabilityMeasure, optional
            The probability measure used for the computation of the
            expectation. The default is None, indicating to use the standard
            tensap.ProbabilityMeasure associated with each polynomial.

        Returns
        -------
        numpy.ndarray
            The expectation of the function.

        &#39;&#39;&#39;
        return self.mean(measure)

    def variance(self, measure=None):
        &#39;&#39;&#39;
        Compute the variance of the function, according to the measure
        associated with the tensap.ProbabilityMeasure measure if provided, or
        to the standard tensap.ProbabilityMeasure associated with each
        polynomial if not.

        Parameters
        ----------
        measure : tensap.ProbabilityMeasure, optional
            The probability measure used for the computation of the variance.
            The default is None, indicating to use the standard
            tensap.ProbabilityMeasure associated with each polynomial.

        Returns
        -------
        numpy.ndarray
            The variance of the function.

        &#39;&#39;&#39;
        m = self.expectation(measure)
        return self.dot_product_expectation(self, None, measure) - m**2

    def std(self, *args):
        &#39;&#39;&#39;
        Compute the standard deviation of the function, according to the
        measure associated with the tensap.ProbabilityMeasure measure if
        provided, or to the standard tensap.ProbabilityMeasure associated with
        each polynomial if not.

        Parameters
        ----------
        measure : tensap.ProbabilityMeasure, optional
            The probability measure used for the computation of the standard
            deviation. The default is None, indicating to use the standard
            tensap.ProbabilityMeasure associated with each polynomial.

        Returns
        -------
        numpy.ndarray
            The standard deviation of the function.

        &#39;&#39;&#39;
        return np.sqrt(self.variance(*args))

    def dot_product_expectation(self, g, dims=None, measure=None):
        &#39;&#39;&#39;
        Compute the expectation of self(X)g(X), where X is the probability
        measure associated with the underlying basis, or measure if provided.

        For vector-valued functions of X, dims specifies the dimensions of
        self and g corresponding to the RandomVector measure.

        Parameters
        ----------
        g : tensap.FunctionalBasisArray
            The second function of the product.
        dims : list or numpy.ndarray, optional
            The dimensions of self and g corresponding to the RandomVector
            measure. The default is None.
        measure : tensap.ProbabilityMeasure, optional
            The probability measure used for the computation of the
            expectation. The default is None, indicating to use the probability
            measure associated with the underlying basis.

        Raises
        ------
        NotImplementedError
            If the method is not implemented.

        Returns
        -------
        float or numpy.ndarray
            The result of the dot product.

        &#39;&#39;&#39;
        if dims is None:
            dims = range(self.basis.cardinal())
        if not (self.basis == g.basis) or not self.basis.is_orthonormal:
            raise NotImplementedError(&#39;Method not implemented.&#39;)

        return self.dot(g, 0)

    def norm_expectation(self, measure=None):
        &#39;&#39;&#39;
        Compute the L^2 norm of self(measure). If measure is not provided, use
        the probability measure associated with the underlying basis of self.

        Parameters
        ----------
        measure : tap.ProbabilityMeasure, optional
            DESCRIPTION. The default is None.

        Returns
        -------
        float
            The L2 norm of the function.

        &#39;&#39;&#39;
        return np.sqrt(self.dot_product_expectation(self, None, measure))

    def conditional_expectation(self, dims, *args):
        &#39;&#39;&#39;
        Compute the conditional expectation of self with respect to
        the random variables dims (a subset of range(d)). The expectation
        with respect to other variables (in the complementary set of
        dims) is taken with respect to the probability measure given by
        tensap.RandomVector XdimsC if provided, or with respect to the
        probability measure associated with the corresponding bases of
        the function.

        Parameters
        ----------
        dims : numpy.ndarray
            The dimensions in which the expectation is computed.
        *args : tuple
            Additional parameters. See also the method conditional_expectation
            of the underlying basis.

        Returns
        -------
        f : tensap.FunctionalBasisArray
            The conditional expectation of the function.

        &#39;&#39;&#39;
        h = self.basis.conditional_expectation(dims, *args)
        f = deepcopy(self)
        f.data = np.matmul(h.data, np.reshape(self.data,
                                              [self.basis.cardinal(),
                                               np.prod(self.shape)],
                                              order=&#39;F&#39;))
        f.data = np.reshape(f.data, (f.data.shape[0], f.shape), order=&#39;F&#39;)
        f.basis = h.basis
        return f

    def variance_conditional_expectation(self, alpha):
        &#39;&#39;&#39;
        Compute the variance of the conditional expectation of the function in
        dimensions in alpha.

        Parameters
        ----------
        alpha : numpy.ndarray
            The dimensions in which the variance of the conditional expectation
            of the function if computed.

        Returns
        -------
        numpy.ndarray
            The variance of the conditional expectation of the function.

        &#39;&#39;&#39;
        alpha = np.atleast_2d(alpha)
        m = self.expectation()
        v = np.zeros((np.shape(alpha)[0], np.prod(self.shape)))
        for i in range(np.shape(alpha)[0]):
            u = alpha[i, :]
            if np.all([isinstance(x, bool) for x in u]):
                u = np.nonzero(u)[0]

            if np.size(u) == 0:
                v[i, :] = 0
            else:
                mi = self.conditional_expectation(u)
                vi = mi.dot_product_expectation(mi) - m**2
                v[i, :] = np.ravel(vi)

        return np.reshape(v, np.concatenate(([np.shape(alpha)[0]],
                                             self.shape)), order=&#39;F&#39;)

    def eval(self, x, *args):
        if np.ndim(x) == 1:
            x = np.expand_dims(x, 1)
        H = self.basis.eval(x, *args)
        return self.eval_with_bases_evals(H, *args)

    def eval_with_bases_evals(self, H):
        &#39;&#39;&#39;
        Compute the evaluations of the function using the evaluations of the
        basis H.

        Parameters
        ----------
        H : numpy.ndarray
            The evaluations of the basis.

        Returns
        -------
        numpy.ndarray
            The evaluations of the function.

        &#39;&#39;&#39;
        y = np.matmul(H, np.reshape(self.data, [self.basis.cardinal(),
                                                np.prod(self.shape)],
                                    order=&#39;F&#39;))
        return np.reshape(y, np.concatenate(([H.shape[0]], self.shape)),
                          order=&#39;F&#39;)

    def eval_derivative(self, n, x):
        &#39;&#39;&#39;
        Compute the n-derivative of the function at points x in R^d, with n a
        multi-index of size d.

        Parameters
        ----------
        n : int or list or numpy.ndarray
            The derivation order in all the dimensions, or the derivation
            orders for each dimension.
        x : numpy.ndarray
            The points used for the evaluation of the derivative.

        Raises
        ------
        NotImplementedError
            If the method is not implemented for the basis.

        Returns
        -------
        numpy.ndarray
            The evaluation of the n-derivative of the function at the points x.

        &#39;&#39;&#39;
        try:
            H = self.basis.eval_derivative(n, x)
            return self.eval_with_bases_evals(H)
        except Exception:
            raise NotImplementedError(&#39;Method not implemented for the basis.&#39;)

    def derivative(self, n):
        &#39;&#39;&#39;
        Compute the n-derivative of the function.

        Parameters
        ----------
        n : int
            The derivation order.

        Returns
        -------
        df : tensap.FunctionalBasisArray()
            The n-derivative of the function.

        &#39;&#39;&#39;
        df = deepcopy(self)
        df.basis = self.basis.derivative(n)
        return df

    def random(self, n=1, measure=None):
        &#39;&#39;&#39;
        Compute evaluations of the function at an array of points of size n,
        drawn randomly according to the tensap.ProbabilityMeasure measure if
        provided, or to the standard tensap.ProbabilityMeasure associated with
        each polynomial if not.

        Parameters
        ----------
        n : int, optional
            The number of random evaluations. The default is 1.
        measure : tensap.ProbabilityMeasure, optional
            The probability measure used to draw the points of evaluation. The
            default is None, indicating to use the standard
            tensap.ProbabilityMeasure associated with each polynomial.

        Returns
        -------
        numpy.ndarray
            The random evaluations of the function.
        numpy.ndarray
            The points used for the evaluations of the function.

        &#39;&#39;&#39;
        fx, x = self.basis.random(n, measure)
        y = np.matmul(fx, np.reshape(self.data, [self.basis.cardinal(),
                                                 np.prod(self.shape)],
                                     order=&#39;F&#39;))
        return np.reshape(y, np.concatenate(([fx.shape[0]], self.shape)),
                          order=&#39;F&#39;), x

    def get_random_vector(self):
        &#39;&#39;&#39;
        Return the random vector associated with the basis functions of the
        object.

        Returns
        -------
        tensap.RandomVector
            The random vector associated with the basis functions of the
            object.

        &#39;&#39;&#39;
        return self.basis.get_random_vector()

    def storage(self):
        &#39;&#39;&#39;
        The storage complexity of the object.

        Returns
        -------
        int
            The storage complexity of the object.

        &#39;&#39;&#39;
        return np.size(self.data)

    def sparse_storage(self):
        &#39;&#39;&#39;
        The storage complexity of the object, taking into account the sparsity.

        Returns
        -------
        int
            The storage complexity of the object, taking into account the
            sparsity.

        &#39;&#39;&#39;
        return np.count_nonzero(self.data)

    def projection(self, basis, indices=None):
        &#39;&#39;&#39;
        Projection of the object on a functional basis using multi-indices
        indices if provided, or the multi-indices associated with
        the functional basis if not.

        Parameters
        ----------
        basis : tensap.FunctionalBasis (tensap.FullTensorProductFunctionalBasis
                or tensap.SparseTensorProductFunctionalBasis)
            The basis used for the projection.
        indices : tensap.MultiIndices, optional
            The multi-indices used for the projection. The default is None,
            indicating to use basis.indices.

        Returns
        -------
        FunctionalBasisArray
            The obtained projection.

        &#39;&#39;&#39;
        if indices is None:
            if isinstance(basis, tensap.SparseTensorProductFunctionalBasis):
                indices = basis.indices
            else:
                raise ValueError(&#39;Must specify a MultiIndices.&#39;)

        if self.basis.ndim() == basis.ndim() and \
                self.basis.cardinal() &lt;= basis.cardinal():
            d = np.zeros((basis.cardinal(), np.prod(self.shape)))
            _, ia, ib = self.basis.indices.intersect_indices(indices)
            d[ib, :] = self.data[ia, :]
            if np.ndim(self.data) != np.ndim(d):
                d = np.reshape(d, [basis.cardinal(), self.shape], order=&#39;F&#39;)

            if isinstance(basis, tensap.FullTensorProductFunctionalBasis):
                H = tensap.FullTensorProductIntegrationRule(basis.bases)
            elif isinstance(basis, tensap.SparseTensorProductFunctionalBasis):
                H = tensap.SparseTensorProductFunctionalBasis(basis.bases,
                                                              indices)
            g = FunctionalBasisArray(d, H, self.shape)
        else:
            raise NotImplementedError(&#39;Method not implemented.&#39;)
        return g

    def sub_functional_basis(self):
        &#39;&#39;&#39;
        Converts the FunctionalBasisArray into a tensap.SubFunctionalbasis.

        Returns
        -------
        tensap.SubFunctionalbasis
            The FunctionalBasisArray as a tensap.SubFunctionalbasis.

        &#39;&#39;&#39;
        return tensap.SubFunctionalBasis(self.basis, self.data)

    def get_coefficients(self):
        &#39;&#39;&#39;
        Return the coefficients of the object.

        Returns
        -------
        numpy.ndarray
            The coefficients of the object.

        &#39;&#39;&#39;
        return np.reshape(self.data, np.concatenate(([self.basis.cardinal()],
                                                     self.shape)),
                          order=&#39;F&#39;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="tensap.functions.function.Function" href="../../functions/function.html#tensap.functions.function.Function">Function</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.is_random"><code class="name flex">
<span>def <span class="ident">is_random</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Determine if the object is random.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Boolean equal to True if the object is random.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def is_random():
    &#39;&#39;&#39;
    Determine if the object is random.

    Returns
    -------
    bool
        Boolean equal to True if the object is random.

    &#39;&#39;&#39;
    return True</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.conditional_expectation"><code class="name flex">
<span>def <span class="ident">conditional_expectation</span></span>(<span>self, dims, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the conditional expectation of self with respect to
the random variables dims (a subset of range(d)). The expectation
with respect to other variables (in the complementary set of
dims) is taken with respect to the probability measure given by
tensap.RandomVector XdimsC if provided, or with respect to the
probability measure associated with the corresponding bases of
the function.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The dimensions in which the expectation is computed.</dd>
<dt><strong><code>*args</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Additional parameters. See also the method conditional_expectation
of the underlying basis.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>f</code></strong> :&ensp;<code>tensap.FunctionalBasisArray</code></dt>
<dd>The conditional expectation of the function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def conditional_expectation(self, dims, *args):
    &#39;&#39;&#39;
    Compute the conditional expectation of self with respect to
    the random variables dims (a subset of range(d)). The expectation
    with respect to other variables (in the complementary set of
    dims) is taken with respect to the probability measure given by
    tensap.RandomVector XdimsC if provided, or with respect to the
    probability measure associated with the corresponding bases of
    the function.

    Parameters
    ----------
    dims : numpy.ndarray
        The dimensions in which the expectation is computed.
    *args : tuple
        Additional parameters. See also the method conditional_expectation
        of the underlying basis.

    Returns
    -------
    f : tensap.FunctionalBasisArray
        The conditional expectation of the function.

    &#39;&#39;&#39;
    h = self.basis.conditional_expectation(dims, *args)
    f = deepcopy(self)
    f.data = np.matmul(h.data, np.reshape(self.data,
                                          [self.basis.cardinal(),
                                           np.prod(self.shape)],
                                          order=&#39;F&#39;))
    f.data = np.reshape(f.data, (f.data.shape[0], f.shape), order=&#39;F&#39;)
    f.basis = h.basis
    return f</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.derivative"><code class="name flex">
<span>def <span class="ident">derivative</span></span>(<span>self, n)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the n-derivative of the function.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>The derivation order.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>tensap.FunctionalBasisArray()</code></dt>
<dd>The n-derivative of the function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def derivative(self, n):
    &#39;&#39;&#39;
    Compute the n-derivative of the function.

    Parameters
    ----------
    n : int
        The derivation order.

    Returns
    -------
    df : tensap.FunctionalBasisArray()
        The n-derivative of the function.

    &#39;&#39;&#39;
    df = deepcopy(self)
    df.basis = self.basis.derivative(n)
    return df</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.dot"><code class="name flex">
<span>def <span class="ident">dot</span></span>(<span>self, g, dim=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the dot product between the arrays self.data and g.data
treated as collections of vectors. The function calculates
the dot product of corresponding vectors along the first
array dimension whose size does not equal 1.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>g</code></strong> :&ensp;<code>tensap.FunctionalBasisArray</code></dt>
<dd>The second object of the dot product.</dd>
<dt><strong><code>dim</code></strong> :&ensp;<code>int</code> or <code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>The dimension along which the dot product is computed. The default
is None, indicating all the dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code> or <code>numpy.ndarray</code></dt>
<dd>The result of the dot product.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dot(self, g, dim=None):
    &#39;&#39;&#39;
    Compute the dot product between the arrays self.data and g.data
    treated as collections of vectors. The function calculates
    the dot product of corresponding vectors along the first
    array dimension whose size does not equal 1.

    Parameters
    ----------
    g : tensap.FunctionalBasisArray
        The second object of the dot product.
    dim : int or list or numpy.ndarray, optional
        The dimension along which the dot product is computed. The default
        is None, indicating all the dimensions.

    Returns
    -------
    float or numpy.ndarray
        The result of the dot product.

    &#39;&#39;&#39;
    return np.sum(self.data * g.data, dim, keepdims=True)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.dot_product_expectation"><code class="name flex">
<span>def <span class="ident">dot_product_expectation</span></span>(<span>self, g, dims=None, measure=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the expectation of self(X)g(X), where X is the probability
measure associated with the underlying basis, or measure if provided.</p>
<p>For vector-valued functions of X, dims specifies the dimensions of
self and g corresponding to the RandomVector measure.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>g</code></strong> :&ensp;<code>tensap.FunctionalBasisArray</code></dt>
<dd>The second function of the product.</dd>
<dt><strong><code>dims</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code>, optional</dt>
<dd>The dimensions of self and g corresponding to the RandomVector
measure. The default is None.</dd>
<dt><strong><code>measure</code></strong> :&ensp;<code>tensap.ProbabilityMeasure</code>, optional</dt>
<dd>The probability measure used for the computation of the
expectation. The default is None, indicating to use the probability
measure associated with the underlying basis.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>NotImplementedError</code></dt>
<dd>If the method is not implemented.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code> or <code>numpy.ndarray</code></dt>
<dd>The result of the dot product.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dot_product_expectation(self, g, dims=None, measure=None):
    &#39;&#39;&#39;
    Compute the expectation of self(X)g(X), where X is the probability
    measure associated with the underlying basis, or measure if provided.

    For vector-valued functions of X, dims specifies the dimensions of
    self and g corresponding to the RandomVector measure.

    Parameters
    ----------
    g : tensap.FunctionalBasisArray
        The second function of the product.
    dims : list or numpy.ndarray, optional
        The dimensions of self and g corresponding to the RandomVector
        measure. The default is None.
    measure : tensap.ProbabilityMeasure, optional
        The probability measure used for the computation of the
        expectation. The default is None, indicating to use the probability
        measure associated with the underlying basis.

    Raises
    ------
    NotImplementedError
        If the method is not implemented.

    Returns
    -------
    float or numpy.ndarray
        The result of the dot product.

    &#39;&#39;&#39;
    if dims is None:
        dims = range(self.basis.cardinal())
    if not (self.basis == g.basis) or not self.basis.is_orthonormal:
        raise NotImplementedError(&#39;Method not implemented.&#39;)

    return self.dot(g, 0)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.eval_derivative"><code class="name flex">
<span>def <span class="ident">eval_derivative</span></span>(<span>self, n, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the n-derivative of the function at points x in R^d, with n a
multi-index of size d.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code> or <code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The derivation order in all the dimensions, or the derivation
orders for each dimension.</dd>
<dt><strong><code>x</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The points used for the evaluation of the derivative.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>NotImplementedError</code></dt>
<dd>If the method is not implemented for the basis.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The evaluation of the n-derivative of the function at the points x.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval_derivative(self, n, x):
    &#39;&#39;&#39;
    Compute the n-derivative of the function at points x in R^d, with n a
    multi-index of size d.

    Parameters
    ----------
    n : int or list or numpy.ndarray
        The derivation order in all the dimensions, or the derivation
        orders for each dimension.
    x : numpy.ndarray
        The points used for the evaluation of the derivative.

    Raises
    ------
    NotImplementedError
        If the method is not implemented for the basis.

    Returns
    -------
    numpy.ndarray
        The evaluation of the n-derivative of the function at the points x.

    &#39;&#39;&#39;
    try:
        H = self.basis.eval_derivative(n, x)
        return self.eval_with_bases_evals(H)
    except Exception:
        raise NotImplementedError(&#39;Method not implemented for the basis.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.eval_with_bases_evals"><code class="name flex">
<span>def <span class="ident">eval_with_bases_evals</span></span>(<span>self, H)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the evaluations of the function using the evaluations of the
basis H.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>H</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The evaluations of the basis.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The evaluations of the function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval_with_bases_evals(self, H):
    &#39;&#39;&#39;
    Compute the evaluations of the function using the evaluations of the
    basis H.

    Parameters
    ----------
    H : numpy.ndarray
        The evaluations of the basis.

    Returns
    -------
    numpy.ndarray
        The evaluations of the function.

    &#39;&#39;&#39;
    y = np.matmul(H, np.reshape(self.data, [self.basis.cardinal(),
                                            np.prod(self.shape)],
                                order=&#39;F&#39;))
    return np.reshape(y, np.concatenate(([H.shape[0]], self.shape)),
                      order=&#39;F&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.expectation"><code class="name flex">
<span>def <span class="ident">expectation</span></span>(<span>self, measure=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the expectation of the function, according to the measure
associated with the tensap.ProbabilityMeasure measure if provided, or
to the standard tensap.ProbabilityMeasure associated with each
polynomial if not.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>measure</code></strong> :&ensp;<code>tensap.ProbabilityMeasure</code>, optional</dt>
<dd>The probability measure used for the computation of the
expectation. The default is None, indicating to use the standard
tensap.ProbabilityMeasure associated with each polynomial.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The expectation of the function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expectation(self, measure=None):
    &#39;&#39;&#39;
    Compute the expectation of the function, according to the measure
    associated with the tensap.ProbabilityMeasure measure if provided, or
    to the standard tensap.ProbabilityMeasure associated with each
    polynomial if not.

    Parameters
    ----------
    measure : tensap.ProbabilityMeasure, optional
        The probability measure used for the computation of the
        expectation. The default is None, indicating to use the standard
        tensap.ProbabilityMeasure associated with each polynomial.

    Returns
    -------
    numpy.ndarray
        The expectation of the function.

    &#39;&#39;&#39;
    return self.mean(measure)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.get_coefficients"><code class="name flex">
<span>def <span class="ident">get_coefficients</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the coefficients of the object.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The coefficients of the object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_coefficients(self):
    &#39;&#39;&#39;
    Return the coefficients of the object.

    Returns
    -------
    numpy.ndarray
        The coefficients of the object.

    &#39;&#39;&#39;
    return np.reshape(self.data, np.concatenate(([self.basis.cardinal()],
                                                 self.shape)),
                      order=&#39;F&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.get_random_vector"><code class="name flex">
<span>def <span class="ident">get_random_vector</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the random vector associated with the basis functions of the
object.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensap.RandomVector</code></dt>
<dd>The random vector associated with the basis functions of the
object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_random_vector(self):
    &#39;&#39;&#39;
    Return the random vector associated with the basis functions of the
    object.

    Returns
    -------
    tensap.RandomVector
        The random vector associated with the basis functions of the
        object.

    &#39;&#39;&#39;
    return self.basis.get_random_vector()</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.matdiv"><code class="name flex">
<span>def <span class="ident">matdiv</span></span>(<span>self, v)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the matrix multiplication of self.data with the inverse of v.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>v</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The array used in the matrix multiplication.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensap.FunctionalBasisArray</code></dt>
<dd>The result of the matrix multiplication.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def matdiv(self, v):
    &#39;&#39;&#39;
    Compute the matrix multiplication of self.data with the inverse of v.

    Parameters
    ----------
    v : numpy.ndarray
        The array used in the matrix multiplication.

    Returns
    -------
    tensap.FunctionalBasisArray
        The result of the matrix multiplication.

    &#39;&#39;&#39;
    data = np.transpose(np.linalg.solve(np.transpose(v),
                                        np.transpose(self.data)))
    return FunctionalBasisArray(data, self.basis, self.shape)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.matmul"><code class="name flex">
<span>def <span class="ident">matmul</span></span>(<span>self, v)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the matrix multiplication of self.data with v.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>v</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The array used in the matrix multiplication.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensap.FunctionalBasisArray</code></dt>
<dd>The result of the matrix multiplication.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def matmul(self, v):
    &#39;&#39;&#39;
    Compute the matrix multiplication of self.data with v.

    Parameters
    ----------
    v : numpy.ndarray
        The array used in the matrix multiplication.

    Returns
    -------
    tensap.FunctionalBasisArray
        The result of the matrix multiplication.

    &#39;&#39;&#39;
    data = np.matmul(self.data, v)
    return FunctionalBasisArray(data, self.basis, data.shape[1:])</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.mean"><code class="name flex">
<span>def <span class="ident">mean</span></span>(<span>self, measure=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the expectation of the function, according to the measure
associated with the tensap.ProbabilityMeasure measure if provided, or
to the standard tensap.ProbabilityMeasure associated with each
polynomial if not.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>measure</code></strong> :&ensp;<code>tensap.ProbabilityMeasure</code>, optional</dt>
<dd>The probability measure used for the computation of the
expectation. The default is None, indicating to use the standard
tensap.ProbabilityMeasure associated with each polynomial.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The expectation of the function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean(self, measure=None):
    &#39;&#39;&#39;
    Compute the expectation of the function, according to the measure
    associated with the tensap.ProbabilityMeasure measure if provided, or
    to the standard tensap.ProbabilityMeasure associated with each
    polynomial if not.

    Parameters
    ----------
    measure : tensap.ProbabilityMeasure, optional
        The probability measure used for the computation of the
        expectation. The default is None, indicating to use the standard
        tensap.ProbabilityMeasure associated with each polynomial.

    Returns
    -------
    numpy.ndarray
        The expectation of the function.

    &#39;&#39;&#39;
    M = self.basis.mean(measure)
    M = np.tile(np.ravel(M), np.concatenate((self.shape, [1])))
    M = np.transpose(M, np.concatenate(([np.ndim(M)-1],
                                        range(np.ndim(M)-1))))
    return np.sum(self.data*M, 0, keepdims=True)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.norm"><code class="name flex">
<span>def <span class="ident">norm</span></span>(<span>self, p='fro')</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the p-norm of the array self.data.</p>
<p>See also numpy.linalg.norm.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>p</code></strong> :&ensp;<code>int</code> or <code>numpy.inf</code> or <code>-numpy.inf</code> or <code>string</code>, optional</dt>
<dd>The order of the norm. The default is 'fro'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>The norm of self.data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def norm(self, p=&#39;fro&#39;):
    &#39;&#39;&#39;
    Compute the p-norm of the array self.data.

    See also numpy.linalg.norm.

    Parameters
    ----------
    p : int or numpy.inf or -numpy.inf or string, optional
        The order of the norm. The default is &#39;fro&#39;.

    Returns
    -------
    float
        The norm of self.data.

    &#39;&#39;&#39;
    return np.linalg.norm(np.reshape(self.data,
                                     [self.basis.cardinal(), -1],
                                     order=&#39;F&#39;), p)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.norm_expectation"><code class="name flex">
<span>def <span class="ident">norm_expectation</span></span>(<span>self, measure=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the L^2 norm of self(measure). If measure is not provided, use
the probability measure associated with the underlying basis of self.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>measure</code></strong> :&ensp;<code>tap.ProbabilityMeasure</code>, optional</dt>
<dd>DESCRIPTION. The default is None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>The L2 norm of the function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def norm_expectation(self, measure=None):
    &#39;&#39;&#39;
    Compute the L^2 norm of self(measure). If measure is not provided, use
    the probability measure associated with the underlying basis of self.

    Parameters
    ----------
    measure : tap.ProbabilityMeasure, optional
        DESCRIPTION. The default is None.

    Returns
    -------
    float
        The L2 norm of the function.

    &#39;&#39;&#39;
    return np.sqrt(self.dot_product_expectation(self, None, measure))</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.projection"><code class="name flex">
<span>def <span class="ident">projection</span></span>(<span>self, basis, indices=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Projection of the object on a functional basis using multi-indices
indices if provided, or the multi-indices associated with
the functional basis if not.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>basis</code></strong> :&ensp;<code>tensap.FunctionalBasis (tensap.FullTensorProductFunctionalBasis</code></dt>
<dd>or tensap.SparseTensorProductFunctionalBasis)
The basis used for the projection.</dd>
<dt><strong><code>indices</code></strong> :&ensp;<code>tensap.MultiIndices</code>, optional</dt>
<dd>The multi-indices used for the projection. The default is None,
indicating to use basis.indices.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray">FunctionalBasisArray</a></code></dt>
<dd>The obtained projection.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def projection(self, basis, indices=None):
    &#39;&#39;&#39;
    Projection of the object on a functional basis using multi-indices
    indices if provided, or the multi-indices associated with
    the functional basis if not.

    Parameters
    ----------
    basis : tensap.FunctionalBasis (tensap.FullTensorProductFunctionalBasis
            or tensap.SparseTensorProductFunctionalBasis)
        The basis used for the projection.
    indices : tensap.MultiIndices, optional
        The multi-indices used for the projection. The default is None,
        indicating to use basis.indices.

    Returns
    -------
    FunctionalBasisArray
        The obtained projection.

    &#39;&#39;&#39;
    if indices is None:
        if isinstance(basis, tensap.SparseTensorProductFunctionalBasis):
            indices = basis.indices
        else:
            raise ValueError(&#39;Must specify a MultiIndices.&#39;)

    if self.basis.ndim() == basis.ndim() and \
            self.basis.cardinal() &lt;= basis.cardinal():
        d = np.zeros((basis.cardinal(), np.prod(self.shape)))
        _, ia, ib = self.basis.indices.intersect_indices(indices)
        d[ib, :] = self.data[ia, :]
        if np.ndim(self.data) != np.ndim(d):
            d = np.reshape(d, [basis.cardinal(), self.shape], order=&#39;F&#39;)

        if isinstance(basis, tensap.FullTensorProductFunctionalBasis):
            H = tensap.FullTensorProductIntegrationRule(basis.bases)
        elif isinstance(basis, tensap.SparseTensorProductFunctionalBasis):
            H = tensap.SparseTensorProductFunctionalBasis(basis.bases,
                                                          indices)
        g = FunctionalBasisArray(d, H, self.shape)
    else:
        raise NotImplementedError(&#39;Method not implemented.&#39;)
    return g</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.random"><code class="name flex">
<span>def <span class="ident">random</span></span>(<span>self, n=1, measure=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute evaluations of the function at an array of points of size n,
drawn randomly according to the tensap.ProbabilityMeasure measure if
provided, or to the standard tensap.ProbabilityMeasure associated with
each polynomial if not.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of random evaluations. The default is 1.</dd>
<dt><strong><code>measure</code></strong> :&ensp;<code>tensap.ProbabilityMeasure</code>, optional</dt>
<dd>The probability measure used to draw the points of evaluation. The
default is None, indicating to use the standard
tensap.ProbabilityMeasure associated with each polynomial.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The random evaluations of the function.</dd>
<dt><code>numpy.ndarray</code></dt>
<dd>The points used for the evaluations of the function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def random(self, n=1, measure=None):
    &#39;&#39;&#39;
    Compute evaluations of the function at an array of points of size n,
    drawn randomly according to the tensap.ProbabilityMeasure measure if
    provided, or to the standard tensap.ProbabilityMeasure associated with
    each polynomial if not.

    Parameters
    ----------
    n : int, optional
        The number of random evaluations. The default is 1.
    measure : tensap.ProbabilityMeasure, optional
        The probability measure used to draw the points of evaluation. The
        default is None, indicating to use the standard
        tensap.ProbabilityMeasure associated with each polynomial.

    Returns
    -------
    numpy.ndarray
        The random evaluations of the function.
    numpy.ndarray
        The points used for the evaluations of the function.

    &#39;&#39;&#39;
    fx, x = self.basis.random(n, measure)
    y = np.matmul(fx, np.reshape(self.data, [self.basis.cardinal(),
                                             np.prod(self.shape)],
                                 order=&#39;F&#39;))
    return np.reshape(y, np.concatenate(([fx.shape[0]], self.shape)),
                      order=&#39;F&#39;), x</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.sparse_storage"><code class="name flex">
<span>def <span class="ident">sparse_storage</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>The storage complexity of the object, taking into account the sparsity.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The storage complexity of the object, taking into account the
sparsity.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sparse_storage(self):
    &#39;&#39;&#39;
    The storage complexity of the object, taking into account the sparsity.

    Returns
    -------
    int
        The storage complexity of the object, taking into account the
        sparsity.

    &#39;&#39;&#39;
    return np.count_nonzero(self.data)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.std"><code class="name flex">
<span>def <span class="ident">std</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the standard deviation of the function, according to the
measure associated with the tensap.ProbabilityMeasure measure if
provided, or to the standard tensap.ProbabilityMeasure associated with
each polynomial if not.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>measure</code></strong> :&ensp;<code>tensap.ProbabilityMeasure</code>, optional</dt>
<dd>The probability measure used for the computation of the standard
deviation. The default is None, indicating to use the standard
tensap.ProbabilityMeasure associated with each polynomial.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The standard deviation of the function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def std(self, *args):
    &#39;&#39;&#39;
    Compute the standard deviation of the function, according to the
    measure associated with the tensap.ProbabilityMeasure measure if
    provided, or to the standard tensap.ProbabilityMeasure associated with
    each polynomial if not.

    Parameters
    ----------
    measure : tensap.ProbabilityMeasure, optional
        The probability measure used for the computation of the standard
        deviation. The default is None, indicating to use the standard
        tensap.ProbabilityMeasure associated with each polynomial.

    Returns
    -------
    numpy.ndarray
        The standard deviation of the function.

    &#39;&#39;&#39;
    return np.sqrt(self.variance(*args))</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.storage"><code class="name flex">
<span>def <span class="ident">storage</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>The storage complexity of the object.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The storage complexity of the object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def storage(self):
    &#39;&#39;&#39;
    The storage complexity of the object.

    Returns
    -------
    int
        The storage complexity of the object.

    &#39;&#39;&#39;
    return np.size(self.data)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.sub_functional_basis"><code class="name flex">
<span>def <span class="ident">sub_functional_basis</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts the FunctionalBasisArray into a tensap.SubFunctionalbasis.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensap.SubFunctionalbasis</code></dt>
<dd>The FunctionalBasisArray as a tensap.SubFunctionalbasis.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sub_functional_basis(self):
    &#39;&#39;&#39;
    Converts the FunctionalBasisArray into a tensap.SubFunctionalbasis.

    Returns
    -------
    tensap.SubFunctionalbasis
        The FunctionalBasisArray as a tensap.SubFunctionalbasis.

    &#39;&#39;&#39;
    return tensap.SubFunctionalBasis(self.basis, self.data)</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.variance"><code class="name flex">
<span>def <span class="ident">variance</span></span>(<span>self, measure=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the variance of the function, according to the measure
associated with the tensap.ProbabilityMeasure measure if provided, or
to the standard tensap.ProbabilityMeasure associated with each
polynomial if not.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>measure</code></strong> :&ensp;<code>tensap.ProbabilityMeasure</code>, optional</dt>
<dd>The probability measure used for the computation of the variance.
The default is None, indicating to use the standard
tensap.ProbabilityMeasure associated with each polynomial.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The variance of the function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def variance(self, measure=None):
    &#39;&#39;&#39;
    Compute the variance of the function, according to the measure
    associated with the tensap.ProbabilityMeasure measure if provided, or
    to the standard tensap.ProbabilityMeasure associated with each
    polynomial if not.

    Parameters
    ----------
    measure : tensap.ProbabilityMeasure, optional
        The probability measure used for the computation of the variance.
        The default is None, indicating to use the standard
        tensap.ProbabilityMeasure associated with each polynomial.

    Returns
    -------
    numpy.ndarray
        The variance of the function.

    &#39;&#39;&#39;
    m = self.expectation(measure)
    return self.dot_product_expectation(self, None, measure) - m**2</code></pre>
</details>
</dd>
<dt id="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.variance_conditional_expectation"><code class="name flex">
<span>def <span class="ident">variance_conditional_expectation</span></span>(<span>self, alpha)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the variance of the conditional expectation of the function in
dimensions in alpha.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>alpha</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The dimensions in which the variance of the conditional expectation
of the function if computed.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The variance of the conditional expectation of the function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def variance_conditional_expectation(self, alpha):
    &#39;&#39;&#39;
    Compute the variance of the conditional expectation of the function in
    dimensions in alpha.

    Parameters
    ----------
    alpha : numpy.ndarray
        The dimensions in which the variance of the conditional expectation
        of the function if computed.

    Returns
    -------
    numpy.ndarray
        The variance of the conditional expectation of the function.

    &#39;&#39;&#39;
    alpha = np.atleast_2d(alpha)
    m = self.expectation()
    v = np.zeros((np.shape(alpha)[0], np.prod(self.shape)))
    for i in range(np.shape(alpha)[0]):
        u = alpha[i, :]
        if np.all([isinstance(x, bool) for x in u]):
            u = np.nonzero(u)[0]

        if np.size(u) == 0:
            v[i, :] = 0
        else:
            mi = self.conditional_expectation(u)
            vi = mi.dot_product_expectation(mi) - m**2
            v[i, :] = np.ravel(vi)

    return np.reshape(v, np.concatenate(([np.shape(alpha)[0]],
                                         self.shape)), order=&#39;F&#39;)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="tensap.functions.function.Function" href="../../functions/function.html#tensap.functions.function.Function">Function</a></b></code>:
<ul class="hlist">
<li><code><a title="tensap.functions.function.Function.eval" href="../../functions/function.html#tensap.functions.function.Function.eval">eval</a></code></li>
<li><code><a title="tensap.functions.function.Function.eval_on_tensor_grid" href="../../functions/function.html#tensap.functions.function.Function.eval_on_tensor_grid">eval_on_tensor_grid</a></code></li>
<li><code><a title="tensap.functions.function.Function.fplot" href="../../functions/function.html#tensap.functions.function.Function.fplot">fplot</a></code></li>
<li><code><a title="tensap.functions.function.Function.partial_evaluation" href="../../functions/function.html#tensap.functions.function.Function.partial_evaluation">partial_evaluation</a></code></li>
<li><code><a title="tensap.functions.function.Function.store_eval" href="../../functions/function.html#tensap.functions.function.Function.store_eval">store_eval</a></code></li>
<li><code><a title="tensap.functions.function.Function.surf" href="../../functions/function.html#tensap.functions.function.Function.surf">surf</a></code></li>
<li><code><a title="tensap.functions.function.Function.test_error" href="../../functions/function.html#tensap.functions.function.Function.test_error">test_error</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tensap.approximation.bases" href="index.html">tensap.approximation.bases</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray">FunctionalBasisArray</a></code></h4>
<ul class="">
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.conditional_expectation" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.conditional_expectation">conditional_expectation</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.derivative" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.derivative">derivative</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.dot" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.dot">dot</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.dot_product_expectation" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.dot_product_expectation">dot_product_expectation</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.eval_derivative" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.eval_derivative">eval_derivative</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.eval_with_bases_evals" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.eval_with_bases_evals">eval_with_bases_evals</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.expectation" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.expectation">expectation</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.get_coefficients" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.get_coefficients">get_coefficients</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.get_random_vector" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.get_random_vector">get_random_vector</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.is_random" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.is_random">is_random</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.matdiv" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.matdiv">matdiv</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.matmul" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.matmul">matmul</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.mean" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.mean">mean</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.norm" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.norm">norm</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.norm_expectation" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.norm_expectation">norm_expectation</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.projection" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.projection">projection</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.random" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.random">random</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.sparse_storage" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.sparse_storage">sparse_storage</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.std" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.std">std</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.storage" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.storage">storage</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.sub_functional_basis" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.sub_functional_basis">sub_functional_basis</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.variance" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.variance">variance</a></code></li>
<li><code><a title="tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.variance_conditional_expectation" href="#tensap.approximation.bases.functional_basis_array.FunctionalBasisArray.variance_conditional_expectation">variance_conditional_expectation</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>
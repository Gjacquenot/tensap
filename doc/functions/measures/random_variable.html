<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>tensap.functions.measures.random_variable API documentation</title>
<meta name="description" content="Module random_variable â€¦" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tensap.functions.measures.random_variable</code></h1>
</header>
<section id="section-intro">
<p>Module random_variable.</p>
<p>Copyright (c) 2020, Anthony Nouy, Erwan Grelier
This file is part of tensap (tensor approximation package).</p>
<p>tensap is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.</p>
<p>tensap is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
See the
GNU Lesser General Public License for more details.</p>
<p>You should have received a copy of the GNU Lesser General Public License
along with tensap.
If not, see <a href="https://www.gnu.org/licenses/">https://www.gnu.org/licenses/</a>.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;
Module random_variable.

Copyright (c) 2020, Anthony Nouy, Erwan Grelier
This file is part of tensap (tensor approximation package).

tensap is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

tensap is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public License
along with tensap.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

&#39;&#39;&#39;

from copy import deepcopy
import numpy as np
import tensap


class RandomVariable(tensap.ProbabilityMeasure):
    &#39;&#39;&#39;
    Class RandomVariable.

    Attributes
    ----------
    moments : numpy.array
        The moments of the normal random variable (if computed).

    &#39;&#39;&#39;

    def __init__(self):
        &#39;&#39;&#39;
        Constructor of the class RandomVariable.

        The moments attribute remains empty as long as the moments have not
        been computed using the method moment.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        self.moments = np.array([])

    @staticmethod
    def ndim():
        &#39;&#39;&#39;
        Return the dimension of the random variable, equal to 1.

        Returns
        -------
        int
            The dimension of the random variable.

        &#39;&#39;&#39;
        return 1

    def __eq__(self, rv_2):
        if not (isinstance(self, tensap.RandomVariable) and
                isinstance(rv_2, tensap.RandomVariable)):
            is_equal = False
        elif not isinstance(self, type(rv_2)):
            is_equal = False
        else:
            is_equal = True
            param_1 = self.get_parameters()
            param_2 = rv_2.get_parameters()
            for ind in zip(param_1, param_2):
                is_equal = is_equal and (ind[0] == ind[1])
        return is_equal

    def __neq__(self, rv_2):
        return not (self == rv_2)

    def number_of_parameters(self):
        &#39;&#39;&#39;
        Compute the number of parameters that admits the random variable.

        Returns
        -------
        int
            The number of parameters that admits the random variable.

        &#39;&#39;&#39;
        return np.size(self.get_parameters())

    def pdf(self, x):
        &#39;&#39;&#39;
        Compute the probability density function (pdf) of the RandomVariable
        at points x.

        Parameters
        ----------
        x : float or list or numpy.ndarray
            The points at which the pdf is to be evaluated.

        Returns
        -------
        numpy.ndarray
            The evaluations of the pdf at points x.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    def cdf(self, x):
        &#39;&#39;&#39;
        Compute the cumulative distribution function (cdf) of the
        RandomVariable at points x.

        Parameters
        ----------
        x : float or list or numpy.ndarray
            The points at which the cdf is to be evaluated.

        Returns
        -------
        numpy.ndarray
            The evaluations of the cdf at points x.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    def icdf(self, x):
        &#39;&#39;&#39;
        Compute the inverse cumulative distribution function (icdf) of the
        RandomVariable at points x.

        Parameters
        ----------
        x : float or list or numpy.ndarray
            The points at which the icdf is to be evaluated.

        Returns
        -------
        numpy.ndarray
            The evaluations of the icdf at points x.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    def iso_probabilistic_grid(self, n):
        &#39;&#39;&#39;
        Return a set of n+1 points (x_0, ..., x_{n}) such that the n sets
        (x0, x_1), [x_1, x_2) ... [x_{n-1}, x_{n})  have all the same
        probability p = 1/n (with x0 = self.min() and x_{n+1}=self.max()).

        Parameters
        ----------
        n : int
            The number of points of the grid plus one.

        Returns
        -------
        numpy.ndarray
            The iso-probabilistic grid.

        &#39;&#39;&#39;
        if n &lt; 1:
            n = int(np.ceil(1/n))

        if n == 1:
            g = []
        elif n == 2:
            g = [self.icdf(0.5)]
        else:
            g = self.icdf(np.linspace(1/n, 1-1/n, n-1))
        return np.concatenate(([self.min()], g, [self.max()]))

    def discretize(self, n):
        &#39;&#39;&#39;
        Return a discrete random variable taking n possible values x1, ..., xn,
        these values being the quantiles of self of probability 1/(2n) + i/n,
        i=0n ..., n-1 and such that P(Xn &gt;= xn) = 1/n.

        Parameters
        ----------
        n : int
            The number of possible values the discrete random variable can
            take.

        Returns
        -------
        tensap.DiscreteRandomVariable
            The obtained discrete random variable.

        &#39;&#39;&#39;
        u = np.linspace(1/(2*n), 1-1/(2*n), n)
        x = self.icdf(u)
        return tensap.DiscreteRandomVariable(x)

    def gauss_integration_rule(self, nb_pts):
        &#39;&#39;&#39;
        Return the nb_pts-points gauss integration rule associated with the
        measure of self, using Golub-Welsch algorithm.

        Parameters
        ----------
        nb_pts : int
            The number of integration points.

        Returns
        -------
        tensap.IntegrationRule
            The integration rule associated with the measure of self.

        &#39;&#39;&#39;
        poly = self.orthonormal_polynomials(nb_pts+1)
        if isinstance(poly, tensap.ShiftedOrthonormalPolynomials):
            shift = poly.shift
            scaling = poly.scaling
            poly = poly.polynomials
            flag = True
        else:
            flag = False

        coef = poly._recurrence_coefficients
        if coef.shape[1] &lt; nb_pts:
            coef = poly.recurrence(poly.measure, nb_pts-1)
        else:
            coef = coef[:, :nb_pts]

        # Jacobi matrix
        if nb_pts == 1:
            jacobi_matrix = np.diag(coef[0, :])
        else:
            jacobi_matrix = np.diag(coef[0, :]) + \
                np.diag(np.sqrt(coef[1, 1:]), -1) + \
                np.diag(np.sqrt(coef[1, 1:]), 1)

        # Quadrature points are the eigenvalues of the Jacobi matrix, weights
        # are deduced from the eigenvectors
        eig_values, eig_vectors = np.linalg.eig(jacobi_matrix)
        points = np.sort(eig_values)
        ind = np.argsort(eig_values)
        eig_vectors = eig_vectors[:, ind]

        weights = eig_vectors[0, :]**2 / np.sqrt(np.sum(eig_vectors**2, 0))

        if flag:
            points = shift + scaling * points
        return tensap.IntegrationRule(points, weights)

    def lhs_random(self, n, p=1):
        &#39;&#39;&#39;
        Latin Hypercube Sampling of the random variable self of n points in
        dimension p.

        Requires the package pyDOE.

        Parameters
        ----------
        n : int
            Number of points.
        p : int, optional
            The dimension. The default is 1.

        Returns
        -------
        numpy.ndarray
            The coordinates of the Latin Hypercube Sampling in each dimension.

        &#39;&#39;&#39;
        from pyDOE import lhs
        A = lhs(p, samples=n)
        U = tensap.UniformRandomVariable(0, 1)
        A = [U.transfer(self, A[:, i]) for i in range(A.shape[1])]
        return np.transpose(np.array(A))

    def likelihood(self, x):
        &#39;&#39;&#39;
         Compute the log-likelihood of the random variable on sample x.

        Parameters
        ----------
        x : list or numpy.ndarray
            The sample used to compute the log-likelihood.

        Returns
        -------
        float
            The log-likelihood of the random variable on sample x.

        &#39;&#39;&#39;
        P = self.pdf(x)
        return np.sum(np.log(P + np.finfo(float).eps))

    def max(self):
        &#39;&#39;&#39;
        Compute the maximum value that can take the inverse cumulative
        distribution function of the random variable.

        Returns
        -------
        float
            The maximum value that can take the inverse cumulative distribution
            function of the random variable.

        &#39;&#39;&#39;
        return np.max(self.support())

    def min(self):
        &#39;&#39;&#39;
        Compute the minimum value that can take the inverse cumulative
        distribution function of the random variable.

        Returns
        -------
        float
            The minimum value that can take the inverse cumulative distribution
            function of the random variable.

        &#39;&#39;&#39;
        return np.min(self.support())

    def moment(self, ind, nargout=1):
        &#39;&#39;&#39;
        Compute the moments of self of orders contained in ind, defined as
        E(X^ind[Ã®]).
        If a second output argument is asked, the computed moments are stored
        in the random variable X.

        Parameters
        ----------
        ind : list or numpy.ndarray
            The orders of the moments.
        nargout : int, optional
            Indicates the number of expected outputs. The default is 1,
            indicating to return only the moments.

        Returns
        -------
        numpy.ndarray
            The computed moments.
        tensap.RandomVariable
            The RandomVariable object with the computed moments stored in the
            attribute moments.

        &#39;&#39;&#39;
        ind = np.atleast_1d(ind)
        if np.size(self.moments)-1 &gt;= np.max(ind):
            out = self.moments[ind]
        else:
            out = np.zeros(np.size(ind))
            nb_pts = int(np.ceil((np.max(ind)+1)/2))
            G = self.gauss_integration_rule(nb_pts)
            for nb, ind_loc in enumerate(ind):
                out[nb] = G.integrate(lambda x: x ** ind_loc)

        if nargout == 1:
            return out
        X = deepcopy(self)
        X.moments = out
        return out, X

    def mean(self):
        &#39;&#39;&#39;
        Return the mean of the random variable.

        Returns
        -------
        float
            The mean of the random variable.

        &#39;&#39;&#39;
        return self.random_variable_statistics()[0]

    def std(self):
        &#39;&#39;&#39;
        Return the standard deviation of the random variable.

        Returns
        -------
        float
            The standard deviation of the random variable.

        &#39;&#39;&#39;
        return np.sqrt(self.random_variable_statistics()[1])

    def variance(self):
        &#39;&#39;&#39;
        Return the variance of the random variable.

        Returns
        -------
        float
            The variance of the random variable.

        &#39;&#39;&#39;
        return self.random_variable_statistics()[1]

    def transfer(self, Y, x):
        &#39;&#39;&#39;
        Transfer from the random variable self to the random variable Y at
        points x.

        Parameters
        ----------
        Y : tensap.RandomVariable
            The target RandomVariable of the transfer.
        x : list or numpy.ndarray
            The input points.

        Returns
        -------
        y : numpy.ndarray
            The transfered points.

        &#39;&#39;&#39;
        assert isinstance(self, tensap.RandomVariable) and \
            isinstance(Y, tensap.RandomVariable), \
            &#39;The first two arguments must be RandomVariable.&#39;
        return Y.icdf(self.cdf(x))

    def truncated_support(self):
        &#39;&#39;&#39;
        Return the truncated support of the random variable.

        Returns
        -------
        sup : numpy.ndarray
            The truncated support of the random variable.

        &#39;&#39;&#39;

        sup = self.support()
        if sup[0] == -np.inf:
            sup[0] = self.mean() - 10*self.std()
        if sup[1] == np.inf:
            sup[1] = self.mean() + 10*self.std()
        return sup

    def pdf_plot(self, *args):
        &#39;&#39;&#39;
        Plot the probability density function (pdf) of the random variable.

        See also plot.

        Parameters
        ----------
        *args : tuple
            Additional parameters of the method plot.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        self.plot(&#39;pdf&#39;, *args)

    def cdf_plot(self, *args):
        &#39;&#39;&#39;
        Plot the cumulative distribution function (cdf) of the random variable.

        See also plot.

        Parameters
        ----------
        *args : tuple
            Additional parameters of the method plot.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        self.plot(&#39;cdf&#39;, *args)

    def icdf_plot(self, *args):
        &#39;&#39;&#39;
        Plot the inverse cumulative distribution function (icdf) of the random
        variable.

        See also plot.

        Parameters
        ----------
        *args : tuple
            Additional parameters of the method plot.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        self.plot(&#39;icdf&#39;, *args)

    def plot(self, quantity, n_pts=100, bar=False, *args):
        &#39;&#39;&#39;
        Plot the desired quantity, chosen between &#39;pdf&#39;, &#39;cdf&#39; or &#39;icdf&#39;.

        Parameters
        ----------
        quantity : str
            The desired quantity, chosen between &#39;pdf&#39;, &#39;cdf&#39; or &#39;icdf&#39;.
        n_pts : int, optional
            The number of points used for the plot. The default is 100.
        bar : boolean, optional
            Determines if the method uses matplotlib.pyplot&#39;s function bar
            or plot. The default is False.
        *args : tuple
            Additional parameters for matplotlib.pyplot&#39;s function plot or bar.

        Raises
        ------
        ValueError
            If the provided argument quantity is wrong.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        import matplotlib.pyplot as plt

        sup = self.truncated_support()
        if quantity == &#39;cdf&#39;:
            x = np.linspace(sup[0], sup[1], n_pts)
            P = self.cdf(x)
        elif quantity == &#39;icdf&#39;:
            x = np.linspace(0, 1, n_pts)
            P = self.icdf(x)
        elif quantity == &#39;pdf&#39;:
            x = np.linspace(sup[0], sup[1], n_pts)
            P = self.pdf(x)
        else:
            raise ValueError(&#39;Wrong argument value&#39;)

        if bar:
            plt.bar(x, P, *args)
        else:
            plt.plot(x, P, *args)
        plt.show()

    def get_parameters(self):
        &#39;&#39;&#39;
        Return the parameters of the random variable.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    def random_variable_statistics(self):
        &#39;&#39;&#39;
        Return the mean and the variance of the random variable.

        Returns
        -------
        float
            The mean of the random variable.
        float
            The variance of the random variable.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    def random(self, n):
        &#39;&#39;&#39;
        Generate n random numbers according to the distribution of the
        RandomVariable.

        Parameters
        ----------
        n : int
            The number of random numbers generated.

        Returns
        -------
        numpy.ndarray
            The generated numbers.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    def orthonormal_polynomials(self, *max_degree):
        &#39;&#39;&#39;
        Return the max_degree-1 first orthonormal polynomials associated with
        the RandomVariable.

        Parameters
        ----------
        max_degree : int, optional
            The maximum degree of the returned polynomials. The default is
            None, choosing the default maximum degree associated with the
            constructor of the polynomials.

        Returns
        -------
        poly : tensap.OrthonormalPolynomials
            The generated orthonormal polynomials.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tensap.functions.measures.random_variable.RandomVariable"><code class="flex name class">
<span>class <span class="ident">RandomVariable</span></span>
</code></dt>
<dd>
<div class="desc"><p>Class RandomVariable.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>moments</code></strong> :&ensp;<code>numpy.array</code></dt>
<dd>The moments of the normal random variable (if computed).</dd>
</dl>
<p>Constructor of the class RandomVariable.</p>
<p>The moments attribute remains empty as long as the moments have not
been computed using the method moment.</p>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RandomVariable(tensap.ProbabilityMeasure):
    &#39;&#39;&#39;
    Class RandomVariable.

    Attributes
    ----------
    moments : numpy.array
        The moments of the normal random variable (if computed).

    &#39;&#39;&#39;

    def __init__(self):
        &#39;&#39;&#39;
        Constructor of the class RandomVariable.

        The moments attribute remains empty as long as the moments have not
        been computed using the method moment.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        self.moments = np.array([])

    @staticmethod
    def ndim():
        &#39;&#39;&#39;
        Return the dimension of the random variable, equal to 1.

        Returns
        -------
        int
            The dimension of the random variable.

        &#39;&#39;&#39;
        return 1

    def __eq__(self, rv_2):
        if not (isinstance(self, tensap.RandomVariable) and
                isinstance(rv_2, tensap.RandomVariable)):
            is_equal = False
        elif not isinstance(self, type(rv_2)):
            is_equal = False
        else:
            is_equal = True
            param_1 = self.get_parameters()
            param_2 = rv_2.get_parameters()
            for ind in zip(param_1, param_2):
                is_equal = is_equal and (ind[0] == ind[1])
        return is_equal

    def __neq__(self, rv_2):
        return not (self == rv_2)

    def number_of_parameters(self):
        &#39;&#39;&#39;
        Compute the number of parameters that admits the random variable.

        Returns
        -------
        int
            The number of parameters that admits the random variable.

        &#39;&#39;&#39;
        return np.size(self.get_parameters())

    def pdf(self, x):
        &#39;&#39;&#39;
        Compute the probability density function (pdf) of the RandomVariable
        at points x.

        Parameters
        ----------
        x : float or list or numpy.ndarray
            The points at which the pdf is to be evaluated.

        Returns
        -------
        numpy.ndarray
            The evaluations of the pdf at points x.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    def cdf(self, x):
        &#39;&#39;&#39;
        Compute the cumulative distribution function (cdf) of the
        RandomVariable at points x.

        Parameters
        ----------
        x : float or list or numpy.ndarray
            The points at which the cdf is to be evaluated.

        Returns
        -------
        numpy.ndarray
            The evaluations of the cdf at points x.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    def icdf(self, x):
        &#39;&#39;&#39;
        Compute the inverse cumulative distribution function (icdf) of the
        RandomVariable at points x.

        Parameters
        ----------
        x : float or list or numpy.ndarray
            The points at which the icdf is to be evaluated.

        Returns
        -------
        numpy.ndarray
            The evaluations of the icdf at points x.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    def iso_probabilistic_grid(self, n):
        &#39;&#39;&#39;
        Return a set of n+1 points (x_0, ..., x_{n}) such that the n sets
        (x0, x_1), [x_1, x_2) ... [x_{n-1}, x_{n})  have all the same
        probability p = 1/n (with x0 = self.min() and x_{n+1}=self.max()).

        Parameters
        ----------
        n : int
            The number of points of the grid plus one.

        Returns
        -------
        numpy.ndarray
            The iso-probabilistic grid.

        &#39;&#39;&#39;
        if n &lt; 1:
            n = int(np.ceil(1/n))

        if n == 1:
            g = []
        elif n == 2:
            g = [self.icdf(0.5)]
        else:
            g = self.icdf(np.linspace(1/n, 1-1/n, n-1))
        return np.concatenate(([self.min()], g, [self.max()]))

    def discretize(self, n):
        &#39;&#39;&#39;
        Return a discrete random variable taking n possible values x1, ..., xn,
        these values being the quantiles of self of probability 1/(2n) + i/n,
        i=0n ..., n-1 and such that P(Xn &gt;= xn) = 1/n.

        Parameters
        ----------
        n : int
            The number of possible values the discrete random variable can
            take.

        Returns
        -------
        tensap.DiscreteRandomVariable
            The obtained discrete random variable.

        &#39;&#39;&#39;
        u = np.linspace(1/(2*n), 1-1/(2*n), n)
        x = self.icdf(u)
        return tensap.DiscreteRandomVariable(x)

    def gauss_integration_rule(self, nb_pts):
        &#39;&#39;&#39;
        Return the nb_pts-points gauss integration rule associated with the
        measure of self, using Golub-Welsch algorithm.

        Parameters
        ----------
        nb_pts : int
            The number of integration points.

        Returns
        -------
        tensap.IntegrationRule
            The integration rule associated with the measure of self.

        &#39;&#39;&#39;
        poly = self.orthonormal_polynomials(nb_pts+1)
        if isinstance(poly, tensap.ShiftedOrthonormalPolynomials):
            shift = poly.shift
            scaling = poly.scaling
            poly = poly.polynomials
            flag = True
        else:
            flag = False

        coef = poly._recurrence_coefficients
        if coef.shape[1] &lt; nb_pts:
            coef = poly.recurrence(poly.measure, nb_pts-1)
        else:
            coef = coef[:, :nb_pts]

        # Jacobi matrix
        if nb_pts == 1:
            jacobi_matrix = np.diag(coef[0, :])
        else:
            jacobi_matrix = np.diag(coef[0, :]) + \
                np.diag(np.sqrt(coef[1, 1:]), -1) + \
                np.diag(np.sqrt(coef[1, 1:]), 1)

        # Quadrature points are the eigenvalues of the Jacobi matrix, weights
        # are deduced from the eigenvectors
        eig_values, eig_vectors = np.linalg.eig(jacobi_matrix)
        points = np.sort(eig_values)
        ind = np.argsort(eig_values)
        eig_vectors = eig_vectors[:, ind]

        weights = eig_vectors[0, :]**2 / np.sqrt(np.sum(eig_vectors**2, 0))

        if flag:
            points = shift + scaling * points
        return tensap.IntegrationRule(points, weights)

    def lhs_random(self, n, p=1):
        &#39;&#39;&#39;
        Latin Hypercube Sampling of the random variable self of n points in
        dimension p.

        Requires the package pyDOE.

        Parameters
        ----------
        n : int
            Number of points.
        p : int, optional
            The dimension. The default is 1.

        Returns
        -------
        numpy.ndarray
            The coordinates of the Latin Hypercube Sampling in each dimension.

        &#39;&#39;&#39;
        from pyDOE import lhs
        A = lhs(p, samples=n)
        U = tensap.UniformRandomVariable(0, 1)
        A = [U.transfer(self, A[:, i]) for i in range(A.shape[1])]
        return np.transpose(np.array(A))

    def likelihood(self, x):
        &#39;&#39;&#39;
         Compute the log-likelihood of the random variable on sample x.

        Parameters
        ----------
        x : list or numpy.ndarray
            The sample used to compute the log-likelihood.

        Returns
        -------
        float
            The log-likelihood of the random variable on sample x.

        &#39;&#39;&#39;
        P = self.pdf(x)
        return np.sum(np.log(P + np.finfo(float).eps))

    def max(self):
        &#39;&#39;&#39;
        Compute the maximum value that can take the inverse cumulative
        distribution function of the random variable.

        Returns
        -------
        float
            The maximum value that can take the inverse cumulative distribution
            function of the random variable.

        &#39;&#39;&#39;
        return np.max(self.support())

    def min(self):
        &#39;&#39;&#39;
        Compute the minimum value that can take the inverse cumulative
        distribution function of the random variable.

        Returns
        -------
        float
            The minimum value that can take the inverse cumulative distribution
            function of the random variable.

        &#39;&#39;&#39;
        return np.min(self.support())

    def moment(self, ind, nargout=1):
        &#39;&#39;&#39;
        Compute the moments of self of orders contained in ind, defined as
        E(X^ind[Ã®]).
        If a second output argument is asked, the computed moments are stored
        in the random variable X.

        Parameters
        ----------
        ind : list or numpy.ndarray
            The orders of the moments.
        nargout : int, optional
            Indicates the number of expected outputs. The default is 1,
            indicating to return only the moments.

        Returns
        -------
        numpy.ndarray
            The computed moments.
        tensap.RandomVariable
            The RandomVariable object with the computed moments stored in the
            attribute moments.

        &#39;&#39;&#39;
        ind = np.atleast_1d(ind)
        if np.size(self.moments)-1 &gt;= np.max(ind):
            out = self.moments[ind]
        else:
            out = np.zeros(np.size(ind))
            nb_pts = int(np.ceil((np.max(ind)+1)/2))
            G = self.gauss_integration_rule(nb_pts)
            for nb, ind_loc in enumerate(ind):
                out[nb] = G.integrate(lambda x: x ** ind_loc)

        if nargout == 1:
            return out
        X = deepcopy(self)
        X.moments = out
        return out, X

    def mean(self):
        &#39;&#39;&#39;
        Return the mean of the random variable.

        Returns
        -------
        float
            The mean of the random variable.

        &#39;&#39;&#39;
        return self.random_variable_statistics()[0]

    def std(self):
        &#39;&#39;&#39;
        Return the standard deviation of the random variable.

        Returns
        -------
        float
            The standard deviation of the random variable.

        &#39;&#39;&#39;
        return np.sqrt(self.random_variable_statistics()[1])

    def variance(self):
        &#39;&#39;&#39;
        Return the variance of the random variable.

        Returns
        -------
        float
            The variance of the random variable.

        &#39;&#39;&#39;
        return self.random_variable_statistics()[1]

    def transfer(self, Y, x):
        &#39;&#39;&#39;
        Transfer from the random variable self to the random variable Y at
        points x.

        Parameters
        ----------
        Y : tensap.RandomVariable
            The target RandomVariable of the transfer.
        x : list or numpy.ndarray
            The input points.

        Returns
        -------
        y : numpy.ndarray
            The transfered points.

        &#39;&#39;&#39;
        assert isinstance(self, tensap.RandomVariable) and \
            isinstance(Y, tensap.RandomVariable), \
            &#39;The first two arguments must be RandomVariable.&#39;
        return Y.icdf(self.cdf(x))

    def truncated_support(self):
        &#39;&#39;&#39;
        Return the truncated support of the random variable.

        Returns
        -------
        sup : numpy.ndarray
            The truncated support of the random variable.

        &#39;&#39;&#39;

        sup = self.support()
        if sup[0] == -np.inf:
            sup[0] = self.mean() - 10*self.std()
        if sup[1] == np.inf:
            sup[1] = self.mean() + 10*self.std()
        return sup

    def pdf_plot(self, *args):
        &#39;&#39;&#39;
        Plot the probability density function (pdf) of the random variable.

        See also plot.

        Parameters
        ----------
        *args : tuple
            Additional parameters of the method plot.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        self.plot(&#39;pdf&#39;, *args)

    def cdf_plot(self, *args):
        &#39;&#39;&#39;
        Plot the cumulative distribution function (cdf) of the random variable.

        See also plot.

        Parameters
        ----------
        *args : tuple
            Additional parameters of the method plot.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        self.plot(&#39;cdf&#39;, *args)

    def icdf_plot(self, *args):
        &#39;&#39;&#39;
        Plot the inverse cumulative distribution function (icdf) of the random
        variable.

        See also plot.

        Parameters
        ----------
        *args : tuple
            Additional parameters of the method plot.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        self.plot(&#39;icdf&#39;, *args)

    def plot(self, quantity, n_pts=100, bar=False, *args):
        &#39;&#39;&#39;
        Plot the desired quantity, chosen between &#39;pdf&#39;, &#39;cdf&#39; or &#39;icdf&#39;.

        Parameters
        ----------
        quantity : str
            The desired quantity, chosen between &#39;pdf&#39;, &#39;cdf&#39; or &#39;icdf&#39;.
        n_pts : int, optional
            The number of points used for the plot. The default is 100.
        bar : boolean, optional
            Determines if the method uses matplotlib.pyplot&#39;s function bar
            or plot. The default is False.
        *args : tuple
            Additional parameters for matplotlib.pyplot&#39;s function plot or bar.

        Raises
        ------
        ValueError
            If the provided argument quantity is wrong.

        Returns
        -------
        None.

        &#39;&#39;&#39;
        import matplotlib.pyplot as plt

        sup = self.truncated_support()
        if quantity == &#39;cdf&#39;:
            x = np.linspace(sup[0], sup[1], n_pts)
            P = self.cdf(x)
        elif quantity == &#39;icdf&#39;:
            x = np.linspace(0, 1, n_pts)
            P = self.icdf(x)
        elif quantity == &#39;pdf&#39;:
            x = np.linspace(sup[0], sup[1], n_pts)
            P = self.pdf(x)
        else:
            raise ValueError(&#39;Wrong argument value&#39;)

        if bar:
            plt.bar(x, P, *args)
        else:
            plt.plot(x, P, *args)
        plt.show()

    def get_parameters(self):
        &#39;&#39;&#39;
        Return the parameters of the random variable.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    def random_variable_statistics(self):
        &#39;&#39;&#39;
        Return the mean and the variance of the random variable.

        Returns
        -------
        float
            The mean of the random variable.
        float
            The variance of the random variable.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    def random(self, n):
        &#39;&#39;&#39;
        Generate n random numbers according to the distribution of the
        RandomVariable.

        Parameters
        ----------
        n : int
            The number of random numbers generated.

        Returns
        -------
        numpy.ndarray
            The generated numbers.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)

    def orthonormal_polynomials(self, *max_degree):
        &#39;&#39;&#39;
        Return the max_degree-1 first orthonormal polynomials associated with
        the RandomVariable.

        Parameters
        ----------
        max_degree : int, optional
            The maximum degree of the returned polynomials. The default is
            None, choosing the default maximum degree associated with the
            constructor of the polynomials.

        Returns
        -------
        poly : tensap.OrthonormalPolynomials
            The generated orthonormal polynomials.

        &#39;&#39;&#39;
        raise NotImplementedError(&#39;No generic implementation of the method.&#39;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="tensap.functions.measures.probability_measure.ProbabilityMeasure" href="probability_measure.html#tensap.functions.measures.probability_measure.ProbabilityMeasure">ProbabilityMeasure</a></li>
<li><a title="tensap.functions.measures.measure.Measure" href="measure.html#tensap.functions.measures.measure.Measure">Measure</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="tensap.functions.measures.discrete_random_variable.DiscreteRandomVariable" href="discrete_random_variable.html#tensap.functions.measures.discrete_random_variable.DiscreteRandomVariable">DiscreteRandomVariable</a></li>
<li><a title="tensap.functions.measures.empirical_random_variable.EmpiricalRandomVariable" href="empirical_random_variable.html#tensap.functions.measures.empirical_random_variable.EmpiricalRandomVariable">EmpiricalRandomVariable</a></li>
<li><a title="tensap.functions.measures.normal_random_variable.NormalRandomVariable" href="normal_random_variable.html#tensap.functions.measures.normal_random_variable.NormalRandomVariable">NormalRandomVariable</a></li>
<li><a title="tensap.functions.measures.uniform_random_variable.UniformRandomVariable" href="uniform_random_variable.html#tensap.functions.measures.uniform_random_variable.UniformRandomVariable">UniformRandomVariable</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="tensap.functions.measures.random_variable.RandomVariable.ndim"><code class="name flex">
<span>def <span class="ident">ndim</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the dimension of the random variable, equal to 1.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The dimension of the random variable.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def ndim():
    &#39;&#39;&#39;
    Return the dimension of the random variable, equal to 1.

    Returns
    -------
    int
        The dimension of the random variable.

    &#39;&#39;&#39;
    return 1</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tensap.functions.measures.random_variable.RandomVariable.cdf"><code class="name flex">
<span>def <span class="ident">cdf</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the cumulative distribution function (cdf) of the
RandomVariable at points x.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>float</code> or <code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The points at which the cdf is to be evaluated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The evaluations of the cdf at points x.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cdf(self, x):
    &#39;&#39;&#39;
    Compute the cumulative distribution function (cdf) of the
    RandomVariable at points x.

    Parameters
    ----------
    x : float or list or numpy.ndarray
        The points at which the cdf is to be evaluated.

    Returns
    -------
    numpy.ndarray
        The evaluations of the cdf at points x.

    &#39;&#39;&#39;
    raise NotImplementedError(&#39;No generic implementation of the method.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.cdf_plot"><code class="name flex">
<span>def <span class="ident">cdf_plot</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the cumulative distribution function (cdf) of the random variable.</p>
<p>See also plot.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>*args</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Additional parameters of the method plot.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cdf_plot(self, *args):
    &#39;&#39;&#39;
    Plot the cumulative distribution function (cdf) of the random variable.

    See also plot.

    Parameters
    ----------
    *args : tuple
        Additional parameters of the method plot.

    Returns
    -------
    None.

    &#39;&#39;&#39;
    self.plot(&#39;cdf&#39;, *args)</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.discretize"><code class="name flex">
<span>def <span class="ident">discretize</span></span>(<span>self, n)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a discrete random variable taking n possible values x1, &hellip;, xn,
these values being the quantiles of self of probability 1/(2n) + i/n,
i=0n &hellip;, n-1 and such that P(Xn &gt;= xn) = 1/n.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of possible values the discrete random variable can
take.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensap.DiscreteRandomVariable</code></dt>
<dd>The obtained discrete random variable.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def discretize(self, n):
    &#39;&#39;&#39;
    Return a discrete random variable taking n possible values x1, ..., xn,
    these values being the quantiles of self of probability 1/(2n) + i/n,
    i=0n ..., n-1 and such that P(Xn &gt;= xn) = 1/n.

    Parameters
    ----------
    n : int
        The number of possible values the discrete random variable can
        take.

    Returns
    -------
    tensap.DiscreteRandomVariable
        The obtained discrete random variable.

    &#39;&#39;&#39;
    u = np.linspace(1/(2*n), 1-1/(2*n), n)
    x = self.icdf(u)
    return tensap.DiscreteRandomVariable(x)</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.gauss_integration_rule"><code class="name flex">
<span>def <span class="ident">gauss_integration_rule</span></span>(<span>self, nb_pts)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the nb_pts-points gauss integration rule associated with the
measure of self, using Golub-Welsch algorithm.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>nb_pts</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of integration points.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensap.IntegrationRule</code></dt>
<dd>The integration rule associated with the measure of self.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gauss_integration_rule(self, nb_pts):
    &#39;&#39;&#39;
    Return the nb_pts-points gauss integration rule associated with the
    measure of self, using Golub-Welsch algorithm.

    Parameters
    ----------
    nb_pts : int
        The number of integration points.

    Returns
    -------
    tensap.IntegrationRule
        The integration rule associated with the measure of self.

    &#39;&#39;&#39;
    poly = self.orthonormal_polynomials(nb_pts+1)
    if isinstance(poly, tensap.ShiftedOrthonormalPolynomials):
        shift = poly.shift
        scaling = poly.scaling
        poly = poly.polynomials
        flag = True
    else:
        flag = False

    coef = poly._recurrence_coefficients
    if coef.shape[1] &lt; nb_pts:
        coef = poly.recurrence(poly.measure, nb_pts-1)
    else:
        coef = coef[:, :nb_pts]

    # Jacobi matrix
    if nb_pts == 1:
        jacobi_matrix = np.diag(coef[0, :])
    else:
        jacobi_matrix = np.diag(coef[0, :]) + \
            np.diag(np.sqrt(coef[1, 1:]), -1) + \
            np.diag(np.sqrt(coef[1, 1:]), 1)

    # Quadrature points are the eigenvalues of the Jacobi matrix, weights
    # are deduced from the eigenvectors
    eig_values, eig_vectors = np.linalg.eig(jacobi_matrix)
    points = np.sort(eig_values)
    ind = np.argsort(eig_values)
    eig_vectors = eig_vectors[:, ind]

    weights = eig_vectors[0, :]**2 / np.sqrt(np.sum(eig_vectors**2, 0))

    if flag:
        points = shift + scaling * points
    return tensap.IntegrationRule(points, weights)</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.get_parameters"><code class="name flex">
<span>def <span class="ident">get_parameters</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the parameters of the random variable.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_parameters(self):
    &#39;&#39;&#39;
    Return the parameters of the random variable.

    &#39;&#39;&#39;
    raise NotImplementedError(&#39;No generic implementation of the method.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.icdf"><code class="name flex">
<span>def <span class="ident">icdf</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the inverse cumulative distribution function (icdf) of the
RandomVariable at points x.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>float</code> or <code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The points at which the icdf is to be evaluated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The evaluations of the icdf at points x.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def icdf(self, x):
    &#39;&#39;&#39;
    Compute the inverse cumulative distribution function (icdf) of the
    RandomVariable at points x.

    Parameters
    ----------
    x : float or list or numpy.ndarray
        The points at which the icdf is to be evaluated.

    Returns
    -------
    numpy.ndarray
        The evaluations of the icdf at points x.

    &#39;&#39;&#39;
    raise NotImplementedError(&#39;No generic implementation of the method.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.icdf_plot"><code class="name flex">
<span>def <span class="ident">icdf_plot</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the inverse cumulative distribution function (icdf) of the random
variable.</p>
<p>See also plot.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>*args</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Additional parameters of the method plot.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def icdf_plot(self, *args):
    &#39;&#39;&#39;
    Plot the inverse cumulative distribution function (icdf) of the random
    variable.

    See also plot.

    Parameters
    ----------
    *args : tuple
        Additional parameters of the method plot.

    Returns
    -------
    None.

    &#39;&#39;&#39;
    self.plot(&#39;icdf&#39;, *args)</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.iso_probabilistic_grid"><code class="name flex">
<span>def <span class="ident">iso_probabilistic_grid</span></span>(<span>self, n)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a set of n+1 points (x_0, &hellip;, x_{n}) such that the n sets
(x0, x_1), [x_1, x_2) &hellip; [x_{n-1}, x_{n})
have all the same
probability p = 1/n (with x0 = self.min() and x_{n+1}=self.max()).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of points of the grid plus one.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The iso-probabilistic grid.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def iso_probabilistic_grid(self, n):
    &#39;&#39;&#39;
    Return a set of n+1 points (x_0, ..., x_{n}) such that the n sets
    (x0, x_1), [x_1, x_2) ... [x_{n-1}, x_{n})  have all the same
    probability p = 1/n (with x0 = self.min() and x_{n+1}=self.max()).

    Parameters
    ----------
    n : int
        The number of points of the grid plus one.

    Returns
    -------
    numpy.ndarray
        The iso-probabilistic grid.

    &#39;&#39;&#39;
    if n &lt; 1:
        n = int(np.ceil(1/n))

    if n == 1:
        g = []
    elif n == 2:
        g = [self.icdf(0.5)]
    else:
        g = self.icdf(np.linspace(1/n, 1-1/n, n-1))
    return np.concatenate(([self.min()], g, [self.max()]))</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.lhs_random"><code class="name flex">
<span>def <span class="ident">lhs_random</span></span>(<span>self, n, p=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Latin Hypercube Sampling of the random variable self of n points in
dimension p.</p>
<p>Requires the package pyDOE.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of points.</dd>
<dt><strong><code>p</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The dimension. The default is 1.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The coordinates of the Latin Hypercube Sampling in each dimension.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lhs_random(self, n, p=1):
    &#39;&#39;&#39;
    Latin Hypercube Sampling of the random variable self of n points in
    dimension p.

    Requires the package pyDOE.

    Parameters
    ----------
    n : int
        Number of points.
    p : int, optional
        The dimension. The default is 1.

    Returns
    -------
    numpy.ndarray
        The coordinates of the Latin Hypercube Sampling in each dimension.

    &#39;&#39;&#39;
    from pyDOE import lhs
    A = lhs(p, samples=n)
    U = tensap.UniformRandomVariable(0, 1)
    A = [U.transfer(self, A[:, i]) for i in range(A.shape[1])]
    return np.transpose(np.array(A))</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.likelihood"><code class="name flex">
<span>def <span class="ident">likelihood</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the log-likelihood of the random variable on sample x.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The sample used to compute the log-likelihood.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>The log-likelihood of the random variable on sample x.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def likelihood(self, x):
    &#39;&#39;&#39;
     Compute the log-likelihood of the random variable on sample x.

    Parameters
    ----------
    x : list or numpy.ndarray
        The sample used to compute the log-likelihood.

    Returns
    -------
    float
        The log-likelihood of the random variable on sample x.

    &#39;&#39;&#39;
    P = self.pdf(x)
    return np.sum(np.log(P + np.finfo(float).eps))</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.max"><code class="name flex">
<span>def <span class="ident">max</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the maximum value that can take the inverse cumulative
distribution function of the random variable.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>The maximum value that can take the inverse cumulative distribution
function of the random variable.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def max(self):
    &#39;&#39;&#39;
    Compute the maximum value that can take the inverse cumulative
    distribution function of the random variable.

    Returns
    -------
    float
        The maximum value that can take the inverse cumulative distribution
        function of the random variable.

    &#39;&#39;&#39;
    return np.max(self.support())</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.mean"><code class="name flex">
<span>def <span class="ident">mean</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the mean of the random variable.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>The mean of the random variable.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean(self):
    &#39;&#39;&#39;
    Return the mean of the random variable.

    Returns
    -------
    float
        The mean of the random variable.

    &#39;&#39;&#39;
    return self.random_variable_statistics()[0]</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.min"><code class="name flex">
<span>def <span class="ident">min</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the minimum value that can take the inverse cumulative
distribution function of the random variable.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>The minimum value that can take the inverse cumulative distribution
function of the random variable.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def min(self):
    &#39;&#39;&#39;
    Compute the minimum value that can take the inverse cumulative
    distribution function of the random variable.

    Returns
    -------
    float
        The minimum value that can take the inverse cumulative distribution
        function of the random variable.

    &#39;&#39;&#39;
    return np.min(self.support())</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.moment"><code class="name flex">
<span>def <span class="ident">moment</span></span>(<span>self, ind, nargout=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the moments of self of orders contained in ind, defined as
E(X^ind[Ã®]).
If a second output argument is asked, the computed moments are stored
in the random variable X.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ind</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The orders of the moments.</dd>
<dt><strong><code>nargout</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Indicates the number of expected outputs. The default is 1,
indicating to return only the moments.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The computed moments.</dd>
<dt><code>tensap.RandomVariable</code></dt>
<dd>The RandomVariable object with the computed moments stored in the
attribute moments.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def moment(self, ind, nargout=1):
    &#39;&#39;&#39;
    Compute the moments of self of orders contained in ind, defined as
    E(X^ind[Ã®]).
    If a second output argument is asked, the computed moments are stored
    in the random variable X.

    Parameters
    ----------
    ind : list or numpy.ndarray
        The orders of the moments.
    nargout : int, optional
        Indicates the number of expected outputs. The default is 1,
        indicating to return only the moments.

    Returns
    -------
    numpy.ndarray
        The computed moments.
    tensap.RandomVariable
        The RandomVariable object with the computed moments stored in the
        attribute moments.

    &#39;&#39;&#39;
    ind = np.atleast_1d(ind)
    if np.size(self.moments)-1 &gt;= np.max(ind):
        out = self.moments[ind]
    else:
        out = np.zeros(np.size(ind))
        nb_pts = int(np.ceil((np.max(ind)+1)/2))
        G = self.gauss_integration_rule(nb_pts)
        for nb, ind_loc in enumerate(ind):
            out[nb] = G.integrate(lambda x: x ** ind_loc)

    if nargout == 1:
        return out
    X = deepcopy(self)
    X.moments = out
    return out, X</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.number_of_parameters"><code class="name flex">
<span>def <span class="ident">number_of_parameters</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the number of parameters that admits the random variable.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The number of parameters that admits the random variable.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def number_of_parameters(self):
    &#39;&#39;&#39;
    Compute the number of parameters that admits the random variable.

    Returns
    -------
    int
        The number of parameters that admits the random variable.

    &#39;&#39;&#39;
    return np.size(self.get_parameters())</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.orthonormal_polynomials"><code class="name flex">
<span>def <span class="ident">orthonormal_polynomials</span></span>(<span>self, *max_degree)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the max_degree-1 first orthonormal polynomials associated with
the RandomVariable.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>max_degree</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The maximum degree of the returned polynomials. The default is
None, choosing the default maximum degree associated with the
constructor of the polynomials.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>poly</code></strong> :&ensp;<code>tensap.OrthonormalPolynomials</code></dt>
<dd>The generated orthonormal polynomials.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def orthonormal_polynomials(self, *max_degree):
    &#39;&#39;&#39;
    Return the max_degree-1 first orthonormal polynomials associated with
    the RandomVariable.

    Parameters
    ----------
    max_degree : int, optional
        The maximum degree of the returned polynomials. The default is
        None, choosing the default maximum degree associated with the
        constructor of the polynomials.

    Returns
    -------
    poly : tensap.OrthonormalPolynomials
        The generated orthonormal polynomials.

    &#39;&#39;&#39;
    raise NotImplementedError(&#39;No generic implementation of the method.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.pdf"><code class="name flex">
<span>def <span class="ident">pdf</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the probability density function (pdf) of the RandomVariable
at points x.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>float</code> or <code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The points at which the pdf is to be evaluated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The evaluations of the pdf at points x.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pdf(self, x):
    &#39;&#39;&#39;
    Compute the probability density function (pdf) of the RandomVariable
    at points x.

    Parameters
    ----------
    x : float or list or numpy.ndarray
        The points at which the pdf is to be evaluated.

    Returns
    -------
    numpy.ndarray
        The evaluations of the pdf at points x.

    &#39;&#39;&#39;
    raise NotImplementedError(&#39;No generic implementation of the method.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.pdf_plot"><code class="name flex">
<span>def <span class="ident">pdf_plot</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the probability density function (pdf) of the random variable.</p>
<p>See also plot.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>*args</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Additional parameters of the method plot.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pdf_plot(self, *args):
    &#39;&#39;&#39;
    Plot the probability density function (pdf) of the random variable.

    See also plot.

    Parameters
    ----------
    *args : tuple
        Additional parameters of the method plot.

    Returns
    -------
    None.

    &#39;&#39;&#39;
    self.plot(&#39;pdf&#39;, *args)</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, quantity, n_pts=100, bar=False, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the desired quantity, chosen between 'pdf', 'cdf' or 'icdf'.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>quantity</code></strong> :&ensp;<code>str</code></dt>
<dd>The desired quantity, chosen between 'pdf', 'cdf' or 'icdf'.</dd>
<dt><strong><code>n_pts</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of points used for the plot. The default is 100.</dd>
<dt><strong><code>bar</code></strong> :&ensp;<code>boolean</code>, optional</dt>
<dd>Determines if the method uses matplotlib.pyplot's function bar
or plot. The default is False.</dd>
<dt><strong><code>*args</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Additional parameters for matplotlib.pyplot's function plot or bar.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the provided argument quantity is wrong.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self, quantity, n_pts=100, bar=False, *args):
    &#39;&#39;&#39;
    Plot the desired quantity, chosen between &#39;pdf&#39;, &#39;cdf&#39; or &#39;icdf&#39;.

    Parameters
    ----------
    quantity : str
        The desired quantity, chosen between &#39;pdf&#39;, &#39;cdf&#39; or &#39;icdf&#39;.
    n_pts : int, optional
        The number of points used for the plot. The default is 100.
    bar : boolean, optional
        Determines if the method uses matplotlib.pyplot&#39;s function bar
        or plot. The default is False.
    *args : tuple
        Additional parameters for matplotlib.pyplot&#39;s function plot or bar.

    Raises
    ------
    ValueError
        If the provided argument quantity is wrong.

    Returns
    -------
    None.

    &#39;&#39;&#39;
    import matplotlib.pyplot as plt

    sup = self.truncated_support()
    if quantity == &#39;cdf&#39;:
        x = np.linspace(sup[0], sup[1], n_pts)
        P = self.cdf(x)
    elif quantity == &#39;icdf&#39;:
        x = np.linspace(0, 1, n_pts)
        P = self.icdf(x)
    elif quantity == &#39;pdf&#39;:
        x = np.linspace(sup[0], sup[1], n_pts)
        P = self.pdf(x)
    else:
        raise ValueError(&#39;Wrong argument value&#39;)

    if bar:
        plt.bar(x, P, *args)
    else:
        plt.plot(x, P, *args)
    plt.show()</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.random"><code class="name flex">
<span>def <span class="ident">random</span></span>(<span>self, n)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate n random numbers according to the distribution of the
RandomVariable.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of random numbers generated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>The generated numbers.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def random(self, n):
    &#39;&#39;&#39;
    Generate n random numbers according to the distribution of the
    RandomVariable.

    Parameters
    ----------
    n : int
        The number of random numbers generated.

    Returns
    -------
    numpy.ndarray
        The generated numbers.

    &#39;&#39;&#39;
    raise NotImplementedError(&#39;No generic implementation of the method.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.random_variable_statistics"><code class="name flex">
<span>def <span class="ident">random_variable_statistics</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the mean and the variance of the random variable.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>The mean of the random variable.</dd>
<dt><code>float</code></dt>
<dd>The variance of the random variable.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def random_variable_statistics(self):
    &#39;&#39;&#39;
    Return the mean and the variance of the random variable.

    Returns
    -------
    float
        The mean of the random variable.
    float
        The variance of the random variable.

    &#39;&#39;&#39;
    raise NotImplementedError(&#39;No generic implementation of the method.&#39;)</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.std"><code class="name flex">
<span>def <span class="ident">std</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the standard deviation of the random variable.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>The standard deviation of the random variable.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def std(self):
    &#39;&#39;&#39;
    Return the standard deviation of the random variable.

    Returns
    -------
    float
        The standard deviation of the random variable.

    &#39;&#39;&#39;
    return np.sqrt(self.random_variable_statistics()[1])</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.transfer"><code class="name flex">
<span>def <span class="ident">transfer</span></span>(<span>self, Y, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Transfer from the random variable self to the random variable Y at
points x.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>Y</code></strong> :&ensp;<code>tensap.RandomVariable</code></dt>
<dd>The target RandomVariable of the transfer.</dd>
<dt><strong><code>x</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>The input points.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The transfered points.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transfer(self, Y, x):
    &#39;&#39;&#39;
    Transfer from the random variable self to the random variable Y at
    points x.

    Parameters
    ----------
    Y : tensap.RandomVariable
        The target RandomVariable of the transfer.
    x : list or numpy.ndarray
        The input points.

    Returns
    -------
    y : numpy.ndarray
        The transfered points.

    &#39;&#39;&#39;
    assert isinstance(self, tensap.RandomVariable) and \
        isinstance(Y, tensap.RandomVariable), \
        &#39;The first two arguments must be RandomVariable.&#39;
    return Y.icdf(self.cdf(x))</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.truncated_support"><code class="name flex">
<span>def <span class="ident">truncated_support</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the truncated support of the random variable.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>sup</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The truncated support of the random variable.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def truncated_support(self):
    &#39;&#39;&#39;
    Return the truncated support of the random variable.

    Returns
    -------
    sup : numpy.ndarray
        The truncated support of the random variable.

    &#39;&#39;&#39;

    sup = self.support()
    if sup[0] == -np.inf:
        sup[0] = self.mean() - 10*self.std()
    if sup[1] == np.inf:
        sup[1] = self.mean() + 10*self.std()
    return sup</code></pre>
</details>
</dd>
<dt id="tensap.functions.measures.random_variable.RandomVariable.variance"><code class="name flex">
<span>def <span class="ident">variance</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the variance of the random variable.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>The variance of the random variable.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def variance(self):
    &#39;&#39;&#39;
    Return the variance of the random variable.

    Returns
    -------
    float
        The variance of the random variable.

    &#39;&#39;&#39;
    return self.random_variable_statistics()[1]</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="tensap.functions.measures.probability_measure.ProbabilityMeasure" href="probability_measure.html#tensap.functions.measures.probability_measure.ProbabilityMeasure">ProbabilityMeasure</a></b></code>:
<ul class="hlist">
<li><code><a title="tensap.functions.measures.probability_measure.ProbabilityMeasure.mass" href="measure.html#tensap.functions.measures.measure.Measure.mass">mass</a></code></li>
<li><code><a title="tensap.functions.measures.probability_measure.ProbabilityMeasure.support" href="measure.html#tensap.functions.measures.measure.Measure.support">support</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tensap.functions.measures" href="index.html">tensap.functions.measures</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tensap.functions.measures.random_variable.RandomVariable" href="#tensap.functions.measures.random_variable.RandomVariable">RandomVariable</a></code></h4>
<ul class="">
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.cdf" href="#tensap.functions.measures.random_variable.RandomVariable.cdf">cdf</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.cdf_plot" href="#tensap.functions.measures.random_variable.RandomVariable.cdf_plot">cdf_plot</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.discretize" href="#tensap.functions.measures.random_variable.RandomVariable.discretize">discretize</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.gauss_integration_rule" href="#tensap.functions.measures.random_variable.RandomVariable.gauss_integration_rule">gauss_integration_rule</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.get_parameters" href="#tensap.functions.measures.random_variable.RandomVariable.get_parameters">get_parameters</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.icdf" href="#tensap.functions.measures.random_variable.RandomVariable.icdf">icdf</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.icdf_plot" href="#tensap.functions.measures.random_variable.RandomVariable.icdf_plot">icdf_plot</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.iso_probabilistic_grid" href="#tensap.functions.measures.random_variable.RandomVariable.iso_probabilistic_grid">iso_probabilistic_grid</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.lhs_random" href="#tensap.functions.measures.random_variable.RandomVariable.lhs_random">lhs_random</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.likelihood" href="#tensap.functions.measures.random_variable.RandomVariable.likelihood">likelihood</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.max" href="#tensap.functions.measures.random_variable.RandomVariable.max">max</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.mean" href="#tensap.functions.measures.random_variable.RandomVariable.mean">mean</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.min" href="#tensap.functions.measures.random_variable.RandomVariable.min">min</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.moment" href="#tensap.functions.measures.random_variable.RandomVariable.moment">moment</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.ndim" href="#tensap.functions.measures.random_variable.RandomVariable.ndim">ndim</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.number_of_parameters" href="#tensap.functions.measures.random_variable.RandomVariable.number_of_parameters">number_of_parameters</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.orthonormal_polynomials" href="#tensap.functions.measures.random_variable.RandomVariable.orthonormal_polynomials">orthonormal_polynomials</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.pdf" href="#tensap.functions.measures.random_variable.RandomVariable.pdf">pdf</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.pdf_plot" href="#tensap.functions.measures.random_variable.RandomVariable.pdf_plot">pdf_plot</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.plot" href="#tensap.functions.measures.random_variable.RandomVariable.plot">plot</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.random" href="#tensap.functions.measures.random_variable.RandomVariable.random">random</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.random_variable_statistics" href="#tensap.functions.measures.random_variable.RandomVariable.random_variable_statistics">random_variable_statistics</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.std" href="#tensap.functions.measures.random_variable.RandomVariable.std">std</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.transfer" href="#tensap.functions.measures.random_variable.RandomVariable.transfer">transfer</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.truncated_support" href="#tensap.functions.measures.random_variable.RandomVariable.truncated_support">truncated_support</a></code></li>
<li><code><a title="tensap.functions.measures.random_variable.RandomVariable.variance" href="#tensap.functions.measures.random_variable.RandomVariable.variance">variance</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>